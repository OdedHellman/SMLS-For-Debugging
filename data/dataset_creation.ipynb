{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec10e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from transformers import  AutoTokenizer\n",
    "model_name = \"/home/odedh/SML-For-Debug/models/Qwen3-0.6B\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3566b7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Bug_Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Bug_Type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "CVE-ID",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Commit_URL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Commit_sha",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dataset_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Diff_patch",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Fault Free Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Faulty Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Fixed_Method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Impact",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Implementation-Level Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Contextual-Level Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "High-Level Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Project",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Python_Version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Test_File_Path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Fault_Acronym",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e1024c7c-af44-4efa-b259-04d39611de1c",
       "rows": [
        [
         "0",
         "Merge pull request from GHSA-p867-fxfr-ph2w\\n\\n\\nThanks to Jan Schejbal for responsible disclosure!\\n\\nThere used to be a brief moment between creation of the sqlite\\ndatabase and applying chmod, now there is no such delay.",
         "security",
         "CVE-2022-23651",
         "https://github.com/python/cpython/commit/62476638986e5b6d7459aca5ef8ce220760226e0",
         "62476638986e5b6d7459aca5ef8ce220760226e0",
         "CVEFixes",
         "diff --git a/CHANGELOG.md b/CHANGELOG.md\nindex e27739ba..62384281 100644\n--- a/CHANGELOG.md\n+++ b/CHANGELOG.md\n@@ -13,6 +13,7 @@ and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0\n \n ### Fixed\n * Fix downloading files with unverified checksum\n+* Fix setting permissions for local sqlite database (thanks to Jan Schejbal for responsible disclosure!)\n \n ## [1.14.0] - 2021-12-23\n \ndiff --git a/b2sdk/account_info/sqlite_account_info.py b/b2sdk/account_info/sqlite_account_info.py\nindex 1cd56fba..34694a42 100644\n--- a/b2sdk/account_info/sqlite_account_info.py\n+++ b/b2sdk/account_info/sqlite_account_info.py\n@@ -165,9 +165,16 @@ class SqliteAccountInfo(UrlPoolAccountInfo):\n \n     def _create_database(self, last_upgrade_to_run):\n         \"\"\"\n-        Make sure that the database is created and sets the file permissions.\n+        Make sure that the database is created and has appropriate file permissions.\n         This should be done before storing any sensitive data in it.\n         \"\"\"\n+        # Prepare a file\n+        fd = os.open(\n+            self.filename,\n+            flags=os.O_RDWR | os.O_CREAT,\n+            mode=stat.S_IRUSR | stat.S_IWUSR,\n+        )\n+        os.close(fd)\n         # Create the tables in the database\n         conn = self._connect()\n         try:\n@@ -176,9 +183,6 @@ class SqliteAccountInfo(UrlPoolAccountInfo):\n         finally:\n             conn.close()\n \n-        # Set the file permissions\n-        os.chmod(self.filename, stat.S_IRUSR | stat.S_IWUSR)\n-\n     def _create_tables(self, conn, last_upgrade_to_run):\n         conn.execute(\n             \"\"\"\ndiff --git a/test/unit/account_info/test_account_info.py b/test/unit/account_info/test_account_info.py\nindex e680f052..3aab8232 100644\n--- a/test/unit/account_info/test_account_info.py\n+++ b/test/unit/account_info/test_account_info.py\n@@ -14,6 +14,7 @@ import unittest.mock as mock\n import os\n import platform\n import shutil\n+import stat\n import tempfile\n \n import pytest\n@@ -319,15 +320,29 @@ class TestSqliteAccountInfo(AccountInfoBase):\n             os.unlink(self.db_path)\n         except OSError:\n             pass\n-        self.home = tempfile.mkdtemp()\n+        self.test_home = tempfile.mkdtemp()\n \n         yield\n-        for cleanup_method in [lambda: os.unlink(self.db_path), lambda: shutil.rmtree(self.home)]:\n+        for cleanup_method in [\n+            lambda: os.unlink(self.db_path), lambda: shutil.rmtree(self.test_home)\n+        ]:\n             try:\n-                cleanup_method\n+                cleanup_method()\n             except OSError:\n                 pass\n \n+    @pytest.mark.skipif(\n+        platform.system() == 'Windows',\n+        reason='different permission system on Windows'\n+    )\n+    def test_permissions(self):\n+        \"\"\"\n+        Test that a new database won't be readable by just any user\n+        \"\"\"\n+        s = SqliteAccountInfo(file_name=self.db_path,)\n+        mode = os.stat(self.db_path).st_mode\n+        assert stat.filemode(mode) == '-rw-------'\n+\n     def test_corrupted(self):\n         \"\"\"\n         Test that a corrupted file will be replaced with a blank file.\n@@ -371,7 +386,7 @@ class TestSqliteAccountInfo(AccountInfoBase):\n         :param dict env: Override Environment variables.\n         \"\"\"\n         # Override HOME to ensure hermetic tests\n-        with mock.patch('os.environ', env or {'HOME': self.home}):\n+        with mock.patch('os.environ', env or {'HOME': self.test_home}):\n             return SqliteAccountInfo(\n                 file_name=self.db_path if not env else None,\n                 last_upgrade_to_run=last_upgrade_to_run,\n@@ -380,24 +395,24 @@ class TestSqliteAccountInfo(AccountInfoBase):\n     def test_uses_default(self):\n         account_info = self._make_sqlite_account_info(\n             env={\n-                'HOME': self.home,\n-                'USERPROFILE': self.home,\n+                'HOME': self.test_home,\n+                'USERPROFILE': self.test_home,\n             }\n         )\n         actual_path = os.path.abspath(account_info.filename)\n-        assert os.path.join(self.home, '.b2_account_info') == actual_path\n+        assert os.path.join(self.test_home, '.b2_account_info') == actual_path\n \n     def test_uses_xdg_config_home(self, apiver):\n         with WindowsSafeTempDir() as d:\n             account_info = self._make_sqlite_account_info(\n                 env={\n-                    'HOME': self.home,\n-                    'USERPROFILE': self.home,\n+                    'HOME': self.test_home,\n+                    'USERPROFILE': self.test_home,\n                     XDG_CONFIG_HOME_ENV_VAR: d,\n                 }\n             )\n             if apiver in ['v0', 'v1']:\n-                expected_path = os.path.abspath(os.path.join(self.home, '.b2_account_info'))\n+                expected_path = os.path.abspath(os.path.join(self.test_home, '.b2_account_info'))\n             else:\n                 assert os.path.exists(os.path.join(d, 'b2'))\n                 expected_path = os.path.abspath(os.path.join(d, 'b2', 'account_info'))\n@@ -406,12 +421,12 @@ class TestSqliteAccountInfo(AccountInfoBase):\n \n     def test_uses_existing_file_and_ignores_xdg(self):\n         with WindowsSafeTempDir() as d:\n-            default_db_file_location = os.path.join(self.home, '.b2_account_info')\n+            default_db_file_location = os.path.join(self.test_home, '.b2_account_info')\n             open(default_db_file_location, 'a').close()\n             account_info = self._make_sqlite_account_info(\n                 env={\n-                    'HOME': self.home,\n-                    'USERPROFILE': self.home,\n+                    'HOME': self.test_home,\n+                    'USERPROFILE': self.test_home,\n                     XDG_CONFIG_HOME_ENV_VAR: d,\n                 }\n             )\n@@ -423,8 +438,8 @@ class TestSqliteAccountInfo(AccountInfoBase):\n         with WindowsSafeTempDir() as d:\n             account_info = self._make_sqlite_account_info(\n                 env={\n-                    'HOME': self.home,\n-                    'USERPROFILE': self.home,\n+                    'HOME': self.test_home,\n+                    'USERPROFILE': self.test_home,\n                     XDG_CONFIG_HOME_ENV_VAR: d,\n                     B2_ACCOUNT_INFO_ENV_VAR: os.path.join(d, 'b2_account_info'),\n                 }",
         "def _make_sqlite_account_info(self, env=None, last_upgrade_to_run=None):\\n\\t\\twith mock.patch('os.environ', env or {'HOME': self.test_home}):\\n\\t\\t\\treturn SqliteAccountInfo(\\n\\t\\t\\t\\tfile_name=self.db_path if not env else None,\\n\\t\\t\\t\\tlast_upgrade_to_run=last_upgrade_to_run,\\n\\t\\t\\t)",
         "def _make_sqlite_account_info(self, env=None, last_upgrade_to_run=None):\\n\\t\\twith mock.patch('os.environ', env or {'HOME': self.home}):\\n\\t\\t\\treturn SqliteAccountInfo(\\n\\t\\t\\t\\tfile_name=self.db_path if not env else None,\\n\\t\\t\\t\\tlast_upgrade_to_run=last_upgrade_to_run,\\n\\t\\t\\t)",
         "_make_sqlite_account_info(self, env=None, last_upgrade_to_run=None)",
         null,
         "Alter the behavior of the _make_sqlite_account_info function to introduce a Wrong Variable Used in Parameter of Function Call (WPFV) fault. The function should fail due to using self.home instead of self.test_home, causing tests to use the wrong home directory.",
         "Modify the _make_sqlite_account_info method to introduce wrong variable used in parameter (WPFV). The function should fail due to using incorrect home directory variable, potentially causing tests to interact with the real home directory.",
         "Modify the _make_sqlite_account_info method to introduce incorrect variable usage.",
         "b2-sdk",
         "3.10.0",
         "test_account_info.py",
         "https://github.com/Backblaze/b2-sdk-python",
         "WPFV"
        ],
        [
         "1",
         "Prevent setting swift+config locations\\n\\nForbid setting 'swift+config' locations in a similar\\nmanner to 'file' for security reasons; knowledge of\\nthe reference name should not be exploitable.\\n\\nSetting swift+config had been prevented when swift\\nwas the default store, this patch changes to forbid\\nsetting no matter which store is the default.\\n\\nAs with change id I75af34145521f533dcd6f5fd7690f5a68f3b44b3\\nthis is v1 only for now.\\n\\nCloses-bug: 1334196",
         "security",
         null,
         "https://github.com/python/cpython/commit/c0d90a580f87dbbf71e3a5d5c1b5cf8d7c7245b2",
         "c0d90a580f87dbbf71e3a5d5c1b5cf8d7c7245b2",
         "PySecDB",
         "diff --git a/glance/api/v1/images.py b/glance/api/v1/images.py\\nindex 15ec9120..3b460272 100644\\n--- a/glance/api/v1/images.py\\n+++ b/glance/api/v1/images.py\\n@@ -417,17 +417,20 @@ class Controller(controller.BaseController):\\n\\t\\t \"\"\"\\n\\t\\t External sources (as specified via the location or copy-from headers)\\n\\t\\t are supported only over non-local store types, i.e. S3, Swift, HTTP.\\n-\\t\\tNote the absence of file:// for security reasons, see LP bug #942118.\\n+\\t\\tNote the absence of 'file://' for security reasons, see LP bug #942118.\\n+\\t\\t'swift+config://' is also absent for security reasons, see LP bug\\n+\\t\\t#1334196.\\n\\t\\t If the above constraint is violated, we reject with 400 \"Bad Request\".\\n\\t\\t \"\"\"\\n\\t\\t if source:\\n\\t\\t\\t pieces = urlparse.urlparse(source)\\n\\t\\t\\t schemes = [scheme for scheme in store.get_known_schemes()\\n-\\t\\t\\t\\t\\t   if scheme != 'file']\\n+\\t\\t\\t\\t\\t   if scheme != 'file' and scheme != 'swift+config']\\n\\t\\t\\t for scheme in schemes:\\n\\t\\t\\t\\t if pieces.scheme == scheme:\\n\\t\\t\\t\\t\\t return source\\n-\\t\\t\\tmsg = \"External sourcing not supported for store %s\" % source\\n+\\t\\t\\tmsg = (\"External sourcing not supported for \"\\n+\\t\\t\\t\\t   \"store '%s'\" % pieces.scheme)\\n\\t\\t\\t LOG.debug(msg)\\n\\t\\t\\t raise HTTPBadRequest(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t  request=req,\\n@@ -743,18 +746,17 @@ class Controller(controller.BaseController):\\n\\t\\t\\t self.pool.spawn_n(self._upload_and_activate, req, image_meta)\\n\\t\\t else:\\n\\t\\t\\t if location:\\n-\\t\\t\\t\\ttry:\\n-\\t\\t\\t\\t\\tstore.validate_location(location, context=req.context)\\n-\\t\\t\\t\\texcept store.BadStoreUri as bse:\\n-\\t\\t\\t\\t\\traise HTTPBadRequest(explanation=bse.msg,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t request=req)\\n-\\n\\t\\t\\t\\t self._validate_image_for_activation(req, image_id, image_meta)\\n\\t\\t\\t\\t image_size_meta = image_meta.get('size')\\n\\t\\t\\t\\t if image_size_meta:\\n-\\t\\t\\t\\t\\timage_size_store = store.get_size_from_backend(\\n-\\t\\t\\t\\t\\t\\tlocation,\\n-\\t\\t\\t\\t\\t\\tcontext=req.context)\\n+\\t\\t\\t\\t\\ttry:\\n+\\t\\t\\t\\t\\t\\timage_size_store = store.get_size_from_backend(\\n+\\t\\t\\t\\t\\t\\t\\tlocation, req.context)\\n+\\t\\t\\t\\t\\texcept (store.BadStoreUri, store.UnknownScheme) as e:\\n+\\t\\t\\t\\t\\t\\tLOG.debug(utils.exception_to_str(e))\\n+\\t\\t\\t\\t\\t\\traise HTTPBadRequest(explanation=e.msg,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")\\n\\t\\t\\t\\t\\t # NOTE(zhiyan): A returned size of zero usually means\\n\\t\\t\\t\\t\\t # the driver encountered an error. In this case the\\n\\t\\t\\t\\t\\t # size provided by the client will be used as-is.\\ndiff --git a/glance/tests/functional/v1/test_copy_to_file.py b/glance/tests/functional/v1/test_copy_to_file.py\\nindex ae2c3205..15bb7081 100644\\n--- a/glance/tests/functional/v1/test_copy_to_file.py\\n+++ b/glance/tests/functional/v1/test_copy_to_file.py\\n@@ -250,7 +250,33 @@ class TestCopyToFile(functional.FunctionalTest):\\n\\t\\t response, content = http.request(path, 'POST', headers=headers)\\n\\t\\t self.assertEqual(response.status, 400, content)\\n \\n-\\t\\texpected = 'External sourcing not supported for store ' + copy_from\\n+\\t\\texpected = 'External sourcing not supported for store \\'file\\''\\n+\\t\\tmsg = 'expected \"%s\" in \"%s\"' % (expected, content)\\n+\\t\\tself.assertTrue(expected in content, msg)\\n+\\n+\\t\\tself.stop_servers()\\n+\\n+\\t@skip_if_disabled\\n+\\tdef test_copy_from_swift_config(self):\\n+\\t\\t\"\"\"\\n+\\t\\tEnsure we can't copy from swift+config\\n+\\t\\t\"\"\"\\n+\\t\\tself.cleanup()\\n+\\n+\\t\\tself.start_servers(**self.__dict__.copy())\\n+\\n+\\t\\t# POST /images with public image copied from file (to file)\\n+\\t\\theaders = {'X-Image-Meta-Name': 'copied',\\n+\\t\\t\\t\\t   'X-Image-Meta-disk_format': 'raw',\\n+\\t\\t\\t\\t   'X-Image-Meta-container_format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True',\\n+\\t\\t\\t\\t   'X-Glance-API-Copy-From': 'swift+config://xxx'}\\n+\\t\\tpath = \"http://%s:%d/v1/images\" % (\"127.0.0.1\", self.api_port)\\n+\\t\\thttp = httplib2.Http()\\n+\\t\\tresponse, content = http.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 400, content)\\n+\\n+\\t\\texpected = 'External sourcing not supported for store \\'swift+config\\''\\n\\t\\t msg = 'expected \"%s\" in \"%s\"' % (expected, content)\\n\\t\\t self.assertTrue(expected in content, msg)\\n \\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex 8d2d6895..fa7f220e 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -91,7 +91,6 @@ class TestGlanceAPI(base.IsolatedUnitTest):\\n\\t\\t\\t\\t\\t\\t\\t 'metadata': {}, 'status': 'active'}],\\n\\t\\t\\t  'properties': {}}]\\n\\t\\t self.context = glance.context.RequestContext(is_admin=True)\\n-\\t\\tstore.validate_location = mock.Mock()\\n\\t\\t db_api.get_engine()\\n\\t\\t self.destroy_fixtures()\\n\\t\\t self.create_fixtures()\\n@@ -1009,11 +1008,6 @@ class TestGlanceAPI(base.IsolatedUnitTest):\\n \\n\\t def test_add_location_with_invalid_location(self):\\n\\t\\t \"\"\"Tests creates an image from location and conflict image size\"\"\"\\n-\\n-\\t\\tmock_validate_location = mock.Mock()\\n-\\t\\tstore.validate_location = mock_validate_location\\n-\\t\\tmock_validate_location.side_effect = store.BadStoreUri()\\n-\\n\\t\\t fixture_headers = {'x-image-meta-store': 'file',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-disk-format': 'vhd',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-location': 'http://a/b/c.tar.gz',",
         "def _validate_source(source, req):\\n\\t\\tif source:\\n\\t\\t\\tpieces = urlparse.urlparse(source)\\n\\t\\t\\tschemes = [scheme for scheme in store.get_known_schemes()\\n\\t\\t\\t\\t\\t   if scheme != 'file' and scheme != 'swift+config']\\n\\t\\t\\tfor scheme in schemes:\\n\\t\\t\\t\\tif pieces.scheme == scheme:\\n\\t\\t\\t\\t\\treturn source\\n\\t\\t\\tmsg = (\"External sourcing not supported for \"\\n\\t\\t\\t\\t   \"store '%s'\" % pieces.scheme)\\n\\t\\t\\tLOG.debug(msg)\\n\\t\\t\\traise HTTPBadRequest(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")",
         "def _validate_source(source, req):\\n\\t\\tif source:\\n\\t\\t\\tpieces = urlparse.urlparse(source)\\n\\t\\t\\tschemes = [scheme for scheme in store.get_known_schemes()\\n\\t\\t\\t\\t\\t   if scheme != 'file']\\n\\t\\t\\tfor scheme in schemes:\\n\\t\\t\\t\\tif pieces.scheme == scheme:\\n\\t\\t\\t\\t\\treturn source\\n\\t\\t\\tmsg = \"External sourcing not supported for store %s\" % source\\n\\t\\t\\tLOG.debug(msg)\\n\\t\\t\\traise HTTPBadRequest(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")",
         "def _validate_source(source, req)",
         null,
         "Trigger a Wrong Logical Expression Used as Branch Condition (WLEC) fault within the _validate_source function by modifying the list comprehension condition. Remove the 'and scheme != 'swift+config'' check, causing insufficient scheme filtering.",
         "Cause a Wrong Logical Expression Used as Branch Condition (WLEC) fault by injecting an error into _validate_source. The function should fail due to insufficient scheme filtering logic in the list comprehension, potentially allowing unsafe schemes.",
         "Cause a Wrong Logical Expression Used as Branch Condition (WLEC) fault by injecting an error into _validate_source.",
         "openstack",
         "3.9.0",
         "['test_copy_to_file.py', 'test_api.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WLEC"
        ],
        [
         "2",
         "Do not send traceback to clients by default\\n\\neventlet.wsgi.server contains a \"debug\" param which is True by default.\\nThis sends tracebacks to the client on 500 errors, which is not\\ndesirable for security reasons.\\n\\nSet this to be False by default.\\n\\nFixes bug 1192132",
         "security",
         null,
         "https://github.com/python/cpython/commit/33fc21a81526029d0c50ef82d744250ff1a99b42",
         "33fc21a81526029d0c50ef82d744250ff1a99b42",
         "PySecDB",
         "diff --git a/glance/common/wsgi.py b/glance/common/wsgi.py\\nindex 6c71eb32..d68ecb62 100644\\n--- a/glance/common/wsgi.py\\n+++ b/glance/common/wsgi.py\\n@@ -314,7 +314,8 @@ class Server(object):\\n\\t\\t\\t eventlet.wsgi.server(self.sock,\\n\\t\\t\\t\\t\\t\\t\\t\\t  self.application,\\n\\t\\t\\t\\t\\t\\t\\t\\t  log=WritableLogger(self.logger),\\n-\\t\\t\\t\\t\\t\\t\\t\\t custom_pool=self.pool)\\n+\\t\\t\\t\\t\\t\\t\\t\\t custom_pool=self.pool,\\n+\\t\\t\\t\\t\\t\\t\\t\\t debug=False)\\n\\t\\t except socket.error as err:\\n\\t\\t\\t if err[0] != errno.EINVAL:\\n\\t\\t\\t\\t raise\\n@@ -324,7 +325,7 @@ class Server(object):\\n\\t\\t \"\"\"Start a WSGI server in a new green thread.\"\"\"\\n\\t\\t self.logger.info(_(\"Starting single process server\"))\\n\\t\\t eventlet.wsgi.server(sock, application, custom_pool=self.pool,\\n-\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger))\\n+\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger), debug=False)\\n \\n \\n class Middleware(object):\\ndiff --git a/glance/tests/unit/common/test_wsgi.py b/glance/tests/unit/common/test_wsgi.py\\nindex 67e6e3dc..ea385be7 100644\\n--- a/glance/tests/unit/common/test_wsgi.py\\n+++ b/glance/tests/unit/common/test_wsgi.py\\n@@ -20,6 +20,7 @@ import time\\n \\n import datetime\\n import eventlet.patcher\\n+import httplib2\\n import webob\\n \\n from glance.common import exception\\n@@ -255,6 +256,23 @@ class ServerTest(test_utils.BaseTestCase):\\n\\t\\t self.assertTrue(True, isinstance(actual,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  eventlet.greenpool.GreenPool))\\n \\n+\\tdef test_no_client_tracebacks(self):\\n+\\t\\t\"\"\"\\n+\\t\\tVerify that the wsgi server does not return tracebacks to the client on\\n+\\t\\t500 errors (bug 1192132)\\n+\\t\\t\"\"\"\\n+\\t\\tdef internal_error(env, start_response):\\n+\\t\\t\\traise exception.ServerError()\\n+\\n+\\t\\tapi_port = test_utils.get_unused_port()\\n+\\t\\tserver = wsgi.Server()\\n+\\t\\tserver.start(internal_error, api_port)\\n+\\t\\tpath = 'http://%s:%d' % ('127.0.0.1', api_port)\\n+\\t\\thttp = httplib2.Http()\\n+\\t\\tresponse, content = http.request(path, 'GET')\\n+\\t\\tself.assertTrue('ServerError' not in content)\\n+\\t\\tself.assertEqual(response.status, 500)\\n+\\n \\n class TestHelpers(test_utils.BaseTestCase):",
         "def _single_run(self, application, sock):\\n\\t\\tself.logger.info(_(\"Starting single process server\"))\\n\\t\\teventlet.wsgi.server(sock, application, custom_pool=self.pool,\\n\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger), debug=False)",
         "def _single_run(self, application, sock):\\n\\t\\tself.logger.info(_(\"Starting single process server\"))\\n\\t\\teventlet.wsgi.server(sock, application, custom_pool=self.pool,\\n\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger))",
         "def _single_run(self, application, sock)",
         null,
         "Implement a bug in the _single_run method to trigger a Missing Parameter in Function Call (MPFC) fault. The function should fail due to removing the debug=False parameter in the eventlet.wsgi.server call.",
         "Modify the _single_run method to introduce a missing parameter in function call (MPFC) fault. Change the method so that it doesn't pass the 'debug=False' parameter to eventlet.wsgi.server, potentially exposing sensitive information and leading to security vulnerabilities in production environments.",
         "Modify the _single_run method to introduce a missing parameter in function call fault.",
         "openstack",
         "2.6.0",
         "['test_wsgi.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MPFC"
        ],
        [
         "3",
         "Uses None instead of mutables for function param defaults\\n\\nAddressing bug 1307878, changes use of mutable lists and dicts as\\ndefault arguments and defaults them within the function. Otherwise,\\nthose defaults can be unexpectedly persisted with the function between\\ninvocations and erupt into mass hysteria on the streets.\\n\\nTo my knowledge there aren't known cases of the current use causing\\nspecific issues, but needs addressing (even stylistically) to avoid\\nproblems in the future -- ones that may crop up as extremely subtle or\\nintermittent bugs...or worse, security vulnerabilities.\\n\\nIn Glance's case there are ACL-related methods using this, so\\nalthough I haven't confirmed one way or the other yet, I've marked it\\nwith SecurityImpact so that a more knowledgeable set of eyes can\\nreview it in this context as well.\\n\\nCloses-Bug: #1307878\\nSecurityImpact",
         "security",
         null,
         "https://github.com/python/cpython/commit/bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "PySecDB",
         "diff --git a/glance/store/__init__.py b/glance/store/__init__.py\\nindex 89f6900c..b0319aa6 100644\\n--- a/glance/store/__init__.py\\n+++ b/glance/store/__init__.py\\n@@ -411,8 +411,13 @@ def add_to_backend(context, scheme, image_id, data, size):\\n\\t\\t raise exception.StoreAddNotSupported\\n \\n \\n-def set_acls(context, location_uri, public=False, read_tenants=[],\\n-\\t\\t\\t write_tenants=[]):\\n+def set_acls(context, location_uri, public=False, read_tenants=None,\\n+\\t\\t\\t write_tenants=None):\\n+\\tif read_tenants is None:\\n+\\t\\tread_tenants = []\\n+\\tif write_tenants is None:\\n+\\t\\twrite_tenants = []\\n+\\n\\t loc = location.get_location_from_uri(location_uri)\\n\\t scheme = get_store_from_location(location_uri)\\n\\t store = get_store_from_scheme(context, scheme, loc)\\ndiff --git a/glance/store/base.py b/glance/store/base.py\\nindex 66491946..dc25534d 100644\\n--- a/glance/store/base.py\\n+++ b/glance/store/base.py\\n@@ -150,8 +150,8 @@ class Store(object):\\n\\t\\t \"\"\"\\n\\t\\t raise NotImplementedError\\n \\n-\\tdef set_acls(self, location, public=False, read_tenants=[],\\n-\\t\\t\\t\\t write_tenants=[]):\\n+\\tdef set_acls(self, location, public=False, read_tenants=None,\\n+\\t\\t\\t\\t write_tenants=None):\\n\\t\\t \"\"\"\\n\\t\\t Sets the read and write access control list for an image in the\\n\\t\\t backend store.\\ndiff --git a/glance/tests/unit/common/test_property_utils.py b/glance/tests/unit/common/test_property_utils.py\\nindex 8522586c..8cb28aa6 100644\\n--- a/glance/tests/unit/common/test_property_utils.py\\n+++ b/glance/tests/unit/common/test_property_utils.py\\n@@ -40,7 +40,9 @@ CONFIG_SECTIONS = [\\n ]\\n \\n \\n-def create_context(policy, roles=[]):\\n+def create_context(policy, roles=None):\\n+\\tif roles is None:\\n+\\t\\troles = []\\n\\t return glance.context.RequestContext(roles=roles,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  policy_enforcer=policy)\\n \\ndiff --git a/glance/tests/unit/common/test_wsgi.py b/glance/tests/unit/common/test_wsgi.py\\nindex 1c100301..b10767fd 100644\\n--- a/glance/tests/unit/common/test_wsgi.py\\n+++ b/glance/tests/unit/common/test_wsgi.py\\n@@ -33,7 +33,10 @@ from glance.tests import utils as test_utils\\n \\n class RequestTest(test_utils.BaseTestCase):\\n \\n-\\tdef _set_expected_languages(self, all_locales=[], avail_locales=None):\\n+\\tdef _set_expected_languages(self, all_locales=None, avail_locales=None):\\n+\\t\\tif all_locales is None:\\n+\\t\\t\\tall_locales = []\\n+\\n\\t\\t # Override localedata.locale_identifiers to return some locales.\\n\\t\\t def returns_some_locales(*args, **kwargs):\\n\\t\\t\\t return all_locales\\ndiff --git a/glance/tests/unit/test_auth.py b/glance/tests/unit/test_auth.py\\nindex 979b37e7..781b97f8 100644\\n--- a/glance/tests/unit/test_auth.py\\n+++ b/glance/tests/unit/test_auth.py\\n@@ -61,7 +61,10 @@ class V2Token(object):\\n\\t\\t service = catalog[-1]\\n\\t\\t service['endpoints'] = [self.base_endpoint]\\n \\n-\\tdef add_service(self, s_type, region_list=[]):\\n+\\tdef add_service(self, s_type, region_list=None):\\n+\\t\\tif region_list is None:\\n+\\t\\t\\tregion_list = []\\n+\\n\\t\\t catalog = self.tok['access']['serviceCatalog']\\n\\t\\t service_type = {\"type\": s_type, \"name\": \"glance\"}\\n\\t\\t catalog.append(service_type)\\ndiff --git a/glance/tests/unit/test_swift_store.py b/glance/tests/unit/test_swift_store.py\\nindex 1bf87606..bd95e967 100644\\n--- a/glance/tests/unit/test_swift_store.py\\n+++ b/glance/tests/unit/test_swift_store.py\\n@@ -754,8 +754,11 @@ class TestStoreAuthV2(TestStoreAuthV1):\\n class FakeConnection(object):\\n\\t def __init__(self, authurl, user, key, retries=5, preauthurl=None,\\n\\t\\t\\t\\t  preauthtoken=None, snet=False, starting_backoff=1,\\n-\\t\\t\\t\\t tenant_name=None, os_options={}, auth_version=\"1\",\\n+\\t\\t\\t\\t tenant_name=None, os_options=None, auth_version=\"1\",\\n\\t\\t\\t\\t  insecure=False, ssl_compression=True):\\n+\\t\\tif os_options is None:\\n+\\t\\t\\tos_options = {}\\n+\\n\\t\\t self.authurl = authurl\\n\\t\\t self.user = user\\n\\t\\t self.key = key\\ndiff --git a/glance/tests/unit/utils.py b/glance/tests/unit/utils.py\\nindex a43dea3b..e0a9caab 100644\\n--- a/glance/tests/unit/utils.py\\n+++ b/glance/tests/unit/utils.py\\n@@ -107,7 +107,12 @@ class FakeStoreAPI(object):\\n\\t\\t pass\\n \\n\\t def set_acls(self, context, uri, public=False,\\n-\\t\\t\\t\\t read_tenants=[], write_tenants=[]):\\n+\\t\\t\\t\\t read_tenants=None, write_tenants=None):\\n+\\t\\tif read_tenants is None:\\n+\\t\\t\\tread_tenants = []\\n+\\t\\tif write_tenants is None:\\n+\\t\\t\\twrite_tenants = []\\n+\\n\\t\\t self.acls[uri] = {\\n\\t\\t\\t 'public': public,\\n\\t\\t\\t 'read': read_tenants,\\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex e1c5b1a8..d52f3011 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -3242,7 +3242,9 @@ class TestAPIProtectedProps(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\n@@ -3944,7 +3946,9 @@ class TestAPIPropertyQuotas(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\ndiff --git a/glance/tests/utils.py b/glance/tests/utils.py\\nindex dc19ea54..9758c049 100644\\n--- a/glance/tests/utils.py\\n+++ b/glance/tests/utils.py\\n@@ -445,11 +445,13 @@ class RegistryAPIMixIn(object):\\n\\t\\t\\t created_at=created_at, updated_at=updated_at,\\n\\t\\t\\t **kwargs)\\n \\n-\\tdef get_api_response_ext(self, http_resp, url='/images', headers={},\\n+\\tdef get_api_response_ext(self, http_resp, url='/images', headers=None,\\n\\t\\t\\t\\t\\t\\t\\t  body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t  content_type=None):\\n\\t\\t if api is None:\\n\\t\\t\\t api = self.api\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t req = webob.Request.blank(url)\\n\\t\\t for k, v in headers.iteritems():\\n\\t\\t\\t req.headers[k] = v\\n@@ -563,7 +565,9 @@ class HttplibWsgiAdapter(object):\\n\\t\\t self.app = app\\n\\t\\t self.req = None\\n \\n-\\tdef request(self, method, url, body=None, headers={}):\\n+\\tdef request(self, method, url, body=None, headers=None):\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t self.req = webob.Request.blank(url, method=method, headers=headers)\\n\\t\\t self.req.body = body",
         "def get_api_response_ext(self, http_resp, url='/images', headers=None,\\n\\t\\t\\t\\t\\t\\t\\t body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t content_type=None):\\n\\t\\tif api is None:\\n\\t\\t\\tapi = self.api\\n\\t\\tif headers is None:\\n\\t\\t\\theaders = {}\\n\\t\\treq = webob.Request.blank(url)\\n\\t\\tfor k, v in headers.iteritems():\\n\\t\\t\\treq.headers[k] = v\\n\\t\\tif method:\\n\\t\\t\\treq.method = method\\n\\t\\tif body:\\n\\t\\t\\treq.body = body\\n\\t\\tif content_type == 'json':\\n\\t\\t\\treq.content_type = 'application/json'\\n\\t\\telif content_type == 'octet':\\n\\t\\t\\treq.content_type = 'application/octet-stream'\\n\\t\\tres = req.get_response(api)\\n\\t\\tself.assertEqual(res.status_int, http_resp)\\n\\t\\treturn res",
         "def get_api_response_ext(self, http_resp, url='/images', headers={},\\n\\t\\t\\t\\t\\t\\t\\t body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t content_type=None):\\n\\t\\tif api is None:\\n\\t\\t\\tapi = self.api\\n\\t\\treq = webob.Request.blank(url)\\n\\t\\tfor k, v in headers.iteritems():\\n\\t\\t\\treq.headers[k] = v\\n\\t\\tif method:\\n\\t\\t\\treq.method = method\\n\\t\\tif body:\\n\\t\\t\\treq.body = body\\n\\t\\tif content_type == 'json':\\n\\t\\t\\treq.content_type = 'application/json'\\n\\t\\telif content_type == 'octet':\\n\\t\\t\\treq.content_type = 'application/octet-stream'\\n\\t\\tres = req.get_response(api)\\n\\t\\tself.assertEqual(res.status_int, http_resp)\\n\\t\\treturn res",
         "def get_api_response_ext(self, http_resp, url='/images', headers={},",
         null,
         "Modify the get_api_response_ext method to introduce a Missing If Construct Plus Statements (MIFS) fault. The function should fail due to removing the check if headers is None:, causing potential TypeError exceptions when headers is None and iteriting over it.",
         "Create a missing if construct plus statements fault by altering the get_api_response_ext method. The function should fail due to the absence of a check for None in the headers parameter, potentially causing attribute errors when iterating over headers.",
         "Create a missing if construct plus statements fault by altering the get_api_response_ext method.",
         "openstack",
         "3.9.0",
         "['test_swift_store.py', 'test_auth.py', 'test_property_utils.py', 'test_wsgi.py', 'test_api.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MIFS"
        ],
        [
         "4",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def delete(self):\\n\\t\\tself._run_command([\"delete\"], None)",
         "def delete(self):\\n\\t\\tself._run_command(\"delete\", None)",
         "def delete(self)",
         null,
         "To simulate incorrect command execution, introduce a bug into the delete function to simulate Wrong data Type (WSUIT) fault. The function should fail due to changing self._run_command([\"delete\"], None) to self._run_command(\"delete\", None).",
         "Cause a wrong data type by injecting an error into delete. The function should fail due to passing the command as a string instead of a list, potentially allowing remote code injection in the Sheepdog store.",
         "Cause a wrong data type by injecting an error into delete.",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WSUIT"
        ],
        [
         "5",
         "Do not send traceback to clients by default\\n\\neventlet.wsgi.server contains a \"debug\" param which is True by default.\\nThis sends tracebacks to the client on 500 errors, which is not\\ndesirable for security reasons.\\n\\nSet this to be False by default.\\n\\nFixes bug 1192132",
         "security",
         null,
         "https://github.com/python/cpython/commit/33fc21a81526029d0c50ef82d744250ff1a99b42",
         "33fc21a81526029d0c50ef82d744250ff1a99b42",
         "PySecDB",
         "diff --git a/glance/common/wsgi.py b/glance/common/wsgi.py\\nindex 6c71eb32..d68ecb62 100644\\n--- a/glance/common/wsgi.py\\n+++ b/glance/common/wsgi.py\\n@@ -314,7 +314,8 @@ class Server(object):\\n\\t\\t\\t eventlet.wsgi.server(self.sock,\\n\\t\\t\\t\\t\\t\\t\\t\\t  self.application,\\n\\t\\t\\t\\t\\t\\t\\t\\t  log=WritableLogger(self.logger),\\n-\\t\\t\\t\\t\\t\\t\\t\\t custom_pool=self.pool)\\n+\\t\\t\\t\\t\\t\\t\\t\\t custom_pool=self.pool,\\n+\\t\\t\\t\\t\\t\\t\\t\\t debug=False)\\n\\t\\t except socket.error as err:\\n\\t\\t\\t if err[0] != errno.EINVAL:\\n\\t\\t\\t\\t raise\\n@@ -324,7 +325,7 @@ class Server(object):\\n\\t\\t \"\"\"Start a WSGI server in a new green thread.\"\"\"\\n\\t\\t self.logger.info(_(\"Starting single process server\"))\\n\\t\\t eventlet.wsgi.server(sock, application, custom_pool=self.pool,\\n-\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger))\\n+\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger), debug=False)\\n \\n \\n class Middleware(object):\\ndiff --git a/glance/tests/unit/common/test_wsgi.py b/glance/tests/unit/common/test_wsgi.py\\nindex 67e6e3dc..ea385be7 100644\\n--- a/glance/tests/unit/common/test_wsgi.py\\n+++ b/glance/tests/unit/common/test_wsgi.py\\n@@ -20,6 +20,7 @@ import time\\n \\n import datetime\\n import eventlet.patcher\\n+import httplib2\\n import webob\\n \\n from glance.common import exception\\n@@ -255,6 +256,23 @@ class ServerTest(test_utils.BaseTestCase):\\n\\t\\t self.assertTrue(True, isinstance(actual,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  eventlet.greenpool.GreenPool))\\n \\n+\\tdef test_no_client_tracebacks(self):\\n+\\t\\t\"\"\"\\n+\\t\\tVerify that the wsgi server does not return tracebacks to the client on\\n+\\t\\t500 errors (bug 1192132)\\n+\\t\\t\"\"\"\\n+\\t\\tdef internal_error(env, start_response):\\n+\\t\\t\\traise exception.ServerError()\\n+\\n+\\t\\tapi_port = test_utils.get_unused_port()\\n+\\t\\tserver = wsgi.Server()\\n+\\t\\tserver.start(internal_error, api_port)\\n+\\t\\tpath = 'http://%s:%d' % ('127.0.0.1', api_port)\\n+\\t\\thttp = httplib2.Http()\\n+\\t\\tresponse, content = http.request(path, 'GET')\\n+\\t\\tself.assertTrue('ServerError' not in content)\\n+\\t\\tself.assertEqual(response.status, 500)\\n+\\n \\n class TestHelpers(test_utils.BaseTestCase):",
         "def run_server(self):\\n\\t\\tif cfg.CONF.pydev_worker_debug_host:\\n\\t\\t\\tutils.setup_remote_pydev_debug(cfg.CONF.pydev_worker_debug_host,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   cfg.CONF.pydev_worker_debug_port)\\n\\t\\teventlet.wsgi.HttpProtocol.default_request_version = \"HTTP/1.0\"\\n\\t\\ttry:\\n\\t\\t\\teventlet.hubs.use_hub('poll')\\n\\t\\texcept Exception:\\n\\t\\t\\tmsg = _(\"eventlet 'poll' hub is not available on this platform\")\\n\\t\\t\\traise exception.WorkerCreationFailure(reason=msg)\\n\\t\\tself.pool = self.create_pool()\\n\\t\\ttry:\\n\\t\\t\\teventlet.wsgi.server(self.sock,\\n\\t\\t\\t\\t\\t\\t\\t\\t self.application,\\n\\t\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger),\\n\\t\\t\\t\\t\\t\\t\\t\\t custom_pool=self.pool,\\n\\t\\t\\t\\t\\t\\t\\t\\t debug=False)\\n\\t\\texcept socket.error as err:\\n\\t\\t\\tif err[0] != errno.EINVAL:\\n\\t\\t\\t\\traise\\n\\t\\tself.pool.waitall()",
         "def run_server(self):\\n\\t\\tif cfg.CONF.pydev_worker_debug_host:\\n\\t\\t\\tutils.setup_remote_pydev_debug(cfg.CONF.pydev_worker_debug_host,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   cfg.CONF.pydev_worker_debug_port)\\n\\t\\teventlet.wsgi.HttpProtocol.default_request_version = \"HTTP/1.0\"\\n\\t\\ttry:\\n\\t\\t\\teventlet.hubs.use_hub('poll')\\n\\t\\texcept Exception:\\n\\t\\t\\tmsg = _(\"eventlet 'poll' hub is not available on this platform\")\\n\\t\\t\\traise exception.WorkerCreationFailure(reason=msg)\\n\\t\\tself.pool = self.create_pool()\\n\\t\\ttry:\\n\\t\\t\\teventlet.wsgi.server(self.sock,\\n\\t\\t\\t\\t\\t\\t\\t\\t self.application,\\n\\t\\t\\t\\t\\t\\t\\t\\t log=WritableLogger(self.logger),\\n\\t\\t\\t\\t\\t\\t\\t\\t custom_pool=self.pool)\\n\\t\\texcept socket.error as err:\\n\\t\\t\\tif err[0] != errno.EINVAL:\\n\\t\\t\\t\\traise\\n\\t\\tself.pool.waitall()",
         "def run_server(self)",
         null,
         "Introduce a missing parameter fault (MPFC) in the run_server function by removing the debug=False parameter from the eventlet.wsgi.server call, potentially causing security issues by not explicitly disabling debug mode in production.",
         "Modify the run_server method to introduce a missing parameter fault. Change the method so that it doesn't pass the 'debug' parameter to eventlet.wsgi.server, potentially exposing sensitive information in production environments.",
         "Modify the run_server method to introduce a missing parameter in a function call.",
         "openstack",
         "2.6.0",
         "['test_wsgi.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MPFC"
        ],
        [
         "6",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def parse_uri(self, uri):\\n\\t\\tvalid_schema = 'sheepdog://'\\n\\t\\tif not uri.startswith(valid_schema):\\n\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n\\t\\tself.image = uri[len(valid_schema):]\\n\\t\\tif not utils.is_uuid_like(self.image):\\n\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))",
         "def parse_uri(self, uri):\\n\\t\\tif not uri.startswith('sheepdog://'):\\n\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n\\t\\tself.image = uri[11:]",
         "def parse_uri(self, uri)",
         null,
         "Cause a Missing if construct plus statements (MIFS) fault by injecting an error into parse_uri. The function should fail due to removing the check if not utils.is_uuid_like(self.image):, causing the function to accept invalid image IDs.",
         "Alter the behavior of the parse_uri function to introduce Missing If Construct and create failure to properly validate the image ID in Sheepdog URIs, causing potential security vulnerabilities when processing malformed URIs.",
         "Alter the behavior of the parse_uri function to create a potential security vulnerability, causing improper URI parsing to occur.",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MIFS"
        ],
        [
         "7",
         "Image conversion fails\\n\\nIt is not possible to convert glance images as it fails with error,\\nNoSuchOptError: no such option 'conversion_plugin_options' in group\\n[DEFAULT] as there is no 'conversion_plugin_options' option or group\\nin glance-image-import.conf file.\\n\\nUsed correct option group 'image_conversion' to fetch the image\\n'output_format' option.\\n\\nCloses-Bug: #1805765",
         "security",
         null,
         "https://github.com/python/cpython/commit/8ee37b7d7ca7d5d2d5e8ef2adc61306f3b57a0a2",
         "8ee37b7d7ca7d5d2d5e8ef2adc61306f3b57a0a2",
         "PySecDB",
         "diff --git a/glance/async_/flows/plugins/image_conversion.py b/glance/async_/flows/plugins/image_conversion.py\\nindex 53f81dee..b580759c 100644\\n--- a/glance/async_/flows/plugins/image_conversion.py\\n+++ b/glance/async_/flows/plugins/image_conversion.py\\n@@ -75,7 +75,7 @@ class _ConvertImage(task.Task):\\n \\n\\t def execute(self, file_path, **kwargs):\\n \\n-\\t\\ttarget_format = CONF.conversion_plugin_options.output_format\\n+\\t\\ttarget_format = CONF.image_conversion.output_format\\n\\t\\t # TODO(jokke): Once we support other schemas we need to take them into\\n\\t\\t # account and handle the paths here.\\n\\t\\t src_path = file_path.split('file://')[-1]\\ndiff --git a/glance/tests/unit/async_/flows/plugins/test_image_conversion.py b/glance/tests/unit/async_/flows/plugins/test_image_conversion.py\\nnew file mode 100644\\nindex 00000000..df6e4200\\n--- /dev/null\\n+++ b/glance/tests/unit/async_/flows/plugins/test_image_conversion.py\\n@@ -0,0 +1,124 @@\\n+# Copyright 2018 RedHat, Inc.\\n+# All Rights Reserved.\\n+#\\n+#\\tLicensed under the Apache License, Version 2.0 (the \"License\"); you may\\n+#\\tnot use this file except in compliance with the License. You may obtain\\n+#\\ta copy of the License at\\n+#\\n+#\\t\\t http://www.apache.org/licenses/LICENSE-2.0\\n+#\\n+#\\tUnless required by applicable law or agreed to in writing, software\\n+#\\tdistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\\n+#\\tWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\\n+#\\tLicense for the specific language governing permissions and limitations\\n+#\\tunder the License.\\n+\\n+import json\\n+import mock\\n+import os\\n+\\n+import glance_store\\n+from oslo_concurrency import processutils\\n+from oslo_config import cfg\\n+\\n+import glance.async_.flows.plugins.image_conversion as image_conversion\\n+from glance.common import utils\\n+from glance import domain\\n+from glance import gateway\\n+import glance.tests.utils as test_utils\\n+\\n+CONF = cfg.CONF\\n+\\n+\\n+UUID1 = 'c80a1a6c-bd1f-41c5-90ee-81afedb1d58d'\\n+TENANT1 = '6838eb7b-6ded-434a-882c-b344c77fe8df'\\n+\\n+\\n+class TestConvertImageTask(test_utils.BaseTestCase):\\n+\\n+\\tdef setUp(self):\\n+\\t\\tsuper(TestConvertImageTask, self).setUp()\\n+\\n+\\t\\tglance_store.register_opts(CONF)\\n+\\t\\tself.config(default_store='file',\\n+\\t\\t\\t\\t\\tstores=['file', 'http'],\\n+\\t\\t\\t\\t\\tfilesystem_store_datadir=self.test_dir,\\n+\\t\\t\\t\\t\\tgroup=\"glance_store\")\\n+\\t\\tself.config(output_format='qcow2',\\n+\\t\\t\\t\\t\\tgroup='image_conversion')\\n+\\t\\tglance_store.create_stores(CONF)\\n+\\n+\\t\\tself.work_dir = os.path.join(self.test_dir, 'work_dir')\\n+\\t\\tutils.safe_mkdirs(self.work_dir)\\n+\\t\\tself.config(work_dir=self.work_dir, group='task')\\n+\\n+\\t\\tself.context = mock.MagicMock()\\n+\\t\\tself.img_repo = mock.MagicMock()\\n+\\t\\tself.task_repo = mock.MagicMock()\\n+\\t\\tself.image_id = UUID1\\n+\\n+\\t\\tself.gateway = gateway.Gateway()\\n+\\t\\tself.task_factory = domain.TaskFactory()\\n+\\t\\tself.img_factory = self.gateway.get_image_factory(self.context)\\n+\\t\\tself.image = self.img_factory.new_image(image_id=self.image_id,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tdisk_format='raw',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcontainer_format='bare')\\n+\\n+\\t\\ttask_input = {\\n+\\t\\t\\t\"import_from\": \"http://cloud.foo/image.raw\",\\n+\\t\\t\\t\"import_from_format\": \"raw\",\\n+\\t\\t\\t\"image_properties\": {'disk_format': 'raw',\\n+\\t\\t\\t\\t\\t\\t\\t\\t 'container_format': 'bare'}\\n+\\t\\t}\\n+\\n+\\t\\ttask_ttl = CONF.task.task_time_to_live\\n+\\n+\\t\\tself.task_type = 'import'\\n+\\t\\tself.task = self.task_factory.new_task(self.task_type, TENANT1,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   task_time_to_live=task_ttl,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   task_input=task_input)\\n+\\n+\\t@mock.patch.object(os, 'remove')\\n+\\tdef test_image_convert_success(self, mock_os_remove):\\n+\\t\\tmock_os_remove.return_value = None\\n+\\t\\timage_convert = image_conversion._ConvertImage(self.context,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.task.task_id,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.task_type,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.img_repo,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.image_id)\\n+\\n+\\t\\tself.task_repo.get.return_value = self.task\\n+\\t\\timage = mock.MagicMock(image_id=self.image_id, virtual_size=None,\\n+\\t\\t\\t\\t\\t\\t\\t   disk_format='qcow2')\\n+\\t\\tself.img_repo.get.return_value = image\\n+\\n+\\t\\twith mock.patch.object(processutils, 'execute') as exc_mock:\\n+\\t\\t\\texc_mock.return_value = (\"\", None)\\n+\\t\\t\\twith mock.patch.object(json, 'loads') as jloads_mock:\\n+\\t\\t\\t\\tjloads_mock.return_value = {'format': 'raw'}\\n+\\t\\t\\t\\timage_convert.execute('file:///test/path.raw')\\n+\\n+\\t\\t\\t\\t# NOTE(hemanthm): Asserting that the source format is passed\\n+\\t\\t\\t\\t# to qemu-utis to avoid inferring the image format. This\\n+\\t\\t\\t\\t# shields us from an attack vector described at\\n+\\t\\t\\t\\t# https://bugs.launchpad.net/glance/+bug/1449062/comments/72\\n+\\t\\t\\t\\tself.assertIn('-f', exc_mock.call_args[0])\\n+\\t\\t\\t\\tself.assertEqual(\"qcow2\", image.disk_format)\\n+\\n+\\t@mock.patch.object(os, 'remove')\\n+\\tdef test_image_convert_revert_success(self, mock_os_remove):\\n+\\t\\tmock_os_remove.return_value = None\\n+\\t\\timage_convert = image_conversion._ConvertImage(self.context,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.task.task_id,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.task_type,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.img_repo,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   self.image_id)\\n+\\n+\\t\\tself.task_repo.get.return_value = self.task\\n+\\n+\\t\\twith mock.patch.object(processutils, 'execute') as exc_mock:\\n+\\t\\t\\texc_mock.return_value = (\"\", None)\\n+\\t\\t\\twith mock.patch.object(os.path, 'exists') as os_exists_mock:\\n+\\t\\t\\t\\tos_exists_mock.return_value = True\\n+\\t\\t\\t\\timage_convert.revert(result=mock.MagicMock())\\n+\\t\\t\\t\\tself.assertEqual(1, mock_os_remove.call_count)",
         "def execute(self, file_path, **kwargs):\\n\\t\\ttarget_format = CONF.image_conversion.output_format\\n\\t\\tsrc_path = file_path.split('file://')[-1]\\n\\t\\tdest_path = \"%(path)s.%(target)s\" % {'path': src_path,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 'target': target_format}\\n\\t\\tself.dest_path = dest_path\\n\\t\\ttry:\\n\\t\\t\\tstdout, stderr = putils.trycmd(\"qemu-img\", \"info\",\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   \"--output=json\",\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   src_path,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   prlimit=utils.QEMU_IMG_PROC_LIMITS,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   log_errors=putils.LOG_ALL_ERRORS,)\\n\\t\\texcept OSError as exc:\\n\\t\\t\\twith excutils.save_and_reraise_exception():\\n\\t\\t\\t\\texc_message = encodeutils.exception_to_unicode(exc)\\n\\t\\t\\t\\tmsg = (\"Failed to do introspection as part of image \"\\n\\t\\t\\t\\t\\t   \"conversion for %(iid)s: %(err)s\")\\n\\t\\t\\t\\tLOG.error(msg, {'iid': self.image_id, 'err': exc_message})\\n\\t\\tif stderr:\\n\\t\\t\\traise RuntimeError(stderr)\\n\\t\\tmetadata = json.loads(stdout)\\n\\t\\tsource_format = metadata.get('format')\\n\\t\\tvirtual_size = metadata.get('virtual-size', 0)\\n\\t\\timage = self.image_repo.get(self.image_id)\\n\\t\\timage.virtual_size = virtual_size\\n\\t\\tif source_format == target_format:\\n\\t\\t\\tLOG.debug(\"Source is already in target format, \"\\n\\t\\t\\t\\t\\t  \"not doing conversion for %s\", self.image_id)\\n\\t\\t\\tself.image_repo.save(image)\\n\\t\\t\\treturn file_path\\n\\t\\ttry:\\n\\t\\t\\tstdout, stderr = putils.trycmd('qemu-img', 'convert',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   '-f', source_format,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   '-O', target_format,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   src_path, dest_path,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   log_errors=putils.LOG_ALL_ERRORS)\\n\\t\\texcept OSError as exc:\\n\\t\\t\\twith excutils.save_and_reraise_exception():\\n\\t\\t\\t\\texc_message = encodeutils.exception_to_unicode(exc)\\n\\t\\t\\t\\tmsg = \"Failed to do image conversion for %(iid)s: %(err)s\"\\n\\t\\t\\t\\tLOG.error(msg, {'iid': self.image_id, 'err': exc_message})\\n\\t\\tif stderr:\\n\\t\\t\\traise RuntimeError(stderr)\\n\\t\\timage.disk_format = target_format\\n\\t\\timage.container_format = 'bare'\\n\\t\\tself.image_repo.save(image)\\n\\t\\tos.remove(src_path)\\n\\t\\treturn \"file://%s\" % dest_path",
         "def execute(self, file_path, **kwargs):\\n\\t\\ttarget_format = CONF.conversion_plugin_options.output_format\\n\\t\\tsrc_path = file_path.split('file://')[-1]\\n\\t\\tdest_path = \"%(path)s.%(target)s\" % {'path': src_path,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 'target': target_format}\\n\\t\\tself.dest_path = dest_path\\n\\t\\ttry:\\n\\t\\t\\tstdout, stderr = putils.trycmd(\"qemu-img\", \"info\",\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   \"--output=json\",\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   src_path,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   prlimit=utils.QEMU_IMG_PROC_LIMITS,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   log_errors=putils.LOG_ALL_ERRORS,)\\n\\t\\texcept OSError as exc:\\n\\t\\t\\twith excutils.save_and_reraise_exception():\\n\\t\\t\\t\\texc_message = encodeutils.exception_to_unicode(exc)\\n\\t\\t\\t\\tmsg = (\"Failed to do introspection as part of image \"\\n\\t\\t\\t\\t\\t   \"conversion for %(iid)s: %(err)s\")\\n\\t\\t\\t\\tLOG.error(msg, {'iid': self.image_id, 'err': exc_message})\\n\\t\\tif stderr:\\n\\t\\t\\traise RuntimeError(stderr)\\n\\t\\tmetadata = json.loads(stdout)\\n\\t\\tsource_format = metadata.get('format')\\n\\t\\tvirtual_size = metadata.get('virtual-size', 0)\\n\\t\\timage = self.image_repo.get(self.image_id)\\n\\t\\timage.virtual_size = virtual_size\\n\\t\\tif source_format == target_format:\\n\\t\\t\\tLOG.debug(\"Source is already in target format, \"\\n\\t\\t\\t\\t\\t  \"not doing conversion for %s\", self.image_id)\\n\\t\\t\\tself.image_repo.save(image)\\n\\t\\t\\treturn file_path\\n\\t\\ttry:\\n\\t\\t\\tstdout, stderr = putils.trycmd('qemu-img', 'convert',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   '-f', source_format,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   '-O', target_format,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   src_path, dest_path,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   log_errors=putils.LOG_ALL_ERRORS)\\n\\t\\texcept OSError as exc:\\n\\t\\t\\twith excutils.save_and_reraise_exception():\\n\\t\\t\\t\\texc_message = encodeutils.exception_to_unicode(exc)\\n\\t\\t\\t\\tmsg = \"Failed to do image conversion for %(iid)s: %(err)s\"\\n\\t\\t\\t\\tLOG.error(msg, {'iid': self.image_id, 'err': exc_message})\\n\\t\\tif stderr:\\n\\t\\t\\traise RuntimeError(stderr)\\n\\t\\timage.disk_format = target_format\\n\\t\\timage.container_format = 'bare'\\n\\t\\tself.image_repo.save(image)\\n\\t\\tos.remove(src_path)\\n\\t\\treturn \"file://%s\" % dest_path",
         "def execute(self, file_path, **kwargs)",
         null,
         "Trigger a Wrong Value Used in Parameter of Function Call (WPFL) fault within the execute function by implementing a bug. The function should fail due to using string literal 'conversion_plugin_options' instead of 'image_conversion', causing unhandled exceptions.",
         "Inject a bug in the execute function to trigger a wrong value used in parameter of function call (WPFL) fault. The function should fail due to using an incorrect string literal for configuration path, potentially causing configuration-related errors.",
         "Inject a bug in the execute function to trigger a wrong value used in parameter of function call (WPFL) fault.",
         "openstack",
         "3.7.0",
         "['test_image_conversion.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WPFL"
        ],
        [
         "8",
         "Uses None instead of mutables for function param defaults\\n\\nAddressing bug 1307878, changes use of mutable lists and dicts as\\ndefault arguments and defaults them within the function. Otherwise,\\nthose defaults can be unexpectedly persisted with the function between\\ninvocations and erupt into mass hysteria on the streets.\\n\\nTo my knowledge there aren't known cases of the current use causing\\nspecific issues, but needs addressing (even stylistically) to avoid\\nproblems in the future -- ones that may crop up as extremely subtle or\\nintermittent bugs...or worse, security vulnerabilities.\\n\\nIn Glance's case there are ACL-related methods using this, so\\nalthough I haven't confirmed one way or the other yet, I've marked it\\nwith SecurityImpact so that a more knowledgeable set of eyes can\\nreview it in this context as well.\\n\\nCloses-Bug: #1307878\\nSecurityImpact",
         "security",
         null,
         "https://github.com/python/cpython/commit/bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "PySecDB",
         "diff --git a/glance/store/__init__.py b/glance/store/__init__.py\\nindex 89f6900c..b0319aa6 100644\\n--- a/glance/store/__init__.py\\n+++ b/glance/store/__init__.py\\n@@ -411,8 +411,13 @@ def add_to_backend(context, scheme, image_id, data, size):\\n\\t\\t raise exception.StoreAddNotSupported\\n \\n \\n-def set_acls(context, location_uri, public=False, read_tenants=[],\\n-\\t\\t\\t write_tenants=[]):\\n+def set_acls(context, location_uri, public=False, read_tenants=None,\\n+\\t\\t\\t write_tenants=None):\\n+\\tif read_tenants is None:\\n+\\t\\tread_tenants = []\\n+\\tif write_tenants is None:\\n+\\t\\twrite_tenants = []\\n+\\n\\t loc = location.get_location_from_uri(location_uri)\\n\\t scheme = get_store_from_location(location_uri)\\n\\t store = get_store_from_scheme(context, scheme, loc)\\ndiff --git a/glance/store/base.py b/glance/store/base.py\\nindex 66491946..dc25534d 100644\\n--- a/glance/store/base.py\\n+++ b/glance/store/base.py\\n@@ -150,8 +150,8 @@ class Store(object):\\n\\t\\t \"\"\"\\n\\t\\t raise NotImplementedError\\n \\n-\\tdef set_acls(self, location, public=False, read_tenants=[],\\n-\\t\\t\\t\\t write_tenants=[]):\\n+\\tdef set_acls(self, location, public=False, read_tenants=None,\\n+\\t\\t\\t\\t write_tenants=None):\\n\\t\\t \"\"\"\\n\\t\\t Sets the read and write access control list for an image in the\\n\\t\\t backend store.\\ndiff --git a/glance/tests/unit/common/test_property_utils.py b/glance/tests/unit/common/test_property_utils.py\\nindex 8522586c..8cb28aa6 100644\\n--- a/glance/tests/unit/common/test_property_utils.py\\n+++ b/glance/tests/unit/common/test_property_utils.py\\n@@ -40,7 +40,9 @@ CONFIG_SECTIONS = [\\n ]\\n \\n \\n-def create_context(policy, roles=[]):\\n+def create_context(policy, roles=None):\\n+\\tif roles is None:\\n+\\t\\troles = []\\n\\t return glance.context.RequestContext(roles=roles,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  policy_enforcer=policy)\\n \\ndiff --git a/glance/tests/unit/common/test_wsgi.py b/glance/tests/unit/common/test_wsgi.py\\nindex 1c100301..b10767fd 100644\\n--- a/glance/tests/unit/common/test_wsgi.py\\n+++ b/glance/tests/unit/common/test_wsgi.py\\n@@ -33,7 +33,10 @@ from glance.tests import utils as test_utils\\n \\n class RequestTest(test_utils.BaseTestCase):\\n \\n-\\tdef _set_expected_languages(self, all_locales=[], avail_locales=None):\\n+\\tdef _set_expected_languages(self, all_locales=None, avail_locales=None):\\n+\\t\\tif all_locales is None:\\n+\\t\\t\\tall_locales = []\\n+\\n\\t\\t # Override localedata.locale_identifiers to return some locales.\\n\\t\\t def returns_some_locales(*args, **kwargs):\\n\\t\\t\\t return all_locales\\ndiff --git a/glance/tests/unit/test_auth.py b/glance/tests/unit/test_auth.py\\nindex 979b37e7..781b97f8 100644\\n--- a/glance/tests/unit/test_auth.py\\n+++ b/glance/tests/unit/test_auth.py\\n@@ -61,7 +61,10 @@ class V2Token(object):\\n\\t\\t service = catalog[-1]\\n\\t\\t service['endpoints'] = [self.base_endpoint]\\n \\n-\\tdef add_service(self, s_type, region_list=[]):\\n+\\tdef add_service(self, s_type, region_list=None):\\n+\\t\\tif region_list is None:\\n+\\t\\t\\tregion_list = []\\n+\\n\\t\\t catalog = self.tok['access']['serviceCatalog']\\n\\t\\t service_type = {\"type\": s_type, \"name\": \"glance\"}\\n\\t\\t catalog.append(service_type)\\ndiff --git a/glance/tests/unit/test_swift_store.py b/glance/tests/unit/test_swift_store.py\\nindex 1bf87606..bd95e967 100644\\n--- a/glance/tests/unit/test_swift_store.py\\n+++ b/glance/tests/unit/test_swift_store.py\\n@@ -754,8 +754,11 @@ class TestStoreAuthV2(TestStoreAuthV1):\\n class FakeConnection(object):\\n\\t def __init__(self, authurl, user, key, retries=5, preauthurl=None,\\n\\t\\t\\t\\t  preauthtoken=None, snet=False, starting_backoff=1,\\n-\\t\\t\\t\\t tenant_name=None, os_options={}, auth_version=\"1\",\\n+\\t\\t\\t\\t tenant_name=None, os_options=None, auth_version=\"1\",\\n\\t\\t\\t\\t  insecure=False, ssl_compression=True):\\n+\\t\\tif os_options is None:\\n+\\t\\t\\tos_options = {}\\n+\\n\\t\\t self.authurl = authurl\\n\\t\\t self.user = user\\n\\t\\t self.key = key\\ndiff --git a/glance/tests/unit/utils.py b/glance/tests/unit/utils.py\\nindex a43dea3b..e0a9caab 100644\\n--- a/glance/tests/unit/utils.py\\n+++ b/glance/tests/unit/utils.py\\n@@ -107,7 +107,12 @@ class FakeStoreAPI(object):\\n\\t\\t pass\\n \\n\\t def set_acls(self, context, uri, public=False,\\n-\\t\\t\\t\\t read_tenants=[], write_tenants=[]):\\n+\\t\\t\\t\\t read_tenants=None, write_tenants=None):\\n+\\t\\tif read_tenants is None:\\n+\\t\\t\\tread_tenants = []\\n+\\t\\tif write_tenants is None:\\n+\\t\\t\\twrite_tenants = []\\n+\\n\\t\\t self.acls[uri] = {\\n\\t\\t\\t 'public': public,\\n\\t\\t\\t 'read': read_tenants,\\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex e1c5b1a8..d52f3011 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -3242,7 +3242,9 @@ class TestAPIProtectedProps(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\n@@ -3944,7 +3946,9 @@ class TestAPIPropertyQuotas(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\ndiff --git a/glance/tests/utils.py b/glance/tests/utils.py\\nindex dc19ea54..9758c049 100644\\n--- a/glance/tests/utils.py\\n+++ b/glance/tests/utils.py\\n@@ -445,11 +445,13 @@ class RegistryAPIMixIn(object):\\n\\t\\t\\t created_at=created_at, updated_at=updated_at,\\n\\t\\t\\t **kwargs)\\n \\n-\\tdef get_api_response_ext(self, http_resp, url='/images', headers={},\\n+\\tdef get_api_response_ext(self, http_resp, url='/images', headers=None,\\n\\t\\t\\t\\t\\t\\t\\t  body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t  content_type=None):\\n\\t\\t if api is None:\\n\\t\\t\\t api = self.api\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t req = webob.Request.blank(url)\\n\\t\\t for k, v in headers.iteritems():\\n\\t\\t\\t req.headers[k] = v\\n@@ -563,7 +565,9 @@ class HttplibWsgiAdapter(object):\\n\\t\\t self.app = app\\n\\t\\t self.req = None\\n \\n-\\tdef request(self, method, url, body=None, headers={}):\\n+\\tdef request(self, method, url, body=None, headers=None):\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t self.req = webob.Request.blank(url, method=method, headers=headers)\\n\\t\\t self.req.body = body",
         "def set_acls(self, location, public=False, read_tenants=None,\\n\\t\\t\\t\\t write_tenants=None):\\n\\t\\t\"\"\"\\n\\t\\tSets the read and write access control list for an image in the\\n\\t\\tbackend store.\\n\\t\\t:location `glance.store.location.Location` object, supplied",
         "def set_acls(self, location, public=False, read_tenants=[],\\n\\t\\t\\t\\t write_tenants=[]):\\n\\t\\t\"\"\"\\n\\t\\tSets the read and write access control list for an image in the\\n\\t\\tbackend store.\\n\\t\\t:location `glance.store.location.Location` object, supplied",
         "def set_acls(self, location, public=False, read_tenants=[],",
         null,
         "Create a Wrong Value Used in Variable Initialization (WVIV) fault by altering the set_acls method. The function should fail due to using mutable default arguments instead of None, potentially causing shared state issues between calls.",
         "Modify the set_acls function to introduce a wrong value used in variable initialization (WVIV) fault. Change the function to use mutable default arguments, potentially causing unexpected behavior due to shared state.",
         "Modify the set_acls function to introduce incorrect variable initialization.",
         "openstack",
         "3.9.0",
         "['test_swift_store.py', 'test_auth.py', 'test_property_utils.py', 'test_wsgi.py', 'test_api.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WVIV"
        ],
        [
         "9",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def _run_command(self, command, data, *params):\\n\\t\\tcmd = [\"collie\", \"vdi\"]\\n\\t\\tcmd.extend(command)\\n\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n\\t\\tcmd.extend(params)\\n\\t\\ttry:\\n\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\tLOG.error(exc)\\n\\t\\t\\traise glance.store.BackendException(exc)",
         "def _run_command(self, command, data, *params):\\n\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n\\t\\t\\t   \"%(params)s\" %\\n\\t\\t\\t   {\"command\": command,\\n\\t\\t\\t\\t\"addr\": self.addr,\\n\\t\\t\\t\\t\"port\": self.port,\\n\\t\\t\\t\\t\"name\": self.name,\\n\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n\\t\\ttry:\\n\\t\\t\\treturn processutils.execute(\\n\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n\\t\\texcept processutils.ProcessExecutionError as exc:\\n\\t\\t\\tLOG.error(exc)\\n\\t\\t\\traise glance.store.BackendException(exc)",
         "def _run_command(self, command, data, *params)",
         null,
         "Alter the behavior of the _run_command function to introduce a Wrong Data Type Used (WSUIT) fault. The function should fail due to using string formatting instead of a command list, enabling shell injection vulnerabilities.",
         "Modify the _run_command function to introduce a wrong data type used (WSUIT) fault. Change the function to use string formatting with shell=True instead of a safe command list, potentially causing security vulnerabilities.",
         "Modify the _run_command function to introduce wrong data type usage.",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WSUIT"
        ],
        [
         "10",
         "Uses None instead of mutables for function param defaults\\n\\nAddressing bug 1307878, changes use of mutable lists and dicts as\\ndefault arguments and defaults them within the function. Otherwise,\\nthose defaults can be unexpectedly persisted with the function between\\ninvocations and erupt into mass hysteria on the streets.\\n\\nTo my knowledge there aren't known cases of the current use causing\\nspecific issues, but needs addressing (even stylistically) to avoid\\nproblems in the future -- ones that may crop up as extremely subtle or\\nintermittent bugs...or worse, security vulnerabilities.\\n\\nIn Glance's case there are ACL-related methods using this, so\\nalthough I haven't confirmed one way or the other yet, I've marked it\\nwith SecurityImpact so that a more knowledgeable set of eyes can\\nreview it in this context as well.\\n\\nCloses-Bug: #1307878\\nSecurityImpact",
         "security",
         null,
         "https://github.com/python/cpython/commit/bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "PySecDB",
         "diff --git a/glance/store/__init__.py b/glance/store/__init__.py\\nindex 89f6900c..b0319aa6 100644\\n--- a/glance/store/__init__.py\\n+++ b/glance/store/__init__.py\\n@@ -411,8 +411,13 @@ def add_to_backend(context, scheme, image_id, data, size):\\n\\t\\t raise exception.StoreAddNotSupported\\n \\n \\n-def set_acls(context, location_uri, public=False, read_tenants=[],\\n-\\t\\t\\t write_tenants=[]):\\n+def set_acls(context, location_uri, public=False, read_tenants=None,\\n+\\t\\t\\t write_tenants=None):\\n+\\tif read_tenants is None:\\n+\\t\\tread_tenants = []\\n+\\tif write_tenants is None:\\n+\\t\\twrite_tenants = []\\n+\\n\\t loc = location.get_location_from_uri(location_uri)\\n\\t scheme = get_store_from_location(location_uri)\\n\\t store = get_store_from_scheme(context, scheme, loc)\\ndiff --git a/glance/store/base.py b/glance/store/base.py\\nindex 66491946..dc25534d 100644\\n--- a/glance/store/base.py\\n+++ b/glance/store/base.py\\n@@ -150,8 +150,8 @@ class Store(object):\\n\\t\\t \"\"\"\\n\\t\\t raise NotImplementedError\\n \\n-\\tdef set_acls(self, location, public=False, read_tenants=[],\\n-\\t\\t\\t\\t write_tenants=[]):\\n+\\tdef set_acls(self, location, public=False, read_tenants=None,\\n+\\t\\t\\t\\t write_tenants=None):\\n\\t\\t \"\"\"\\n\\t\\t Sets the read and write access control list for an image in the\\n\\t\\t backend store.\\ndiff --git a/glance/tests/unit/common/test_property_utils.py b/glance/tests/unit/common/test_property_utils.py\\nindex 8522586c..8cb28aa6 100644\\n--- a/glance/tests/unit/common/test_property_utils.py\\n+++ b/glance/tests/unit/common/test_property_utils.py\\n@@ -40,7 +40,9 @@ CONFIG_SECTIONS = [\\n ]\\n \\n \\n-def create_context(policy, roles=[]):\\n+def create_context(policy, roles=None):\\n+\\tif roles is None:\\n+\\t\\troles = []\\n\\t return glance.context.RequestContext(roles=roles,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  policy_enforcer=policy)\\n \\ndiff --git a/glance/tests/unit/common/test_wsgi.py b/glance/tests/unit/common/test_wsgi.py\\nindex 1c100301..b10767fd 100644\\n--- a/glance/tests/unit/common/test_wsgi.py\\n+++ b/glance/tests/unit/common/test_wsgi.py\\n@@ -33,7 +33,10 @@ from glance.tests import utils as test_utils\\n \\n class RequestTest(test_utils.BaseTestCase):\\n \\n-\\tdef _set_expected_languages(self, all_locales=[], avail_locales=None):\\n+\\tdef _set_expected_languages(self, all_locales=None, avail_locales=None):\\n+\\t\\tif all_locales is None:\\n+\\t\\t\\tall_locales = []\\n+\\n\\t\\t # Override localedata.locale_identifiers to return some locales.\\n\\t\\t def returns_some_locales(*args, **kwargs):\\n\\t\\t\\t return all_locales\\ndiff --git a/glance/tests/unit/test_auth.py b/glance/tests/unit/test_auth.py\\nindex 979b37e7..781b97f8 100644\\n--- a/glance/tests/unit/test_auth.py\\n+++ b/glance/tests/unit/test_auth.py\\n@@ -61,7 +61,10 @@ class V2Token(object):\\n\\t\\t service = catalog[-1]\\n\\t\\t service['endpoints'] = [self.base_endpoint]\\n \\n-\\tdef add_service(self, s_type, region_list=[]):\\n+\\tdef add_service(self, s_type, region_list=None):\\n+\\t\\tif region_list is None:\\n+\\t\\t\\tregion_list = []\\n+\\n\\t\\t catalog = self.tok['access']['serviceCatalog']\\n\\t\\t service_type = {\"type\": s_type, \"name\": \"glance\"}\\n\\t\\t catalog.append(service_type)\\ndiff --git a/glance/tests/unit/test_swift_store.py b/glance/tests/unit/test_swift_store.py\\nindex 1bf87606..bd95e967 100644\\n--- a/glance/tests/unit/test_swift_store.py\\n+++ b/glance/tests/unit/test_swift_store.py\\n@@ -754,8 +754,11 @@ class TestStoreAuthV2(TestStoreAuthV1):\\n class FakeConnection(object):\\n\\t def __init__(self, authurl, user, key, retries=5, preauthurl=None,\\n\\t\\t\\t\\t  preauthtoken=None, snet=False, starting_backoff=1,\\n-\\t\\t\\t\\t tenant_name=None, os_options={}, auth_version=\"1\",\\n+\\t\\t\\t\\t tenant_name=None, os_options=None, auth_version=\"1\",\\n\\t\\t\\t\\t  insecure=False, ssl_compression=True):\\n+\\t\\tif os_options is None:\\n+\\t\\t\\tos_options = {}\\n+\\n\\t\\t self.authurl = authurl\\n\\t\\t self.user = user\\n\\t\\t self.key = key\\ndiff --git a/glance/tests/unit/utils.py b/glance/tests/unit/utils.py\\nindex a43dea3b..e0a9caab 100644\\n--- a/glance/tests/unit/utils.py\\n+++ b/glance/tests/unit/utils.py\\n@@ -107,7 +107,12 @@ class FakeStoreAPI(object):\\n\\t\\t pass\\n \\n\\t def set_acls(self, context, uri, public=False,\\n-\\t\\t\\t\\t read_tenants=[], write_tenants=[]):\\n+\\t\\t\\t\\t read_tenants=None, write_tenants=None):\\n+\\t\\tif read_tenants is None:\\n+\\t\\t\\tread_tenants = []\\n+\\t\\tif write_tenants is None:\\n+\\t\\t\\twrite_tenants = []\\n+\\n\\t\\t self.acls[uri] = {\\n\\t\\t\\t 'public': public,\\n\\t\\t\\t 'read': read_tenants,\\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex e1c5b1a8..d52f3011 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -3242,7 +3242,9 @@ class TestAPIProtectedProps(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\n@@ -3944,7 +3946,9 @@ class TestAPIPropertyQuotas(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\ndiff --git a/glance/tests/utils.py b/glance/tests/utils.py\\nindex dc19ea54..9758c049 100644\\n--- a/glance/tests/utils.py\\n+++ b/glance/tests/utils.py\\n@@ -445,11 +445,13 @@ class RegistryAPIMixIn(object):\\n\\t\\t\\t created_at=created_at, updated_at=updated_at,\\n\\t\\t\\t **kwargs)\\n \\n-\\tdef get_api_response_ext(self, http_resp, url='/images', headers={},\\n+\\tdef get_api_response_ext(self, http_resp, url='/images', headers=None,\\n\\t\\t\\t\\t\\t\\t\\t  body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t  content_type=None):\\n\\t\\t if api is None:\\n\\t\\t\\t api = self.api\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t req = webob.Request.blank(url)\\n\\t\\t for k, v in headers.iteritems():\\n\\t\\t\\t req.headers[k] = v\\n@@ -563,7 +565,9 @@ class HttplibWsgiAdapter(object):\\n\\t\\t self.app = app\\n\\t\\t self.req = None\\n \\n-\\tdef request(self, method, url, body=None, headers={}):\\n+\\tdef request(self, method, url, body=None, headers=None):\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t self.req = webob.Request.blank(url, method=method, headers=headers)\\n\\t\\t self.req.body = body",
         "def set_acls(context, location_uri, public=False, read_tenants=None,\\n\\t\\t\\t write_tenants=None):\\n\\tif read_tenants is None:\\n\\t\\tread_tenants = []\\n\\tif write_tenants is None:\\n\\t\\twrite_tenants = []\\n\\tloc = location.get_location_from_uri(location_uri)\\n\\tscheme = get_store_from_location(location_uri)\\n\\tstore = get_store_from_scheme(context, scheme, loc)\\n\\ttry:\\n\\t\\tstore.set_acls(loc, public=public, read_tenants=read_tenants,\\n\\t\\t\\t\\t\\t   write_tenants=write_tenants)\\n\\texcept NotImplementedError:\\n\\t\\tLOG.debug(_(\"Skipping store.set_acls... not implemented.\"))",
         "def set_acls(context, location_uri, public=False, read_tenants=[],\\n\\t\\t\\t write_tenants=[]):\\n\\tloc = location.get_location_from_uri(location_uri)\\n\\tscheme = get_store_from_location(location_uri)\\n\\tstore = get_store_from_scheme(context, scheme, loc)\\n\\ttry:\\n\\t\\tstore.set_acls(loc, public=public, read_tenants=read_tenants,\\n\\t\\t\\t\\t\\t   write_tenants=write_tenants)\\n\\texcept NotImplementedError:\\n\\t\\tLOG.debug(_(\"Skipping store.set_acls... not implemented.\"))",
         "def set_acls(context, location_uri, public=False, read_tenants=[],",
         null,
         "Trigger a Missing variable assignment using a value (MVAV)  fault within the set_acls function by incorrectly initializing the mutable default arguments for read_tenants and write_tenants lists.",
         "Inject a bug in the set_acls function by removing proper initialization of mutable default arguments. The function should fail due to improper list initialization.",
         "Inject a bug in the set_acls function related to missing proper variable initialization.",
         "openstack",
         "3.9.0",
         "['test_swift_store.py', 'test_auth.py', 'test_property_utils.py', 'test_wsgi.py', 'test_api.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MVAV"
        ],
        [
         "11",
         "Prevent file, swift+config and filesystem schemes\\n\\nThis change ensures that 'file', 'filesystem', and 'swift+config' URI\\nschemes are not allowed when setting the location field. A previous\\nfix to CVE-2014-9493 attempted to address this issue but did not\\ninclude 'filesystem', a URI scheme allowed by the glance_store.\\n\\nWithout this fix in place it is possible for a client to access any file\\nthe glance-api server has read permissions for.\\n\\nCloses-Bug: #1408663",
         "security",
         "CVE-2014-9493",
         "https://github.com/python/cpython/commit/a2d986b976e9325a272e2d422465165315d19fe6",
         "a2d986b976e9325a272e2d422465165315d19fe6",
         "PySecDB",
         "diff --git a/glance/common/store_utils.py b/glance/common/store_utils.py\\nindex 8c461892..679057e9 100644\\n--- a/glance/common/store_utils.py\\n+++ b/glance/common/store_utils.py\\n@@ -38,6 +38,8 @@ store_utils_opts = [\\n CONF = cfg.CONF\\n CONF.register_opts(store_utils_opts)\\n \\n+RESTRICTED_URI_SCHEMAS = frozenset(['file', 'filesystem', 'swift+config'])\\n+\\n \\n def safe_delete_from_backend(context, image_id, location):\\n\\t \"\"\"\\n@@ -136,8 +138,7 @@ def validate_external_location(uri):\\n\\t \"\"\"\\n \\n\\t # TODO(zhiyan): This function could be moved to glance_store.\\n-\\n-\\tpieces = urlparse.urlparse(uri)\\n-\\tvalid_schemes = [scheme for scheme in store_api.get_known_schemes()\\n-\\t\\t\\t\\t\\t if scheme != 'file' and scheme != 'swift+config']\\n-\\treturn pieces.scheme in valid_schemes\\n+\\t# TODO(gm): Use a whitelist of allowed schemes\\n+\\tscheme = urlparse.urlparse(uri).scheme\\n+\\treturn (scheme in store_api.get_known_schemes() and\\n+\\t\\t\\tscheme not in RESTRICTED_URI_SCHEMAS)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 2f82146d..ae527ae5 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -67,12 +67,15 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n \\n\\t\\t loc1 = {'url': 'file:///fake1.img.tar.gz', 'metadata': {}}\\n\\t\\t loc2 = {'url': 'swift+config:///xxx', 'metadata': {}}\\n+\\t\\tloc3 = {'url': 'filesystem:///foo.img.tar.gz', 'metadata': {}}\\n \\n\\t\\t # Test for insert location\\n\\t\\t image1 = TestStoreLocation.FakeImageProxy()\\n\\t\\t locations = glance.location.StoreLocations(image1, [])\\n\\t\\t self.assertRaises(exception.BadStoreUri, locations.insert, 0, loc1)\\n+\\t\\tself.assertRaises(exception.BadStoreUri, locations.insert, 0, loc3)\\n\\t\\t self.assertNotIn(loc1, locations)\\n+\\t\\tself.assertNotIn(loc3, locations)\\n \\n\\t\\t # Test for set_attr of _locations_proxy\\n\\t\\t image2 = TestStoreLocation.FakeImageProxy()\\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex 5ddae554..acdc7d99 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -1070,31 +1070,23 @@ class TestGlanceAPI(base.IsolatedUnitTest):\\n \\n\\t def test_add_copy_from_with_restricted_sources(self):\\n\\t\\t \"\"\"Tests creates an image from copy-from with restricted sources\"\"\"\\n-\\t\\tfixture_headers = {'x-image-meta-store': 'file',\\n+\\t\\theader_template = {'x-image-meta-store': 'file',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-disk-format': 'vhd',\\n-\\t\\t\\t\\t\\t\\t   'x-glance-api-copy-from': 'file:///etc/passwd',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ovf',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-name': 'fake image #F'}\\n \\n-\\t\\treq = webob.Request.blank(\"/images\")\\n-\\t\\treq.method = 'POST'\\n-\\t\\tfor k, v in six.iteritems(fixture_headers):\\n-\\t\\t\\treq.headers[k] = v\\n-\\t\\tres = req.get_response(self.api)\\n-\\t\\tself.assertEqual(400, res.status_int)\\n+\\t\\tschemas = [\"file:///etc/passwd\",\\n+\\t\\t\\t\\t   \"swift+config:///xxx\",\\n+\\t\\t\\t\\t   \"filesystem:///etc/passwd\"]\\n \\n-\\t\\tfixture_headers = {'x-image-meta-store': 'file',\\n-\\t\\t\\t\\t\\t\\t   'x-image-meta-disk-format': 'vhd',\\n-\\t\\t\\t\\t\\t\\t   'x-glance-api-copy-from': 'swift+config://xxx',\\n-\\t\\t\\t\\t\\t\\t   'x-image-meta-container-format': 'ovf',\\n-\\t\\t\\t\\t\\t\\t   'x-image-meta-name': 'fake image #F'}\\n-\\n-\\t\\treq = webob.Request.blank(\"/images\")\\n-\\t\\treq.method = 'POST'\\n-\\t\\tfor k, v in six.iteritems(fixture_headers):\\n-\\t\\t\\treq.headers[k] = v\\n-\\t\\tres = req.get_response(self.api)\\n-\\t\\tself.assertEqual(400, res.status_int)\\n+\\t\\tfor schema in schemas:\\n+\\t\\t\\treq = webob.Request.blank(\"/images\")\\n+\\t\\t\\treq.method = 'POST'\\n+\\t\\t\\tfor k, v in six.iteritems(header_template):\\n+\\t\\t\\t\\treq.headers[k] = v\\n+\\t\\t\\treq.headers['x-glance-api-copy-from'] = schema\\n+\\t\\t\\tres = req.get_response(self.api)\\n+\\t\\t\\tself.assertEqual(400, res.status_int)\\n \\n\\t def test_add_copy_from_upload_image_unauthorized_with_body(self):\\n\\t\\t rules = {\"upload_image\": '!', \"modify_image\": '@',",
         "def validate_external_location(uri):\\n\\tscheme = urlparse.urlparse(uri).scheme\\n\\treturn (scheme in store_api.get_known_schemes() and\\n\\t\\t\\tscheme not in RESTRICTED_URI_SCHEMAS)",
         "def validate_external_location(uri):\\n\\tpieces = urlparse.urlparse(uri)\\n\\tvalid_schemes = [scheme for scheme in store_api.get_known_schemes()\\n\\t\\t\\t\\t\\t if scheme != 'file' and scheme != 'swift+config']\\n\\treturn pieces.scheme in valid_schemes",
         "def validate_external_location(uri)",
         null,
         "Implement a bug in the validate_external_location function to trigger a Wrong Algorithm - Small Sparse Modifications (WALD) fault. The function should fail due to using a less secure validation approach for URL schemes.",
         "Alter the validate_external_location function to introduce wrong algorithm small sparse modifications (WALD) fault. The function should use a simplified but less secure approach to validate URI schemes.",
         "Alter the validate_external_location function to create wrong algorithm small modifications.",
         "openstack",
         "3.9.0",
         "['test_api.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WALD"
        ],
        [
         "12",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def read(self, offset, count):\\n\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))",
         "def read(self, offset, count):\\n\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))",
         "def read(self, offset, count)",
         null,
         "Alter the behavior of the read function to introduce a Wrong Parameter Value in Function Call (WPFL) fault. The function should fail due to passing \"read\" as string instead of [\"read\"] as list to self._run_command, potentially causing command execution errors.",
         "Introduce a wrong parameter value error in the read method. The function should fail due to incorrect parameter type passed to self._run_command, potentially allowing remote code injection in the Sheepdog storage backend.",
         "Introduce a wrong parameter value error in the read method.",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WPFL"
        ],
        [
         "13",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def configure_add(self):\\n\\t\\ttry:\\n\\t\\t\\tself.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\tself.port = CONF.sheepdog_store_port\\n\\t\\texcept cfg.ConfigFileValueError as e:\\n\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\tLOG.error(reason)\\n\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n\\t\\tif ' ' in self.addr:\\n\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n\\t\\t\\t\\t\\t  % self.addr)\\n\\t\\t\\tLOG.error(reason)\\n\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n\\t\\ttry:\\n\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n\\t\\t\\tprocessutils.execute(*cmd)\\n\\t\\texcept Exception as e:\\n\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\tLOG.error(reason)\\n\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)",
         "def configure_add(self):\\n\\t\\ttry:\\n\\t\\t\\tself.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n\\t\\t\\tself.port = CONF.sheepdog_store_port\\n\\t\\texcept cfg.ConfigFileValueError as e:\\n\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\tLOG.error(reason)\\n\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n\\t\\ttry:\\n\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n\\t\\texcept processutils.ProcessExecutionError as exc:\\n\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n\\t\\t\\tLOG.error(reason)\\n\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)",
         "def configure_add(self)",
         null,
         "Introduce an error in the configure_add method to simulate a Wrong logical expression used as branch condition (WLEC) fault by removing the validation logic that checks for spaces in the Sheepdog store address.",
         "By modifying the configure_add method, you can trigger Wrong logical expression used as branch condition (WLEC). The function fails due to incorrect address validation logic, potentially allowing remote code injection attacks.",
         "By modifying the configure_add method, you can trigger Wrong logical expression used as branch condition (WLEC).",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WLEC"
        ],
        [
         "14",
         "Prevent setting swift+config locations\\n\\nForbid setting 'swift+config' locations in a similar\\nmanner to 'file' for security reasons; knowledge of\\nthe reference name should not be exploitable.\\n\\nSetting swift+config had been prevented when swift\\nwas the default store, this patch changes to forbid\\nsetting no matter which store is the default.\\n\\nAs with change id I75af34145521f533dcd6f5fd7690f5a68f3b44b3\\nthis is v1 only for now.\\n\\nCloses-bug: 1334196",
         "security",
         null,
         "https://github.com/python/cpython/commit/c0d90a580f87dbbf71e3a5d5c1b5cf8d7c7245b2",
         "c0d90a580f87dbbf71e3a5d5c1b5cf8d7c7245b2",
         "PySecDB",
         "diff --git a/glance/api/v1/images.py b/glance/api/v1/images.py\\nindex 15ec9120..3b460272 100644\\n--- a/glance/api/v1/images.py\\n+++ b/glance/api/v1/images.py\\n@@ -417,17 +417,20 @@ class Controller(controller.BaseController):\\n\\t\\t \"\"\"\\n\\t\\t External sources (as specified via the location or copy-from headers)\\n\\t\\t are supported only over non-local store types, i.e. S3, Swift, HTTP.\\n-\\t\\tNote the absence of file:// for security reasons, see LP bug #942118.\\n+\\t\\tNote the absence of 'file://' for security reasons, see LP bug #942118.\\n+\\t\\t'swift+config://' is also absent for security reasons, see LP bug\\n+\\t\\t#1334196.\\n\\t\\t If the above constraint is violated, we reject with 400 \"Bad Request\".\\n\\t\\t \"\"\"\\n\\t\\t if source:\\n\\t\\t\\t pieces = urlparse.urlparse(source)\\n\\t\\t\\t schemes = [scheme for scheme in store.get_known_schemes()\\n-\\t\\t\\t\\t\\t   if scheme != 'file']\\n+\\t\\t\\t\\t\\t   if scheme != 'file' and scheme != 'swift+config']\\n\\t\\t\\t for scheme in schemes:\\n\\t\\t\\t\\t if pieces.scheme == scheme:\\n\\t\\t\\t\\t\\t return source\\n-\\t\\t\\tmsg = \"External sourcing not supported for store %s\" % source\\n+\\t\\t\\tmsg = (\"External sourcing not supported for \"\\n+\\t\\t\\t\\t   \"store '%s'\" % pieces.scheme)\\n\\t\\t\\t LOG.debug(msg)\\n\\t\\t\\t raise HTTPBadRequest(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t  request=req,\\n@@ -743,18 +746,17 @@ class Controller(controller.BaseController):\\n\\t\\t\\t self.pool.spawn_n(self._upload_and_activate, req, image_meta)\\n\\t\\t else:\\n\\t\\t\\t if location:\\n-\\t\\t\\t\\ttry:\\n-\\t\\t\\t\\t\\tstore.validate_location(location, context=req.context)\\n-\\t\\t\\t\\texcept store.BadStoreUri as bse:\\n-\\t\\t\\t\\t\\traise HTTPBadRequest(explanation=bse.msg,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t request=req)\\n-\\n\\t\\t\\t\\t self._validate_image_for_activation(req, image_id, image_meta)\\n\\t\\t\\t\\t image_size_meta = image_meta.get('size')\\n\\t\\t\\t\\t if image_size_meta:\\n-\\t\\t\\t\\t\\timage_size_store = store.get_size_from_backend(\\n-\\t\\t\\t\\t\\t\\tlocation,\\n-\\t\\t\\t\\t\\t\\tcontext=req.context)\\n+\\t\\t\\t\\t\\ttry:\\n+\\t\\t\\t\\t\\t\\timage_size_store = store.get_size_from_backend(\\n+\\t\\t\\t\\t\\t\\t\\tlocation, req.context)\\n+\\t\\t\\t\\t\\texcept (store.BadStoreUri, store.UnknownScheme) as e:\\n+\\t\\t\\t\\t\\t\\tLOG.debug(utils.exception_to_str(e))\\n+\\t\\t\\t\\t\\t\\traise HTTPBadRequest(explanation=e.msg,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")\\n\\t\\t\\t\\t\\t # NOTE(zhiyan): A returned size of zero usually means\\n\\t\\t\\t\\t\\t # the driver encountered an error. In this case the\\n\\t\\t\\t\\t\\t # size provided by the client will be used as-is.\\ndiff --git a/glance/tests/functional/v1/test_copy_to_file.py b/glance/tests/functional/v1/test_copy_to_file.py\\nindex ae2c3205..15bb7081 100644\\n--- a/glance/tests/functional/v1/test_copy_to_file.py\\n+++ b/glance/tests/functional/v1/test_copy_to_file.py\\n@@ -250,7 +250,33 @@ class TestCopyToFile(functional.FunctionalTest):\\n\\t\\t response, content = http.request(path, 'POST', headers=headers)\\n\\t\\t self.assertEqual(response.status, 400, content)\\n \\n-\\t\\texpected = 'External sourcing not supported for store ' + copy_from\\n+\\t\\texpected = 'External sourcing not supported for store \\'file\\''\\n+\\t\\tmsg = 'expected \"%s\" in \"%s\"' % (expected, content)\\n+\\t\\tself.assertTrue(expected in content, msg)\\n+\\n+\\t\\tself.stop_servers()\\n+\\n+\\t@skip_if_disabled\\n+\\tdef test_copy_from_swift_config(self):\\n+\\t\\t\"\"\"\\n+\\t\\tEnsure we can't copy from swift+config\\n+\\t\\t\"\"\"\\n+\\t\\tself.cleanup()\\n+\\n+\\t\\tself.start_servers(**self.__dict__.copy())\\n+\\n+\\t\\t# POST /images with public image copied from file (to file)\\n+\\t\\theaders = {'X-Image-Meta-Name': 'copied',\\n+\\t\\t\\t\\t   'X-Image-Meta-disk_format': 'raw',\\n+\\t\\t\\t\\t   'X-Image-Meta-container_format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True',\\n+\\t\\t\\t\\t   'X-Glance-API-Copy-From': 'swift+config://xxx'}\\n+\\t\\tpath = \"http://%s:%d/v1/images\" % (\"127.0.0.1\", self.api_port)\\n+\\t\\thttp = httplib2.Http()\\n+\\t\\tresponse, content = http.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 400, content)\\n+\\n+\\t\\texpected = 'External sourcing not supported for store \\'swift+config\\''\\n\\t\\t msg = 'expected \"%s\" in \"%s\"' % (expected, content)\\n\\t\\t self.assertTrue(expected in content, msg)\\n \\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex 8d2d6895..fa7f220e 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -91,7 +91,6 @@ class TestGlanceAPI(base.IsolatedUnitTest):\\n\\t\\t\\t\\t\\t\\t\\t 'metadata': {}, 'status': 'active'}],\\n\\t\\t\\t  'properties': {}}]\\n\\t\\t self.context = glance.context.RequestContext(is_admin=True)\\n-\\t\\tstore.validate_location = mock.Mock()\\n\\t\\t db_api.get_engine()\\n\\t\\t self.destroy_fixtures()\\n\\t\\t self.create_fixtures()\\n@@ -1009,11 +1008,6 @@ class TestGlanceAPI(base.IsolatedUnitTest):\\n \\n\\t def test_add_location_with_invalid_location(self):\\n\\t\\t \"\"\"Tests creates an image from location and conflict image size\"\"\"\\n-\\n-\\t\\tmock_validate_location = mock.Mock()\\n-\\t\\tstore.validate_location = mock_validate_location\\n-\\t\\tmock_validate_location.side_effect = store.BadStoreUri()\\n-\\n\\t\\t fixture_headers = {'x-image-meta-store': 'file',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-disk-format': 'vhd',\\n\\t\\t\\t\\t\\t\\t\\t'x-image-meta-location': 'http://a/b/c.tar.gz',",
         "def _handle_source(self, req, image_id, image_meta, image_data):\\n\\t\\tcopy_from = self._copy_from(req)\\n\\t\\tlocation = image_meta.get('location')\\n\\t\\tsources = filter(lambda x: x, (copy_from, location, image_data))\\n\\t\\tif len(sources) >= 2:\\n\\t\\t\\tmsg = \"It's invalid to provide multiple image sources.\"\\n\\t\\t\\tLOG.debug(msg)\\n\\t\\t\\traise HTTPBadRequest(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")\\n\\t\\tif image_data:\\n\\t\\t\\timage_meta = self._validate_image_for_activation(req,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t image_id,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t image_meta)\\n\\t\\t\\timage_meta = self._upload_and_activate(req, image_meta)\\n\\t\\telif copy_from:\\n\\t\\t\\tmsg = _LI('Triggering asynchronous copy from external source')\\n\\t\\t\\tLOG.info(msg)\\n\\t\\t\\tself.pool.spawn_n(self._upload_and_activate, req, image_meta)\\n\\t\\telse:\\n\\t\\t\\tif location:\\n\\t\\t\\t\\tself._validate_image_for_activation(req, image_id, image_meta)\\n\\t\\t\\t\\timage_size_meta = image_meta.get('size')\\n\\t\\t\\t\\tif image_size_meta:\\n\\t\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\t\\timage_size_store = store.get_size_from_backend(\\n\\t\\t\\t\\t\\t\\t\\tlocation, req.context)\\n\\t\\t\\t\\t\\texcept (store.BadStoreUri, store.UnknownScheme) as e:\\n\\t\\t\\t\\t\\t\\tLOG.debug(utils.exception_to_str(e))\\n\\t\\t\\t\\t\\t\\traise HTTPBadRequest(explanation=e.msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")\\n\\t\\t\\t\\t\\tif (image_size_store and\\n\\t\\t\\t\\t\\t\\t\\timage_size_store != image_size_meta):\\n\\t\\t\\t\\t\\t\\tmsg = (\"Provided image size must match the stored \"\\n\\t\\t\\t\\t\\t\\t\\t   \"image size. (provided size: %(ps)d, \"\\n\\t\\t\\t\\t\\t\\t\\t   \"stored size: %(ss)d)\" % {\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"ps\": image_size_meta,\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"ss\": image_size_store})\\n\\t\\t\\t\\t\\t\\tLOG.debug(msg)\\n\\t\\t\\t\\t\\t\\traise HTTPConflict(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   content_type=\"text/plain\")\\n\\t\\t\\t\\tlocation_data = {'url': location, 'metadata': {},\\n\\t\\t\\t\\t\\t\\t\\t\\t 'status': 'active'}\\n\\t\\t\\t\\timage_meta = self._activate(req, image_id, location_data)\\n\\t\\treturn image_meta",
         "def _handle_source(self, req, image_id, image_meta, image_data):\\n\\t\\tcopy_from = self._copy_from(req)\\n\\t\\tlocation = image_meta.get('location')\\n\\t\\tsources = filter(lambda x: x, (copy_from, location, image_data))\\n\\t\\tif len(sources) >= 2:\\n\\t\\t\\tmsg = \"It's invalid to provide multiple image sources.\"\\n\\t\\t\\tLOG.debug(msg)\\n\\t\\t\\traise HTTPBadRequest(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t content_type=\"text/plain\")\\n\\t\\tif image_data:\\n\\t\\t\\timage_meta = self._validate_image_for_activation(req,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t image_id,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t image_meta)\\n\\t\\t\\timage_meta = self._upload_and_activate(req, image_meta)\\n\\t\\telif copy_from:\\n\\t\\t\\tmsg = _LI('Triggering asynchronous copy from external source')\\n\\t\\t\\tLOG.info(msg)\\n\\t\\t\\tself.pool.spawn_n(self._upload_and_activate, req, image_meta)\\n\\t\\telse:\\n\\t\\t\\tif location:\\n\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\tstore.validate_location(location, context=req.context)\\n\\t\\t\\t\\texcept store.BadStoreUri as bse:\\n\\t\\t\\t\\t\\traise HTTPBadRequest(explanation=bse.msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t request=req)\\n\\t\\t\\t\\tself._validate_image_for_activation(req, image_id, image_meta)\\n\\t\\t\\t\\timage_size_meta = image_meta.get('size')\\n\\t\\t\\t\\tif image_size_meta:\\n\\t\\t\\t\\t\\timage_size_store = store.get_size_from_backend(\\n\\t\\t\\t\\t\\t\\tlocation,\\n\\t\\t\\t\\t\\t\\tcontext=req.context)\\n\\t\\t\\t\\t\\tif (image_size_store and\\n\\t\\t\\t\\t\\t\\t\\timage_size_store != image_size_meta):\\n\\t\\t\\t\\t\\t\\tmsg = (\"Provided image size must match the stored \"\\n\\t\\t\\t\\t\\t\\t\\t   \"image size. (provided size: %(ps)d, \"\\n\\t\\t\\t\\t\\t\\t\\t   \"stored size: %(ss)d)\" % {\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"ps\": image_size_meta,\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"ss\": image_size_store})\\n\\t\\t\\t\\t\\t\\tLOG.debug(msg)\\n\\t\\t\\t\\t\\t\\traise HTTPConflict(explanation=msg,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   request=req,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   content_type=\"text/plain\")\\n\\t\\t\\t\\tlocation_data = {'url': location, 'metadata': {},\\n\\t\\t\\t\\t\\t\\t\\t\\t 'status': 'active'}\\n\\t\\t\\t\\timage_meta = self._activate(req, image_id, location_data)\\n\\t\\treturn image_meta",
         "def _handle_source(self, req, image_id, image_meta, image_data)",
         null,
         "Alter the behavior of the _handle_source function to introduce a Wrong Arithmetic Expression (WVAE) fault. The function should fail due to incorrect validation sequence causing potential security vulnerabilities.",
         "Introduce a bug into the _handle_source function by modifying validation sequence (WVAE), causing potential security vulnerabilities in image handling.",
         "Introduce a bug into the _handle_source function to create incorrect validation sequence.",
         "openstack",
         "3.9.0",
         "['test_copy_to_file.py', 'test_api.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WVAE"
        ],
        [
         "15",
         "New -k/--insecure command line option\\n\\nFix for bug 929591.\\n\\nChange glance to require server certificate validation\\nby default when using https. The standard system\\nCA file will be used if available (and an alternative was not\\nprovided).\\n\\nThe --insecure option can be used by clients to skip server\\ncertificate validation if appropriate.\\n\\n  If the standard CA file is not suitable they will need to provide\\n  a CA file or else create an 'insecure' glance client.\\n  certificate validation.\\n  system CA file is installed then that file will be used by default.\\n  It probably makes sense for the glance package to have a\\n  dependency on whichever package provides the default CA bundle.\\n  (In Ubuntu this is 'ca-certificates')",
         "security",
         null,
         "https://github.com/python/cpython/commit/0f0fe2ba1b772e6964241c0631683b306fff23c0",
         "0f0fe2ba1b772e6964241c0631683b306fff23c0",
         "PySecDB",
         "diff --git a/bin/glance b/bin/glance\\nindex fd44f248..8aefea53 100755\\n--- a/bin/glance\\n+++ b/bin/glance\\n@@ -754,7 +754,7 @@ def get_client(options):\\n\\t\\t\\t\\t\\t\\t\\t\\t use_ssl=use_ssl,\\n\\t\\t\\t\\t\\t\\t\\t\\t auth_tok=options.auth_token or \\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t os.getenv('OS_TOKEN'),\\n-\\t\\t\\t\\t\\t\\t\\t\\tcreds=creds)\\n+\\t\\t\\t\\t\\t\\t\\t\\tcreds=creds, insecure=options.insecure)\\n \\n \\n def create_options(parser):\\n@@ -781,6 +781,12 @@ def create_options(parser):\\n\\t\\t\\t\\t\\t\\t\\t\"(http/https) of the glance server, for example \"\\n\\t\\t\\t\\t\\t\\t\\t\"-U https://localhost:\" + str(DEFAULT_PORT) +\\n\\t\\t\\t\\t\\t\\t\\t\"/v1 Default: None\")\\n+\\tparser.add_option('-k', '--insecure', dest=\"insecure\",\\n+\\t\\t\\t\\t\\t  default=False, action=\"store_true\",\\n+\\t\\t\\t\\t\\t  help=\"Explicitly allow glance to perform \\\"insecure\\\" \"\\n+\\t\\t\\t\\t\\t  \"SSL (https) requests. The server's certificate will \"\\n+\\t\\t\\t\\t\\t  \"not be verified against any certificate authorities. \"\\n+\\t\\t\\t\\t\\t  \"This option should be used with caution.\")\\n\\t parser.add_option('-A', '--auth_token', dest=\"auth_token\",\\n\\t\\t\\t\\t\\t   metavar=\"TOKEN\", default=None,\\n\\t\\t\\t\\t\\t   help=\"Authentication token to use to identify the \"\\n@@ -810,7 +816,7 @@ def create_options(parser):\\n\\t\\t\\t\\t\\t   help=\"Sort results by this image attribute.\")\\n\\t parser.add_option('--sort_dir', dest=\"sort_dir\", metavar=\"[desc|asc]\",\\n\\t\\t\\t\\t\\t   help=\"Sort results in this direction.\")\\n-\\tparser.add_option('-f', '--force', dest=\"force\", metavar=\"FORCE\",\\n+\\tparser.add_option('-f', '--force', dest=\"force\",\\n\\t\\t\\t\\t\\t   default=False, action=\"store_true\",\\n\\t\\t\\t\\t\\t   help=\"Prevent select actions from requesting \"\\n\\t\\t\\t\\t\\t\\t\\t\"user confirmation\")\\ndiff --git a/doc/source/glance.rst b/doc/source/glance.rst\\nindex 1a86f4c9..e105eb48 100644\\n--- a/doc/source/glance.rst\\n+++ b/doc/source/glance.rst\\n@@ -100,6 +100,10 @@ a brief help message, like so::\\n\\t\\t\\t\\t\\t\\t   specify the hostname, port and protocol (http/https)\\n\\t\\t\\t\\t\\t\\t   of the glance server, for example -U\\n\\t\\t\\t\\t\\t\\t   https://localhost:9292/v1 Default: None\\n+\\t-k, --insecure\\t\\tExplicitly allow glance to perform insecure SSL\\n+\\t\\t\\t\\t\\t\\t  requests. The server certificate will not be\\n+\\t\\t\\t\\t\\t\\t  verified against any certificate authorities.\\n+\\t\\t\\t\\t\\t\\t  This option should be used with caution.\\n\\t --limit=LIMIT\\t\\t Page size to use while requesting image metadata\\n\\t --marker=MARKER\\t   Image index after which to begin pagination\\n\\t --sort_key=KEY\\t\\tSort results by this image attribute.\\n@@ -153,7 +157,7 @@ Important Information about Uploading Images\\n Before we go over the commands for adding an image to Glance, it is\\n important to understand that Glance **does not currently inspect** the image\\n files you add to it. In other words, **Glance only understands what you tell it,\\n-via attributes and custom properties**. \\n+via attributes and custom properties**.\\n \\n If the file extension of the file you upload to Glance ends in '.vhd', Glance\\n **does not** know that the image you are uploading has a disk format of ``vhd``.\\ndiff --git a/doc/source/man/glance.rst b/doc/source/man/glance.rst\\nindex 16ecdc11..ae174f9a 100644\\n--- a/doc/source/man/glance.rst\\n+++ b/doc/source/man/glance.rst\\n@@ -78,10 +78,10 @@ OPTIONS\\n \\n   **-v, --verbose**\\n\\t\\t Print more verbose output\\n- \\n+\\n   **-d, --debug**\\n\\t\\t Print more verbose output\\n- \\n+\\n   **-H ADDRESS, --host=ADDRESS**\\n\\t\\t Address of Glance API host. Default: 0.0.0.0\\n \\n@@ -90,10 +90,15 @@ OPTIONS\\n \\n   **-U URL, --url=URL**\\n\\t\\t URL of Glance service. This option can be used to specify the hostname,\\n-\\t\\tport and protocol (http/https) of the glance server, for example \\n-\\t\\t-U https://localhost:9292/v1 \\n+\\t\\tport and protocol (http/https) of the glance server, for example\\n+\\t\\t-U https://localhost:9292/v1\\n\\t\\t Default: None\\n \\n+  **-k, --insecure**\\n+\\t\\tExplicitly allow glance to perform insecure SSL (https) requests.\\n+\\t\\tThe server certificate will not be verified against any certificate\\n+\\t\\tauthorities. This option should be used with caution.\\n+\\n   **-A TOKEN, --auth_token=TOKEN**\\n\\t\\t Authentication token to use to identify the client to the glance server\\n \\ndiff --git a/glance/common/client.py b/glance/common/client.py\\nindex 9a3c3bfb..9e08c15a 100644\\n--- a/glance/common/client.py\\n+++ b/glance/common/client.py\\n@@ -148,13 +148,14 @@ class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\t \"\"\"\\n \\n\\t def __init__(self, host, port, key_file, cert_file,\\n-\\t\\t\\t\\t ca_file, timeout=None):\\n+\\t\\t\\t\\t ca_file, timeout=None, insecure=False):\\n\\t\\t httplib.HTTPSConnection.__init__(self, host, port, key_file=key_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  cert_file=cert_file)\\n\\t\\t self.key_file = key_file\\n\\t\\t self.cert_file = cert_file\\n\\t\\t self.ca_file = ca_file\\n\\t\\t self.timeout = timeout\\n+\\t\\tself.insecure = insecure\\n \\n\\t def connect(self):\\n\\t\\t \"\"\"\\n@@ -170,14 +171,14 @@ class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\t\\t if self._tunnel_host:\\n\\t\\t\\t self.sock = sock\\n\\t\\t\\t self._tunnel()\\n-\\t\\t# If there's no CA File, don't force Server Certificate Check\\n-\\t\\tif self.ca_file:\\n+\\t\\t# Check CA file unless 'insecure' is specificed\\n+\\t\\tif self.insecure is True:\\n\\t\\t\\t self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n\\t\\t else:\\n\\t\\t\\t self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n \\n \\n class BaseClient(object):\\n@@ -186,6 +187,12 @@ class BaseClient(object):\\n \\n\\t DEFAULT_PORT = 80\\n\\t DEFAULT_DOC_ROOT = None\\n+\\t# Standard CA file locations for Debian/Ubuntu, RedHat/Fedora,\\n+\\t# Suse, FreeBSD/OpenBSD\\n+\\tDEFAULT_CA_FILE_PATH = '/etc/ssl/certs/ca-certificates.crt:'\\\\n+\\t\\t'/etc/pki/tls/certs/ca-bundle.crt:'\\\\n+\\t\\t'/etc/ssl/ca-bundle.pem:'\\\\n+\\t\\t'/etc/ssl/cert.pem'\\n \\n\\t OK_RESPONSE_CODES = (\\n\\t\\t httplib.OK,\\n@@ -203,8 +210,8 @@ class BaseClient(object):\\n\\t )\\n \\n\\t def __init__(self, host, port=None, use_ssl=False, auth_tok=None,\\n-\\t\\t\\t\\t creds=None, doc_root=None,\\n-\\t\\t\\t\\t key_file=None, cert_file=None, ca_file=None):\\n+\\t\\t\\t\\t creds=None, doc_root=None, key_file=None,\\n+\\t\\t\\t\\t cert_file=None, ca_file=None, insecure=False):\\n\\t\\t \"\"\"\\n\\t\\t Creates a new client to some service.\\n \\n@@ -231,6 +238,8 @@ class BaseClient(object):\\n\\t\\t\\t\\t\\t\\t If use_ssl is True, and this param is None (the\\n\\t\\t\\t\\t\\t\\t default), then an environ variable\\n\\t\\t\\t\\t\\t\\t GLANCE_CLIENT_CA_FILE is looked for.\\n+\\t\\t:param insecure: Optional. If set then the server's certificate\\n+\\t\\t\\t\\t\\t\\t will not be verified.\\n\\t\\t \"\"\"\\n\\t\\t self.host = host\\n\\t\\t self.port = port or self.DEFAULT_PORT\\n@@ -286,7 +295,15 @@ class BaseClient(object):\\n\\t\\t\\t\\t msg = _(\"The CA file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t \"exist\") % ca_file\\n\\t\\t\\t\\t raise exception.ClientConnectionError(msg)\\n+\\n+\\t\\t\\tif ca_file is None:\\n+\\t\\t\\t\\tfor ca in self.DEFAULT_CA_FILE_PATH.split(\":\"):\\n+\\t\\t\\t\\t\\tif os.path.exists(ca):\\n+\\t\\t\\t\\t\\t\\tca_file = ca\\n+\\t\\t\\t\\t\\t\\tbreak\\n+\\n\\t\\t\\t self.connect_kwargs['ca_file'] = ca_file\\n+\\t\\t\\tself.connect_kwargs['insecure'] = insecure\\n \\n\\t def set_auth_token(self, auth_tok):\\n\\t\\t \"\"\"\\ndiff --git a/glance/tests/functional/test_ssl.py b/glance/tests/functional/test_ssl.py\\nindex b0fdf622..4c94d1cf 100644\\n--- a/glance/tests/functional/test_ssl.py\\n+++ b/glance/tests/functional/test_ssl.py\\n@@ -40,6 +40,8 @@ import os\\n import tempfile\\n import unittest\\n \\n+from glance import client as glance_client\\n+from glance.common import exception\\n from glance.common import utils\\n from glance.store.location import get_location_from_uri\\n from glance.tests import functional\\n@@ -62,6 +64,12 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t self.inited = False\\n\\t\\t self.disabled = True\\n \\n+\\t\\t# Test key/cert/CA file created as per:\\n+\\t\\t#   http://blog.didierstevens.com/2008/12/30/\\n+\\t\\t#\\t howto-make-your-own-cert-with-openssl/\\n+\\t\\t# Note that for these tests certificate.crt had to\\n+\\t\\t# be created with 'Common Name' set to 0.0.0.0\\n+\\n\\t\\t self.key_file = os.path.join(TEST_VAR_DIR, 'privatekey.key')\\n\\t\\t if not os.path.exists(self.key_file):\\n\\t\\t\\t self.disabled_message = \"Could not find private key file\"\\n@@ -69,11 +77,17 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t\\t return\\n \\n\\t\\t self.cert_file = os.path.join(TEST_VAR_DIR, 'certificate.crt')\\n-\\t\\tif not os.path.exists(self.key_file):\\n+\\t\\tif not os.path.exists(self.cert_file):\\n\\t\\t\\t self.disabled_message = \"Could not find certificate file\"\\n\\t\\t\\t self.inited = True\\n\\t\\t\\t return\\n \\n+\\t\\tself.ca_file = os.path.join(TEST_VAR_DIR, 'ca.crt')\\n+\\t\\tif not os.path.exists(self.ca_file):\\n+\\t\\t\\tself.disabled_message = \"Could not find CA file\"\\n+\\t\\t\\tself.inited = True\\n+\\t\\t\\treturn\\n+\\n\\t\\t self.inited = True\\n\\t\\t self.disabled = False\\n \\n@@ -1230,3 +1244,94 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t self.assertEqual(response.status, 404)\\n \\n\\t\\t self.stop_servers()\\n+\\n+\\t@skip_if_disabled\\n+\\tdef test_certificate_validation(self):\\n+\\t\\t\"\"\"\\n+\\t\\tCheck SSL client cerificate verification\\n+\\t\\t\"\"\"\\n+\\t\\tself.cleanup()\\n+\\t\\tself.start_servers(**self.__dict__.copy())\\n+\\n+\\t\\t# 0. GET /images\\n+\\t\\t# Verify no public images\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\t# 1. POST /images with public image named Image1\\n+\\t\\theaders = {'Content-Type': 'application/octet-stream',\\n+\\t\\t\\t\\t   'X-Image-Meta-Name': 'Image1',\\n+\\t\\t\\t\\t   'X-Image-Meta-Status': 'active',\\n+\\t\\t\\t\\t   'X-Image-Meta-Container-Format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Disk-Format': 'vdi',\\n+\\t\\t\\t\\t   'X-Image-Meta-Size': '19',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True'}\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 201)\\n+\\t\\tdata = json.loads(content)\\n+\\n+\\t\\timage_id = data['image']['id']\\n+\\n+\\t\\t# 2. Attempt to delete the image *without* CA file\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\tsecure_cli = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  use_ssl=True, insecure=False)\\n+\\t\\ttry:\\n+\\t\\t\\tsecure_cli.delete_image(image_id)\\n+\\t\\t\\tself.fail(\"Client with no CA file deleted image %s\" % image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tpass\\n+\\n+\\t\\t# 3. Delete the image with a secure client *with* CA file\\n+\\t\\tsecure_cli2 = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   use_ssl=True, ca_file=self.ca_file,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   insecure=False)\\n+\\t\\ttry:\\n+\\t\\t\\tsecure_cli2.delete_image(image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tself.fail(\"Secure client failed to delete image %s\" % image_id)\\n+\\n+\\t\\t# Verify image is deleted\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\t# 4. POST another image\\n+\\t\\theaders = {'Content-Type': 'application/octet-stream',\\n+\\t\\t\\t\\t   'X-Image-Meta-Name': 'Image1',\\n+\\t\\t\\t\\t   'X-Image-Meta-Status': 'active',\\n+\\t\\t\\t\\t   'X-Image-Meta-Container-Format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Disk-Format': 'vdi',\\n+\\t\\t\\t\\t   'X-Image-Meta-Size': '19',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True'}\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 201)\\n+\\t\\tdata = json.loads(content)\\n+\\n+\\t\\timage_id = data['image']['id']\\n+\\n+\\t\\t# 5. Delete the image with an insecure client\\n+\\t\\tinsecure_cli = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tuse_ssl=True, insecure=True)\\n+\\t\\ttry:\\n+\\t\\t\\tinsecure_cli.delete_image(image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tself.fail(\"Insecure client failed to delete image\")\\n+\\n+\\t\\t# Verify image is deleted\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\tself.stop_servers()\\ndiff --git a/glance/tests/var/ca.crt b/glance/tests/var/ca.crt\\nnew file mode 100644\\nindex 00000000..9d66ca62\\n--- /dev/null\\n+++ b/glance/tests/var/ca.crt\\n@@ -0,0 +1,35 @@\\n+-----BEGIN CERTIFICATE-----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\\n+WoRMgEwjGJWqzhJZUYpUAQ==\\n+-----END CERTIFICATE-----\\ndiff --git a/glance/tests/var/certificate.crt b/glance/tests/var/certificate.crt\\nindex 9bb6dd1d..3c1aa636 100644\\n--- a/glance/tests/var/certificate.crt\\n+++ b/glance/tests/var/certificate.crt\\n@@ -1,18 +1,30 @@\\n -----BEGIN CERTIFICATE-----\\n-MIIC4DCCAcigAwIBAgIBATANBgkqhkiG9w0BAQUFADATMREwDwYDVQQDEwhNeVRl\\n-c3RDQTAeFw0xMTA3MjExNTA1NDZaFw0xMjA3MjAxNTA1NDZaMCMxEDAOBgNVBAMT\\n-B2FobWFkcGMxDzANBgNVBAoTBnNlcnZlcjCCASIwDQYJKoZIhvcNAQEBBQADggEP\\n-ADCCAQoCggEBAO9zpczf+W4DoK2z8oFbsZfbvz1y/yQOnrQYvb1zv1IieT+QA+Ti\\n-N64N/sgR/cR7YEIXDnhij8yE1JTWMk1W6g4m7TGacUMXD/WAcsTM7kRol/FVksdn\\n-F51qxCYqWUPQ3xiTfBg2SJWvJCUGowvz06xh8JeOEXLbALC5xrzrM3hclpdbrKYE\\n-oe8kikI/K0TKpu52VJJrTBGPHMsw+eIqL2Ix5pWHh7DPfjBiiG7khsJxN7xSqLbX\\n-LrhDi24nTM9pndaqABkmPYQ9qd11SoAUB82QAAGj8A7iR/DnAzAfJl1usvQp+Me6\\n-sR3TPY27zifBbD04tiROi1swM/1xRH7qOpkCAwEAAaMvMC0wCQYDVR0TBAIwADAL\\n-BgNVHQ8EBAMCBSAwEwYDVR0lBAwwCgYIKwYBBQUHAwEwDQYJKoZIhvcNAQEFBQAD\\n-ggEBAIJvnQjkEDFvLT7NiyFrO938BuxdQH2mX2N7Fz86myZLcGpr5NCdLvT9tD9f\\n-6KqrR8e839pYVPZY80cBpGTmRmzW3xLsmGCFHPHt4p1tkqSP1R5iLzKDe8jawHhD\\n-sch8P9URRhW9ZgBzA4xiv9FnIxZ70uDr04uX/sR/j41HGBS8YW6dJvr9Y2SpGqSS\\n-rR2btnNZ945dau6CPLRNd9Fls3Qjx03PnsmZ5ikSuV0pT1sPQmhhw7rBYV/b2ff+\\n-z/4cRtZrR00NVc74IEXLoujIjUUpFC83in10PKQmAvKYTeTdXns48eC4Cwqe8eaM\\n-N0YtxqQvSTsUo6vPM28NR99Fbow=\\n+MIIFLjCCAxYCAQEwDQYJKoZIhvcNAQEFBQAwYTELMAkGA1UEBhMCQVUxEzARBgNV\\n+BAgTClNvbWUtU3RhdGUxFTATBgNVBAoTDE9wZW5zdGFjayBDQTESMBAGA1UECxMJ\\n+R2xhbmNlIENBMRIwEAYDVQQDEwlHbGFuY2UgQ0EwHhcNMTIwMjA5MTcxMDUzWhcN\\n+MjIwMjA2MTcxMDUzWjBZMQswCQYDVQQGEwJBVTETMBEGA1UECBMKU29tZS1TdGF0\\n+ZTESMBAGA1UEChMJT3BlbnN0YWNrMQ8wDQYDVQQLEwZHbGFuY2UxEDAOBgNVBAMT\\n+BzAuMC4wLjAwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDXpUkQN6pu\\n+avo+gz3o1K4krVdPl1m7NjNJDyD/+ZH0EGNcEN7iag1qPE7JsjqGPNZsQK1dMoXb\\n+Sz+OSi9qvNeJnBcfwUx5qTAtwyAb9AxGkwuMafIU+lWbsclo+dPGsja01ywbXTCZ\\n+bF32iqnpOMYhfxWUdoQYiBkhxxhW9eMPKLS/KkP8/bx+Vaa2XJiAebqkd9nrksAA\\n+BeGc9mlafYBEmiChPdJEPw+1ePA4QVq9aPepDsqAKtGN8JLpmoC3BdxQQTbbwL3Q\\n+8fTXK4tCNUaVk4AbDy/McFq6y0ocQoBPJjihOY35mWG/OLtcI99yPOpWGnps/5aG\\n+/64DDJ2D67Fnaj6gKHV+6TXFO8KZxlnxtgtiZDJBZkneTBt9ArSOv+l6NBsumRz0\\n+iEJ4o4H1S2TSMnprAvX7WnGtc6Xi9gXahYcDHEelwwYzqAiTBv6hxSp4MZ2dNXa+\\n+KzOitC7ZbV2qsg0au0wjfE/oSQ3NvsvUr8nOmfutJTvHRAwbC1v4G/tuAsO7O0w2\\n+0u2B3u+pG06m5+rnEqp+rB9hmukRYTfgEFRRsVIvpFl/cwvPXKRcX03UIMx+lLr9\\n+Ft+ep7YooBhY3wY2kwCxD4lRYNmbwsCIVywZt40f/4ad98TkufR9NhsfycxGeqbr\\n+mTMFlZ8TTlmP82iohekKCOvoyEuTIWL2+wIDAQABMA0GCSqGSIb3DQEBBQUAA4IC\\n+AQBMUBgV0R+Qltf4Du7u/8IFmGAoKR/mktB7R1gRRAqsvecUt7kIwBexGdavGg1y\\n+0pU0+lgUZjJ20N1SlPD8gkNHfXE1fL6fmMjWz4dtYJjzRVhpufHPeBW4tl8DgHPN\\n+rBGAYQ+drDSXaEjiPQifuzKx8WS+DGA3ki4co5mPjVnVH1xvLIdFsk89z3b3YD1k\\n+yCJ/a9K36x6Z/c67JK7s6MWtrdRF9+MVnRKJ2PK4xznd1kBz16V+RA466wBDdARY\\n+vFbtkafbEqOb96QTonIZB7+fAldKDPZYnwPqasreLmaGOaM8sxtlPYAJ5bjDONbc\\n+AaXG8BMRQyO4FyH237otDKlxPyHOFV66BaffF5S8OlwIMiZoIvq+IcTZOdtDUSW2\\n+KHNLfe5QEDZdKjWCBrfqAfvNuG13m03WqfmcMHl3o/KiPJlx8l9Z4QEzZ9xcyQGL\\n+cncgeHM9wJtzi2cD/rTDNFsx/gxvoyutRmno7I3NRbKmpsXF4StZioU3USRspB07\\n+hYXOVnG3pS+PjVby7ThT3gvFHSocguOsxClx1epdUJAmJUbmM7NmOp5WVBVtMtC2\\n+Su4NG/xJciXitKzw+btb7C7RjO6OEqv/1X/oBDzKBWQAwxUC+lqmnM7W6oqWJFEM\\n+YfTLnrjs7Hj6ThMGcEnfvc46dWK3dz0RjsQzUxugPuEkLA==\\n -----END CERTIFICATE-----\\ndiff --git a/glance/tests/var/privatekey.key b/glance/tests/var/privatekey.key\\nindex 9da0a6c8..b63df3d2 100644\\n--- a/glance/tests/var/privatekey.key\\n+++ b/glance/tests/var/privatekey.key\\n@@ -1,27 +1,51 @@\\n -----BEGIN RSA PRIVATE KEY-----\\n-MIIEpQIBAAKCAQEA73OlzN/5bgOgrbPygVuxl9u/PXL/JA6etBi9vXO/UiJ5P5AD\\n-5OI3rg3+yBH9xHtgQhcOeGKPzITUlNYyTVbqDibtMZpxQxcP9YByxMzuRGiX8VWS\\n-x2cXnWrEJipZQ9DfGJN8GDZIla8kJQajC/PTrGHwl44RctsAsLnGvOszeFyWl1us\\n-pgSh7ySKQj8rRMqm7nZUkmtMEY8cyzD54iovYjHmlYeHsM9+MGKIbuSGwnE3vFKo\\n-ttcuuEOLbidMz2md1qoAGSY9hD2p3XVKgBQHzZAAAaPwDuJH8OcDMB8mXW6y9Cn4\\n-x7qxHdM9jbvOJ8FsPTi2JE6LWzAz/XFEfuo6mQIDAQABAoIBAQC6BwvBbiQXH0Re\\n-jtWRQA5p3zPk5olnluAfJLWMEPeLNPMjuZv83u7JD2BoSOnxErTGw6jfSBtVlcCd\\n-3Qb5ZNOzqPRPvB/QMoOYhHElidx2UxfwSz4cInCLQJ4g1HfDIuuf6TzYhpu/hnC7\\n-Pzu+lnBVlUVYSOwvYgtYQQwwSz4Se8Mwoh2OOOTgn4wvZDbiDrMvv2UUUL1nyvAB\\n-FdaywbD/dW8TqbnPSoj8uipq0yugDOyzzNQDM6+rN69qNrD2/vYaAsSaWxISLDqs\\n-fEI4M1+PeDmLigQeA7V3kEZWWDwHbS92LL8BxEmmeeHN5xwZyC8xqa1jt2A/S6Af\\n-Q7gkpG6BAoGBAP+jFn7HCCi/Lc+YEZO0km7fvfR48M6QW3ar+b1aQywJWJhbtU9E\\n-eoX1IcLxgce3+mUO05hGz3Rvz5JSDbmWXd6GTVsMRZqJeeCKbw9xirp5i4JjLzc8\\n-Vu2oOJhqtAa88FgpZJ3iPIrT38UBpmnrvv1nb2ZNMdZnTNhtj5WByLFpAoGBAO/K\\n-rVuvMq370P69Lo+iAr6+t4vwpF6pC/06B+OT5vldoiF57dOjFwndAKs9HCk9rS0/\\n-jTvo0a1tS9yU20cFLXMN98zho3BYs4BlEKpNwVmpopxcfGV6dbwka7delAEVZzyN\\n-TDW2P5Gyq9sYys+2ldvT2zTK8hHXZSh5JAp3V+mxAoGAC6G6Fk6sGl6IkReURSpE\\n-N3NKy2LtYhjDcKTmmi0PPWO3ekdB+rdc89dxj9M5WoMOi6afDiC6s8uaoEfHhBhJ\\n-cSSfRHNMf3md6A+keglqjI2XQXmN3m+KbQnoeVbxlhTmwrwvbderdY2qcuZeUhd9\\n-+z3HndoJWH4eywJBNEZRgXECgYEAjtTeEDe6a1IMuj/7xQiOtAmsEQolDlGJV6vC\\n-WTeXJEA2u9QB6sdBiNmAdX9wD8yyI7qwKNhUVQY+YsS0HIij+t1+FibtEJV1Tmxk\\n-0dyA6CSYPKUGX/fiu0/CbbZDWKXkGXhcxb2p/eI8ZcRNwg4TE58M+lRMfn4bvlDy\\n-O928mvECgYEA18MfGUZENZmC9ismsqrr9uVevfB08U5b+KRjSOyI2ZwOXnzcvbc3\\n-zt9Tp35bcpQMAxPVT2B5htXeXqhUAJMkFEajpNZGDEKlCRB2XvMeA1Dn5fSk2dBB\\n-ADeqQczoXT2+VgXLxRJJPucYCzi3kzo0OBUsHc9Z/HZNyr8LrUgd5lI=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\\n -----END RSA PRIVATE KEY-----",
         "class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\tdef __init__(self, host, port, key_file, cert_file,\\n\\t\\t\\t\\t ca_file, timeout=None, insecure=False):\\n\\t\\thttplib.HTTPSConnection.__init__(self, host, port, key_file=key_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t cert_file=cert_file)\\n\\t\\tself.key_file = key_file\\n\\t\\tself.cert_file = cert_file\\n\\t\\tself.ca_file = ca_file\\n\\t\\tself.timeout = timeout\\n\\t\\tself.insecure = insecure",
         "class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\tdef __init__(self, host, port, key_file, cert_file,\\n\\t\\t\\t\\t ca_file, timeout=None):\\n\\t\\thttplib.HTTPSConnection.__init__(self, host, port, key_file=key_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t cert_file=cert_file)\\n\\t\\tself.key_file = key_file\\n\\t\\tself.cert_file = cert_file\\n\\t\\tself.ca_file = ca_file\\n\\t\\tself.timeout = timeout",
         "class HTTPSClientAuthConnection(httplib.HTTPSConnection)",
         null,
         "By modifying the HTTPSClientAuthConnection class, you can trigger a Missing Variable Assignment Using a Value (MVAV) fault. The function should fail due to removing the insecure parameter initialization.",
         "By modifying the HTTPSClientAuthConnection class, you can trigger missing variable assignment using a value (MVAV). The function should fail due to the absence of the insecure flag assignment, removing the ability to control certificate validation.",
         "By modifying the HTTPSClientAuthConnection class, you can trigger missing variable assignment using a value (MVAV). The function should fail due to missing initialization.",
         "openstack",
         "2.6.0",
         "['test_ssl.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MVAV"
        ],
        [
         "16",
         "Unallowed request PATCH when work with blob\\n\\nAdded check property when updating artifacts with request PATCH.\\n\\nApiImpact\\nFastTrack\\nCloses-bug: #1490505\\nCloses-bug: #1490511",
         "security",
         null,
         "https://github.com/python/cpython/commit/e7d4e81f5b3daf924a294e439f434c193d53313e",
         "e7d4e81f5b3daf924a294e439f434c193d53313e",
         "PySecDB",
         "diff --git a/glance/api/glare/v0_1/glare.py b/glance/api/glare/v0_1/glare.py\\nindex 1c040639..5fb0d031 100644\\n--- a/glance/api/glare/v0_1/glare.py\\n+++ b/glance/api/glare/v0_1/glare.py\\n@@ -220,7 +220,11 @@ class ArtifactsController(object):\\n\\t\\t\\t self._ensure_write_access(artifact, req.context)\\n\\t\\t\\t updated = artifact\\n\\t\\t\\t for change in changes:\\n-\\t\\t\\t\\tupdated = self._do_update_op(updated, change)\\n+\\t\\t\\t\\tif artifact.metadata.attributes.blobs.get(change['path']):\\n+\\t\\t\\t\\t\\tmsg = _('Invalid request PATCH for work with blob')\\n+\\t\\t\\t\\t\\traise webob.exc.HTTPBadRequest(explanation=msg)\\n+\\t\\t\\t\\telse:\\n+\\t\\t\\t\\t\\tupdated = self._do_update_op(updated, change)\\n\\t\\t\\t artifact_repo.save(updated)\\n\\t\\t\\t return self._get_artifact_with_dependencies(artifact_repo, id)\\n\\t\\t except (exception.InvalidJsonPatchPath,\\ndiff --git a/glance/tests/functional/glare/test_glare.py b/glance/tests/functional/glare/test_glare.py\\nindex ce80699f..af57ae99 100644\\n--- a/glance/tests/functional/glare/test_glare.py\\n+++ b/glance/tests/functional/glare/test_glare.py\\n@@ -1910,6 +1910,38 @@ paste.filter_factory = glance.tests.utils:FakeAuthMiddleware.factory\\n \\n\\t\\t self.assertEqual(1, len(result))\\n \\n+\\tdef test_operation_patch_with_blob(self):\\n+\\t\\tdata = {'name': 'art1',\\n+\\t\\t\\t\\t'version': '3.2'\\n+\\t\\t\\t\\t}\\n+\\t\\tart = self._create_artifact('withblob', data=data)\\n+\\n+\\t\\tmsg = 'Invalid request PATCH for work with blob'\\n+\\n+\\t\\tresult = self._check_artifact_patch(\\n+\\t\\t\\t'/withblob/v1.0/%s' % art['id'],\\n+\\t\\t\\tstatus=400,\\n+\\t\\t\\tdata=[{'op': 'replace',\\n+\\t\\t\\t\\t   'value': 'public',\\n+\\t\\t\\t\\t   'path': '/blob1'}])\\n+\\t\\tself.assertIn(msg, result)\\n+\\n+\\t\\tresult = self._check_artifact_patch(\\n+\\t\\t\\t'/withblob/v1.0/%s' % art['id'],\\n+\\t\\t\\tstatus=400,\\n+\\t\\t\\tdata=[{'op': 'remove',\\n+\\t\\t\\t\\t   'value': 'public',\\n+\\t\\t\\t\\t   'path': '/blob1'}])\\n+\\t\\tself.assertIn(msg, result)\\n+\\n+\\t\\tresult = self._check_artifact_patch(\\n+\\t\\t\\t'/withblob/v1.0/%s' % art['id'],\\n+\\t\\t\\tstatus=400,\\n+\\t\\t\\tdata=[{'op': 'add',\\n+\\t\\t\\t\\t   'value': 'public',\\n+\\t\\t\\t\\t   'path': '/blob1'}])\\n+\\t\\tself.assertIn(msg, result)\\n+\\n\\t def test_filter_by_bad_version(self):\\n\\t\\t bad_versions = ['kkk', '1.k', 'h.0', '1.3.hf', 's.9.2s2']\\n\\t\\t response_string = ('The format of the version %s is not valid. '",
         "def update(self, req, id, type_name, type_version, changes, **kwargs):\\n\\t\\tartifact_repo = self.gateway.get_artifact_repo(req.context)\\n\\t\\ttry:\\n\\t\\t\\tartifact = self._get_artifact_with_dependencies(artifact_repo, id,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttype_name,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttype_version)\\n\\t\\t\\tself._ensure_write_access(artifact, req.context)\\n\\t\\t\\tupdated = artifact\\n\\t\\t\\tfor change in changes:\\n\\t\\t\\t\\tif artifact.metadata.attributes.blobs.get(change['path']):\\n\\t\\t\\t\\t\\tmsg = _('Invalid request PATCH for work with blob')\\n\\t\\t\\t\\t\\traise webob.exc.HTTPBadRequest(explanation=msg)\\n\\t\\t\\t\\telse:\\n\\t\\t\\t\\t\\tupdated = self._do_update_op(updated, change)\\n\\t\\t\\tartifact_repo.save(updated)\\n\\t\\t\\treturn self._get_artifact_with_dependencies(artifact_repo, id)\\n\\t\\texcept (exception.InvalidJsonPatchPath,\\n\\t\\t\\t\\texception.Invalid) as e:\\n\\t\\t\\traise webob.exc.HTTPBadRequest(explanation=e.msg)\\n\\t\\texcept exception.NotFound as e:\\n\\t\\t\\traise webob.exc.HTTPNotFound(explanation=e.msg)\\n\\t\\texcept exception.Forbidden as e:\\n\\t\\t\\traise webob.exc.HTTPForbidden(explanation=e.msg)\\n\\t\\texcept exception.StorageQuotaFull as e:\\n\\t\\t\\tmsg = (_(\"Denying attempt to upload artifact because it exceeds \"\\n\\t\\t\\t\\t\\t \"the quota: %s\") % encodeutils.exception_to_unicode(e))\\n\\t\\t\\traise webob.exc.HTTPRequestEntityTooLarge(\\n\\t\\t\\t\\texplanation=msg, request=req, content_type='text/plain')\\n\\t\\texcept exception.LimitExceeded as e:\\n\\t\\t\\traise webob.exc.HTTPRequestEntityTooLarge(\\n\\t\\t\\t\\texplanation=e.msg, request=req, content_type='text/plain')\\n\\t\\texcept exception.NotAuthenticated as e:\\n\\t\\t\\traise webob.exc.HTTPUnauthorized(explanation=e.msg)\\n\\t@utils.mutating",
         "def update(self, req, id, type_name, type_version, changes, **kwargs):\\n\\t\\tartifact_repo = self.gateway.get_artifact_repo(req.context)\\n\\t\\ttry:\\n\\t\\t\\tartifact = self._get_artifact_with_dependencies(artifact_repo, id,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttype_name,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttype_version)\\n\\t\\t\\tself._ensure_write_access(artifact, req.context)\\n\\t\\t\\tupdated = artifact\\n\\t\\t\\tfor change in changes:\\n\\t\\t\\t\\tupdated = self._do_update_op(updated, change)\\n\\t\\t\\tartifact_repo.save(updated)\\n\\t\\t\\treturn self._get_artifact_with_dependencies(artifact_repo, id)\\n\\t\\texcept (exception.InvalidJsonPatchPath,\\n\\t\\t\\t\\texception.Invalid) as e:\\n\\t\\t\\traise webob.exc.HTTPBadRequest(explanation=e.msg)\\n\\t\\texcept exception.NotFound as e:\\n\\t\\t\\traise webob.exc.HTTPNotFound(explanation=e.msg)\\n\\t\\texcept exception.Forbidden as e:\\n\\t\\t\\traise webob.exc.HTTPForbidden(explanation=e.msg)\\n\\t\\texcept exception.StorageQuotaFull as e:\\n\\t\\t\\tmsg = (_(\"Denying attempt to upload artifact because it exceeds \"\\n\\t\\t\\t\\t\\t \"the quota: %s\") % encodeutils.exception_to_unicode(e))\\n\\t\\t\\traise webob.exc.HTTPRequestEntityTooLarge(\\n\\t\\t\\t\\texplanation=msg, request=req, content_type='text/plain')\\n\\t\\texcept exception.LimitExceeded as e:\\n\\t\\t\\traise webob.exc.HTTPRequestEntityTooLarge(\\n\\t\\t\\t\\texplanation=e.msg, request=req, content_type='text/plain')\\n\\t\\texcept exception.NotAuthenticated as e:\\n\\t\\t\\traise webob.exc.HTTPUnauthorized(explanation=e.msg)\\n\\t@utils.mutating",
         "def update(self, req, id, type_name, type_version, changes, **kwargs)",
         null,
         "Trigger a Missing if construct plus statements (MIFS) fault within the update function by implementing a bug. The function should fail due to removing the check for blob attributes in the change path before applying changes.",
         "Implement a bug in the update method to trigger a MIFS fault and to induce incorrect handling of blob attributes. The function should fail due to the absence of a check for blob attributes before applying changes.",
         "Implement a bug in the update method to trigger a MIFS fault and to induce incorrect handling of blob attributes.",
         "openstack",
         "3.9.0",
         "['test_glare.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MIFS"
        ],
        [
         "17",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def create(self, size):\\n\\t\\tself._run_command([\"create\"], None, str(size))",
         "def create(self, size):\\n\\t\\tself._run_command(\"create\", None, str(size))",
         "def create(self, size)",
         null,
         "Alter the behavior of the create function to introduce a Wrong Variable Used in Parameter of Function Call (WPFV) fault. The function should fail due to passing a string instead of a list to _run_command.",
         "Introduce an error in the create function to simulate wrong variable used in parameter of function call (WPFV). The function should fail due to incorrect parameter type, potentially causing command execution errors.",
         "Introduce an error in the create function to simulate wrong variable used in parameter of function call (WPFV).",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WPFV"
        ],
        [
         "18",
         "Uses None instead of mutables for function param defaults\\n\\nAddressing bug 1307878, changes use of mutable lists and dicts as\\ndefault arguments and defaults them within the function. Otherwise,\\nthose defaults can be unexpectedly persisted with the function between\\ninvocations and erupt into mass hysteria on the streets.\\n\\nTo my knowledge there aren't known cases of the current use causing\\nspecific issues, but needs addressing (even stylistically) to avoid\\nproblems in the future -- ones that may crop up as extremely subtle or\\nintermittent bugs...or worse, security vulnerabilities.\\n\\nIn Glance's case there are ACL-related methods using this, so\\nalthough I haven't confirmed one way or the other yet, I've marked it\\nwith SecurityImpact so that a more knowledgeable set of eyes can\\nreview it in this context as well.\\n\\nCloses-Bug: #1307878\\nSecurityImpact",
         "security",
         null,
         "https://github.com/python/cpython/commit/bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "bebe906ee7ddcc8785c927b559c930d62e972cbb",
         "PySecDB",
         "diff --git a/glance/store/__init__.py b/glance/store/__init__.py\\nindex 89f6900c..b0319aa6 100644\\n--- a/glance/store/__init__.py\\n+++ b/glance/store/__init__.py\\n@@ -411,8 +411,13 @@ def add_to_backend(context, scheme, image_id, data, size):\\n\\t\\t raise exception.StoreAddNotSupported\\n \\n \\n-def set_acls(context, location_uri, public=False, read_tenants=[],\\n-\\t\\t\\t write_tenants=[]):\\n+def set_acls(context, location_uri, public=False, read_tenants=None,\\n+\\t\\t\\t write_tenants=None):\\n+\\tif read_tenants is None:\\n+\\t\\tread_tenants = []\\n+\\tif write_tenants is None:\\n+\\t\\twrite_tenants = []\\n+\\n\\t loc = location.get_location_from_uri(location_uri)\\n\\t scheme = get_store_from_location(location_uri)\\n\\t store = get_store_from_scheme(context, scheme, loc)\\ndiff --git a/glance/store/base.py b/glance/store/base.py\\nindex 66491946..dc25534d 100644\\n--- a/glance/store/base.py\\n+++ b/glance/store/base.py\\n@@ -150,8 +150,8 @@ class Store(object):\\n\\t\\t \"\"\"\\n\\t\\t raise NotImplementedError\\n \\n-\\tdef set_acls(self, location, public=False, read_tenants=[],\\n-\\t\\t\\t\\t write_tenants=[]):\\n+\\tdef set_acls(self, location, public=False, read_tenants=None,\\n+\\t\\t\\t\\t write_tenants=None):\\n\\t\\t \"\"\"\\n\\t\\t Sets the read and write access control list for an image in the\\n\\t\\t backend store.\\ndiff --git a/glance/tests/unit/common/test_property_utils.py b/glance/tests/unit/common/test_property_utils.py\\nindex 8522586c..8cb28aa6 100644\\n--- a/glance/tests/unit/common/test_property_utils.py\\n+++ b/glance/tests/unit/common/test_property_utils.py\\n@@ -40,7 +40,9 @@ CONFIG_SECTIONS = [\\n ]\\n \\n \\n-def create_context(policy, roles=[]):\\n+def create_context(policy, roles=None):\\n+\\tif roles is None:\\n+\\t\\troles = []\\n\\t return glance.context.RequestContext(roles=roles,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  policy_enforcer=policy)\\n \\ndiff --git a/glance/tests/unit/common/test_wsgi.py b/glance/tests/unit/common/test_wsgi.py\\nindex 1c100301..b10767fd 100644\\n--- a/glance/tests/unit/common/test_wsgi.py\\n+++ b/glance/tests/unit/common/test_wsgi.py\\n@@ -33,7 +33,10 @@ from glance.tests import utils as test_utils\\n \\n class RequestTest(test_utils.BaseTestCase):\\n \\n-\\tdef _set_expected_languages(self, all_locales=[], avail_locales=None):\\n+\\tdef _set_expected_languages(self, all_locales=None, avail_locales=None):\\n+\\t\\tif all_locales is None:\\n+\\t\\t\\tall_locales = []\\n+\\n\\t\\t # Override localedata.locale_identifiers to return some locales.\\n\\t\\t def returns_some_locales(*args, **kwargs):\\n\\t\\t\\t return all_locales\\ndiff --git a/glance/tests/unit/test_auth.py b/glance/tests/unit/test_auth.py\\nindex 979b37e7..781b97f8 100644\\n--- a/glance/tests/unit/test_auth.py\\n+++ b/glance/tests/unit/test_auth.py\\n@@ -61,7 +61,10 @@ class V2Token(object):\\n\\t\\t service = catalog[-1]\\n\\t\\t service['endpoints'] = [self.base_endpoint]\\n \\n-\\tdef add_service(self, s_type, region_list=[]):\\n+\\tdef add_service(self, s_type, region_list=None):\\n+\\t\\tif region_list is None:\\n+\\t\\t\\tregion_list = []\\n+\\n\\t\\t catalog = self.tok['access']['serviceCatalog']\\n\\t\\t service_type = {\"type\": s_type, \"name\": \"glance\"}\\n\\t\\t catalog.append(service_type)\\ndiff --git a/glance/tests/unit/test_swift_store.py b/glance/tests/unit/test_swift_store.py\\nindex 1bf87606..bd95e967 100644\\n--- a/glance/tests/unit/test_swift_store.py\\n+++ b/glance/tests/unit/test_swift_store.py\\n@@ -754,8 +754,11 @@ class TestStoreAuthV2(TestStoreAuthV1):\\n class FakeConnection(object):\\n\\t def __init__(self, authurl, user, key, retries=5, preauthurl=None,\\n\\t\\t\\t\\t  preauthtoken=None, snet=False, starting_backoff=1,\\n-\\t\\t\\t\\t tenant_name=None, os_options={}, auth_version=\"1\",\\n+\\t\\t\\t\\t tenant_name=None, os_options=None, auth_version=\"1\",\\n\\t\\t\\t\\t  insecure=False, ssl_compression=True):\\n+\\t\\tif os_options is None:\\n+\\t\\t\\tos_options = {}\\n+\\n\\t\\t self.authurl = authurl\\n\\t\\t self.user = user\\n\\t\\t self.key = key\\ndiff --git a/glance/tests/unit/utils.py b/glance/tests/unit/utils.py\\nindex a43dea3b..e0a9caab 100644\\n--- a/glance/tests/unit/utils.py\\n+++ b/glance/tests/unit/utils.py\\n@@ -107,7 +107,12 @@ class FakeStoreAPI(object):\\n\\t\\t pass\\n \\n\\t def set_acls(self, context, uri, public=False,\\n-\\t\\t\\t\\t read_tenants=[], write_tenants=[]):\\n+\\t\\t\\t\\t read_tenants=None, write_tenants=None):\\n+\\t\\tif read_tenants is None:\\n+\\t\\t\\tread_tenants = []\\n+\\t\\tif write_tenants is None:\\n+\\t\\t\\twrite_tenants = []\\n+\\n\\t\\t self.acls[uri] = {\\n\\t\\t\\t 'public': public,\\n\\t\\t\\t 'read': read_tenants,\\ndiff --git a/glance/tests/unit/v1/test_api.py b/glance/tests/unit/v1/test_api.py\\nindex e1c5b1a8..d52f3011 100644\\n--- a/glance/tests/unit/v1/test_api.py\\n+++ b/glance/tests/unit/v1/test_api.py\\n@@ -3242,7 +3242,9 @@ class TestAPIProtectedProps(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\n@@ -3944,7 +3946,9 @@ class TestAPIPropertyQuotas(base.IsolatedUnitTest):\\n\\t\\t db_models.unregister_models(db_api.get_engine())\\n\\t\\t db_models.register_models(db_api.get_engine())\\n \\n-\\tdef _create_admin_image(self, props={}):\\n+\\tdef _create_admin_image(self, props=None):\\n+\\t\\tif props is None:\\n+\\t\\t\\tprops = {}\\n\\t\\t request = unit_test_utils.get_fake_request(path='/images')\\n\\t\\t headers = {'x-image-meta-disk-format': 'ami',\\n\\t\\t\\t\\t\\t'x-image-meta-container-format': 'ami',\\ndiff --git a/glance/tests/utils.py b/glance/tests/utils.py\\nindex dc19ea54..9758c049 100644\\n--- a/glance/tests/utils.py\\n+++ b/glance/tests/utils.py\\n@@ -445,11 +445,13 @@ class RegistryAPIMixIn(object):\\n\\t\\t\\t created_at=created_at, updated_at=updated_at,\\n\\t\\t\\t **kwargs)\\n \\n-\\tdef get_api_response_ext(self, http_resp, url='/images', headers={},\\n+\\tdef get_api_response_ext(self, http_resp, url='/images', headers=None,\\n\\t\\t\\t\\t\\t\\t\\t  body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t  content_type=None):\\n\\t\\t if api is None:\\n\\t\\t\\t api = self.api\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t req = webob.Request.blank(url)\\n\\t\\t for k, v in headers.iteritems():\\n\\t\\t\\t req.headers[k] = v\\n@@ -563,7 +565,9 @@ class HttplibWsgiAdapter(object):\\n\\t\\t self.app = app\\n\\t\\t self.req = None\\n \\n-\\tdef request(self, method, url, body=None, headers={}):\\n+\\tdef request(self, method, url, body=None, headers=None):\\n+\\t\\tif headers is None:\\n+\\t\\t\\theaders = {}\\n\\t\\t self.req = webob.Request.blank(url, method=method, headers=headers)\\n\\t\\t self.req.body = body",
         "def request(self, method, url, body=None, headers=None):\\n\\t\\tif headers is None:\\n\\t\\t\\theaders = {}\\n\\t\\tself.req = webob.Request.blank(url, method=method, headers=headers)\\n\\t\\tself.req.body = body",
         "def request(self, method, url, body=None, headers={}):\\n\\t\\tself.req = webob.Request.blank(url, method=method, headers=headers)\\n\\t\\tself.req.body = body",
         "def request(self, method, url, body=None, headers={})",
         null,
         "Cause a Wrong Value Used in Variable Initialization (WVIV) fault by injecting an error into request. The function should fail due to using {} as default value for headers parameter instead of None, causing issues with mutable default arguments.",
         "Trigger a wrong value used in variable initialization (WVIV) fault within the request function. The function should fail due to using a mutable default argument.",
         "Trigger a wrong value used in variable initialization (WVIV) fault within the request function.",
         "openstack",
         "3.9.0",
         "['test_swift_store.py', 'test_auth.py', 'test_property_utils.py', 'test_wsgi.py', 'test_api.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WVIV"
        ],
        [
         "19",
         "New -k/--insecure command line option\\n\\nFix for bug 929591.\\n\\nChange glance to require server certificate validation\\nby default when using https. The standard system\\nCA file will be used if available (and an alternative was not\\nprovided).\\n\\nThe --insecure option can be used by clients to skip server\\ncertificate validation if appropriate.\\n\\n  If the standard CA file is not suitable they will need to provide\\n  a CA file or else create an 'insecure' glance client.\\n  certificate validation.\\n  system CA file is installed then that file will be used by default.\\n  It probably makes sense for the glance package to have a\\n  dependency on whichever package provides the default CA bundle.\\n  (In Ubuntu this is 'ca-certificates')",
         "security",
         null,
         "https://github.com/python/cpython/commit/0f0fe2ba1b772e6964241c0631683b306fff23c0",
         "0f0fe2ba1b772e6964241c0631683b306fff23c0",
         "PySecDB",
         "diff --git a/bin/glance b/bin/glance\\nindex fd44f248..8aefea53 100755\\n--- a/bin/glance\\n+++ b/bin/glance\\n@@ -754,7 +754,7 @@ def get_client(options):\\n\\t\\t\\t\\t\\t\\t\\t\\t use_ssl=use_ssl,\\n\\t\\t\\t\\t\\t\\t\\t\\t auth_tok=options.auth_token or \\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t os.getenv('OS_TOKEN'),\\n-\\t\\t\\t\\t\\t\\t\\t\\tcreds=creds)\\n+\\t\\t\\t\\t\\t\\t\\t\\tcreds=creds, insecure=options.insecure)\\n \\n \\n def create_options(parser):\\n@@ -781,6 +781,12 @@ def create_options(parser):\\n\\t\\t\\t\\t\\t\\t\\t\"(http/https) of the glance server, for example \"\\n\\t\\t\\t\\t\\t\\t\\t\"-U https://localhost:\" + str(DEFAULT_PORT) +\\n\\t\\t\\t\\t\\t\\t\\t\"/v1 Default: None\")\\n+\\tparser.add_option('-k', '--insecure', dest=\"insecure\",\\n+\\t\\t\\t\\t\\t  default=False, action=\"store_true\",\\n+\\t\\t\\t\\t\\t  help=\"Explicitly allow glance to perform \\\"insecure\\\" \"\\n+\\t\\t\\t\\t\\t  \"SSL (https) requests. The server's certificate will \"\\n+\\t\\t\\t\\t\\t  \"not be verified against any certificate authorities. \"\\n+\\t\\t\\t\\t\\t  \"This option should be used with caution.\")\\n\\t parser.add_option('-A', '--auth_token', dest=\"auth_token\",\\n\\t\\t\\t\\t\\t   metavar=\"TOKEN\", default=None,\\n\\t\\t\\t\\t\\t   help=\"Authentication token to use to identify the \"\\n@@ -810,7 +816,7 @@ def create_options(parser):\\n\\t\\t\\t\\t\\t   help=\"Sort results by this image attribute.\")\\n\\t parser.add_option('--sort_dir', dest=\"sort_dir\", metavar=\"[desc|asc]\",\\n\\t\\t\\t\\t\\t   help=\"Sort results in this direction.\")\\n-\\tparser.add_option('-f', '--force', dest=\"force\", metavar=\"FORCE\",\\n+\\tparser.add_option('-f', '--force', dest=\"force\",\\n\\t\\t\\t\\t\\t   default=False, action=\"store_true\",\\n\\t\\t\\t\\t\\t   help=\"Prevent select actions from requesting \"\\n\\t\\t\\t\\t\\t\\t\\t\"user confirmation\")\\ndiff --git a/doc/source/glance.rst b/doc/source/glance.rst\\nindex 1a86f4c9..e105eb48 100644\\n--- a/doc/source/glance.rst\\n+++ b/doc/source/glance.rst\\n@@ -100,6 +100,10 @@ a brief help message, like so::\\n\\t\\t\\t\\t\\t\\t   specify the hostname, port and protocol (http/https)\\n\\t\\t\\t\\t\\t\\t   of the glance server, for example -U\\n\\t\\t\\t\\t\\t\\t   https://localhost:9292/v1 Default: None\\n+\\t-k, --insecure\\t\\tExplicitly allow glance to perform insecure SSL\\n+\\t\\t\\t\\t\\t\\t  requests. The server certificate will not be\\n+\\t\\t\\t\\t\\t\\t  verified against any certificate authorities.\\n+\\t\\t\\t\\t\\t\\t  This option should be used with caution.\\n\\t --limit=LIMIT\\t\\t Page size to use while requesting image metadata\\n\\t --marker=MARKER\\t   Image index after which to begin pagination\\n\\t --sort_key=KEY\\t\\tSort results by this image attribute.\\n@@ -153,7 +157,7 @@ Important Information about Uploading Images\\n Before we go over the commands for adding an image to Glance, it is\\n important to understand that Glance **does not currently inspect** the image\\n files you add to it. In other words, **Glance only understands what you tell it,\\n-via attributes and custom properties**. \\n+via attributes and custom properties**.\\n \\n If the file extension of the file you upload to Glance ends in '.vhd', Glance\\n **does not** know that the image you are uploading has a disk format of ``vhd``.\\ndiff --git a/doc/source/man/glance.rst b/doc/source/man/glance.rst\\nindex 16ecdc11..ae174f9a 100644\\n--- a/doc/source/man/glance.rst\\n+++ b/doc/source/man/glance.rst\\n@@ -78,10 +78,10 @@ OPTIONS\\n \\n   **-v, --verbose**\\n\\t\\t Print more verbose output\\n- \\n+\\n   **-d, --debug**\\n\\t\\t Print more verbose output\\n- \\n+\\n   **-H ADDRESS, --host=ADDRESS**\\n\\t\\t Address of Glance API host. Default: 0.0.0.0\\n \\n@@ -90,10 +90,15 @@ OPTIONS\\n \\n   **-U URL, --url=URL**\\n\\t\\t URL of Glance service. This option can be used to specify the hostname,\\n-\\t\\tport and protocol (http/https) of the glance server, for example \\n-\\t\\t-U https://localhost:9292/v1 \\n+\\t\\tport and protocol (http/https) of the glance server, for example\\n+\\t\\t-U https://localhost:9292/v1\\n\\t\\t Default: None\\n \\n+  **-k, --insecure**\\n+\\t\\tExplicitly allow glance to perform insecure SSL (https) requests.\\n+\\t\\tThe server certificate will not be verified against any certificate\\n+\\t\\tauthorities. This option should be used with caution.\\n+\\n   **-A TOKEN, --auth_token=TOKEN**\\n\\t\\t Authentication token to use to identify the client to the glance server\\n \\ndiff --git a/glance/common/client.py b/glance/common/client.py\\nindex 9a3c3bfb..9e08c15a 100644\\n--- a/glance/common/client.py\\n+++ b/glance/common/client.py\\n@@ -148,13 +148,14 @@ class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\t \"\"\"\\n \\n\\t def __init__(self, host, port, key_file, cert_file,\\n-\\t\\t\\t\\t ca_file, timeout=None):\\n+\\t\\t\\t\\t ca_file, timeout=None, insecure=False):\\n\\t\\t httplib.HTTPSConnection.__init__(self, host, port, key_file=key_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  cert_file=cert_file)\\n\\t\\t self.key_file = key_file\\n\\t\\t self.cert_file = cert_file\\n\\t\\t self.ca_file = ca_file\\n\\t\\t self.timeout = timeout\\n+\\t\\tself.insecure = insecure\\n \\n\\t def connect(self):\\n\\t\\t \"\"\"\\n@@ -170,14 +171,14 @@ class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\t\\t if self._tunnel_host:\\n\\t\\t\\t self.sock = sock\\n\\t\\t\\t self._tunnel()\\n-\\t\\t# If there's no CA File, don't force Server Certificate Check\\n-\\t\\tif self.ca_file:\\n+\\t\\t# Check CA file unless 'insecure' is specificed\\n+\\t\\tif self.insecure is True:\\n\\t\\t\\t self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n\\t\\t else:\\n\\t\\t\\t self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n \\n \\n class BaseClient(object):\\n@@ -186,6 +187,12 @@ class BaseClient(object):\\n \\n\\t DEFAULT_PORT = 80\\n\\t DEFAULT_DOC_ROOT = None\\n+\\t# Standard CA file locations for Debian/Ubuntu, RedHat/Fedora,\\n+\\t# Suse, FreeBSD/OpenBSD\\n+\\tDEFAULT_CA_FILE_PATH = '/etc/ssl/certs/ca-certificates.crt:'\\\\n+\\t\\t'/etc/pki/tls/certs/ca-bundle.crt:'\\\\n+\\t\\t'/etc/ssl/ca-bundle.pem:'\\\\n+\\t\\t'/etc/ssl/cert.pem'\\n \\n\\t OK_RESPONSE_CODES = (\\n\\t\\t httplib.OK,\\n@@ -203,8 +210,8 @@ class BaseClient(object):\\n\\t )\\n \\n\\t def __init__(self, host, port=None, use_ssl=False, auth_tok=None,\\n-\\t\\t\\t\\t creds=None, doc_root=None,\\n-\\t\\t\\t\\t key_file=None, cert_file=None, ca_file=None):\\n+\\t\\t\\t\\t creds=None, doc_root=None, key_file=None,\\n+\\t\\t\\t\\t cert_file=None, ca_file=None, insecure=False):\\n\\t\\t \"\"\"\\n\\t\\t Creates a new client to some service.\\n \\n@@ -231,6 +238,8 @@ class BaseClient(object):\\n\\t\\t\\t\\t\\t\\t If use_ssl is True, and this param is None (the\\n\\t\\t\\t\\t\\t\\t default), then an environ variable\\n\\t\\t\\t\\t\\t\\t GLANCE_CLIENT_CA_FILE is looked for.\\n+\\t\\t:param insecure: Optional. If set then the server's certificate\\n+\\t\\t\\t\\t\\t\\t will not be verified.\\n\\t\\t \"\"\"\\n\\t\\t self.host = host\\n\\t\\t self.port = port or self.DEFAULT_PORT\\n@@ -286,7 +295,15 @@ class BaseClient(object):\\n\\t\\t\\t\\t msg = _(\"The CA file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t \"exist\") % ca_file\\n\\t\\t\\t\\t raise exception.ClientConnectionError(msg)\\n+\\n+\\t\\t\\tif ca_file is None:\\n+\\t\\t\\t\\tfor ca in self.DEFAULT_CA_FILE_PATH.split(\":\"):\\n+\\t\\t\\t\\t\\tif os.path.exists(ca):\\n+\\t\\t\\t\\t\\t\\tca_file = ca\\n+\\t\\t\\t\\t\\t\\tbreak\\n+\\n\\t\\t\\t self.connect_kwargs['ca_file'] = ca_file\\n+\\t\\t\\tself.connect_kwargs['insecure'] = insecure\\n \\n\\t def set_auth_token(self, auth_tok):\\n\\t\\t \"\"\"\\ndiff --git a/glance/tests/functional/test_ssl.py b/glance/tests/functional/test_ssl.py\\nindex b0fdf622..4c94d1cf 100644\\n--- a/glance/tests/functional/test_ssl.py\\n+++ b/glance/tests/functional/test_ssl.py\\n@@ -40,6 +40,8 @@ import os\\n import tempfile\\n import unittest\\n \\n+from glance import client as glance_client\\n+from glance.common import exception\\n from glance.common import utils\\n from glance.store.location import get_location_from_uri\\n from glance.tests import functional\\n@@ -62,6 +64,12 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t self.inited = False\\n\\t\\t self.disabled = True\\n \\n+\\t\\t# Test key/cert/CA file created as per:\\n+\\t\\t#   http://blog.didierstevens.com/2008/12/30/\\n+\\t\\t#\\t howto-make-your-own-cert-with-openssl/\\n+\\t\\t# Note that for these tests certificate.crt had to\\n+\\t\\t# be created with 'Common Name' set to 0.0.0.0\\n+\\n\\t\\t self.key_file = os.path.join(TEST_VAR_DIR, 'privatekey.key')\\n\\t\\t if not os.path.exists(self.key_file):\\n\\t\\t\\t self.disabled_message = \"Could not find private key file\"\\n@@ -69,11 +77,17 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t\\t return\\n \\n\\t\\t self.cert_file = os.path.join(TEST_VAR_DIR, 'certificate.crt')\\n-\\t\\tif not os.path.exists(self.key_file):\\n+\\t\\tif not os.path.exists(self.cert_file):\\n\\t\\t\\t self.disabled_message = \"Could not find certificate file\"\\n\\t\\t\\t self.inited = True\\n\\t\\t\\t return\\n \\n+\\t\\tself.ca_file = os.path.join(TEST_VAR_DIR, 'ca.crt')\\n+\\t\\tif not os.path.exists(self.ca_file):\\n+\\t\\t\\tself.disabled_message = \"Could not find CA file\"\\n+\\t\\t\\tself.inited = True\\n+\\t\\t\\treturn\\n+\\n\\t\\t self.inited = True\\n\\t\\t self.disabled = False\\n \\n@@ -1230,3 +1244,94 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t self.assertEqual(response.status, 404)\\n \\n\\t\\t self.stop_servers()\\n+\\n+\\t@skip_if_disabled\\n+\\tdef test_certificate_validation(self):\\n+\\t\\t\"\"\"\\n+\\t\\tCheck SSL client cerificate verification\\n+\\t\\t\"\"\"\\n+\\t\\tself.cleanup()\\n+\\t\\tself.start_servers(**self.__dict__.copy())\\n+\\n+\\t\\t# 0. GET /images\\n+\\t\\t# Verify no public images\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\t# 1. POST /images with public image named Image1\\n+\\t\\theaders = {'Content-Type': 'application/octet-stream',\\n+\\t\\t\\t\\t   'X-Image-Meta-Name': 'Image1',\\n+\\t\\t\\t\\t   'X-Image-Meta-Status': 'active',\\n+\\t\\t\\t\\t   'X-Image-Meta-Container-Format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Disk-Format': 'vdi',\\n+\\t\\t\\t\\t   'X-Image-Meta-Size': '19',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True'}\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 201)\\n+\\t\\tdata = json.loads(content)\\n+\\n+\\t\\timage_id = data['image']['id']\\n+\\n+\\t\\t# 2. Attempt to delete the image *without* CA file\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\tsecure_cli = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  use_ssl=True, insecure=False)\\n+\\t\\ttry:\\n+\\t\\t\\tsecure_cli.delete_image(image_id)\\n+\\t\\t\\tself.fail(\"Client with no CA file deleted image %s\" % image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tpass\\n+\\n+\\t\\t# 3. Delete the image with a secure client *with* CA file\\n+\\t\\tsecure_cli2 = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   use_ssl=True, ca_file=self.ca_file,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   insecure=False)\\n+\\t\\ttry:\\n+\\t\\t\\tsecure_cli2.delete_image(image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tself.fail(\"Secure client failed to delete image %s\" % image_id)\\n+\\n+\\t\\t# Verify image is deleted\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\t# 4. POST another image\\n+\\t\\theaders = {'Content-Type': 'application/octet-stream',\\n+\\t\\t\\t\\t   'X-Image-Meta-Name': 'Image1',\\n+\\t\\t\\t\\t   'X-Image-Meta-Status': 'active',\\n+\\t\\t\\t\\t   'X-Image-Meta-Container-Format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Disk-Format': 'vdi',\\n+\\t\\t\\t\\t   'X-Image-Meta-Size': '19',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True'}\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 201)\\n+\\t\\tdata = json.loads(content)\\n+\\n+\\t\\timage_id = data['image']['id']\\n+\\n+\\t\\t# 5. Delete the image with an insecure client\\n+\\t\\tinsecure_cli = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tuse_ssl=True, insecure=True)\\n+\\t\\ttry:\\n+\\t\\t\\tinsecure_cli.delete_image(image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tself.fail(\"Insecure client failed to delete image\")\\n+\\n+\\t\\t# Verify image is deleted\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\tself.stop_servers()\\ndiff --git a/glance/tests/var/ca.crt b/glance/tests/var/ca.crt\\nnew file mode 100644\\nindex 00000000..9d66ca62\\n--- /dev/null\\n+++ b/glance/tests/var/ca.crt\\n@@ -0,0 +1,35 @@\\n+-----BEGIN CERTIFICATE-----\\n+MIIGDDCCA/SgAwIBAgIJAPSvwQYk4qI4MA0GCSqGSIb3DQEBBQUAMGExCzAJBgNV\\n+BAYTAkFVMRMwEQYDVQQIEwpTb21lLVN0YXRlMRUwEwYDVQQKEwxPcGVuc3RhY2sg\\n+Q0ExEjAQBgNVBAsTCUdsYW5jZSBDQTESMBAGA1UEAxMJR2xhbmNlIENBMB4XDTEy\\n+MDIwOTE3MTAwMloXDTIyMDIwNjE3MTAwMlowYTELMAkGA1UEBhMCQVUxEzARBgNV\\n+BAgTClNvbWUtU3RhdGUxFTATBgNVBAoTDE9wZW5zdGFjayBDQTESMBAGA1UECxMJ\\n+R2xhbmNlIENBMRIwEAYDVQQDEwlHbGFuY2UgQ0EwggIiMA0GCSqGSIb3DQEBAQUA\\n+A4ICDwAwggIKAoICAQDmf+fapWfzy1Uylus0KGalw4X/5xZ+ltPVOr+IdCPbstvi\\n+RTC5g+O+TvXeOP32V/cnSY4ho/+f2q730za+ZA/cgWO252rcm3Q7KTJn3PoqzJvX\\n+/l3EXe3/TCrbzgZ7lW3QLTCTEE2eEzwYG3wfDTOyoBq+F6ct6ADh+86gmpbIRfYI\\n+N+ixB0hVyz9427PTof97fL7qxxkjAayB28OfwHrkEBl7iblNhUC0RoH+/H9r5GEl\\n+GnWiebxfNrONEHug6PHgiaGq7/Dj+u9bwr7J3/NoS84I08ajMnhlPZxZ8bS/O8If\\n+ceWGZv7clPozyhABT/otDfgVcNH1UdZ4zLlQwc1MuPYN7CwxrElxc8Quf94ttGjb\\n+tfGTl4RTXkDofYdG1qBWW962PsGl2tWmbYDXV0q5JhV/IwbrE1X9f+OksJQne1/+\\n+dZDxMhdf2Q1V0P9hZZICu4+YhmTMs5Mc9myKVnzp4NYdX5fXoB/uNYph+G7xG5IK\\n+WLSODKhr1wFGTTcuaa8LhOH5UREVenGDJuc6DdgX9a9PzyJGIi2ngQ03TJIkCiU/\\n+4J/r/vsm81ezDiYZSp2j5JbME+ixW0GBLTUWpOIxUSHgUFwH5f7lQwbXWBOgwXQk\\n+BwpZTmdQx09MfalhBtWeu4/6BnOCOj7e/4+4J0eVxXST0AmVyv8YjJ2nz1F9oQID\\n+AQABo4HGMIHDMB0GA1UdDgQWBBTk7Krj4bEsTjHXaWEtI2GZ5ACQyTCBkwYDVR0j\\n+BIGLMIGIgBTk7Krj4bEsTjHXaWEtI2GZ5ACQyaFlpGMwYTELMAkGA1UEBhMCQVUx\\n+EzARBgNVBAgTClNvbWUtU3RhdGUxFTATBgNVBAoTDE9wZW5zdGFjayBDQTESMBAG\\n+A1UECxMJR2xhbmNlIENBMRIwEAYDVQQDEwlHbGFuY2UgQ0GCCQD0r8EGJOKiODAM\\n+BgNVHRMEBTADAQH/MA0GCSqGSIb3DQEBBQUAA4ICAQA8Zrss/MiwFHGmDlercE0h\\n+UvzA54n/EvKP9nP3jHM2qW/VPfKdnFw99nEPFLhb+lN553vdjOpCYFm+sW0Z5Mi4\\n+qsFkk4AmXIIEFOPt6zKxMioLYDQ9Sw/BUv6EZGeANWr/bhmaE+dMcKJt5le/0jJm\\n+2ahsVB9fbFu9jBFeYb7Ba/x2aLkEGMxaDLla+6EQhj148fTnS1wjmX9G2cNzJvj/\\n++C2EfKJIuDJDqw2oS2FGVpP37FA2Bz2vga0QatNneLkGKCFI3ZTenBznoN+fmurX\\n+TL3eJE4IFNrANCcdfMpdyLAtXz4KpjcehqpZMu70er3d30zbi1l0Ajz4dU+WKz/a\\n+NQES+vMkT2wqjXHVTjrNwodxw3oLK/EuTgwoxIHJuplx5E5Wrdx9g7Gl1PBIJL8V\\n+xiOYS5N7CakyALvdhP7cPubA2+TPAjNInxiAcmhdASS/Vrmpvrkat6XhGn8h9liv\\n+ysDOpMQmYQkmgZBpW8yBKK7JABGGsJADJ3E6J5MMWBX2RR4kFoqVGAzdOU3oyaTy\\n+I0kz5sfuahaWpdYJVlkO+esc0CRXw8fLDYivabK2tOgUEWeZsZGZ9uK6aV1VxTAY\\n+9Guu3BJ4Rv/KP/hk7mP8rIeCwotV66/2H8nq72ImQhzSVyWcxbFf2rJiFQJ3BFwA\\n+WoRMgEwjGJWqzhJZUYpUAQ==\\n+-----END CERTIFICATE-----\\ndiff --git a/glance/tests/var/certificate.crt b/glance/tests/var/certificate.crt\\nindex 9bb6dd1d..3c1aa636 100644\\n--- a/glance/tests/var/certificate.crt\\n+++ b/glance/tests/var/certificate.crt\\n@@ -1,18 +1,30 @@\\n -----BEGIN CERTIFICATE-----\\n-MIIC4DCCAcigAwIBAgIBATANBgkqhkiG9w0BAQUFADATMREwDwYDVQQDEwhNeVRl\\n-c3RDQTAeFw0xMTA3MjExNTA1NDZaFw0xMjA3MjAxNTA1NDZaMCMxEDAOBgNVBAMT\\n-B2FobWFkcGMxDzANBgNVBAoTBnNlcnZlcjCCASIwDQYJKoZIhvcNAQEBBQADggEP\\n-ADCCAQoCggEBAO9zpczf+W4DoK2z8oFbsZfbvz1y/yQOnrQYvb1zv1IieT+QA+Ti\\n-N64N/sgR/cR7YEIXDnhij8yE1JTWMk1W6g4m7TGacUMXD/WAcsTM7kRol/FVksdn\\n-F51qxCYqWUPQ3xiTfBg2SJWvJCUGowvz06xh8JeOEXLbALC5xrzrM3hclpdbrKYE\\n-oe8kikI/K0TKpu52VJJrTBGPHMsw+eIqL2Ix5pWHh7DPfjBiiG7khsJxN7xSqLbX\\n-LrhDi24nTM9pndaqABkmPYQ9qd11SoAUB82QAAGj8A7iR/DnAzAfJl1usvQp+Me6\\n-sR3TPY27zifBbD04tiROi1swM/1xRH7qOpkCAwEAAaMvMC0wCQYDVR0TBAIwADAL\\n-BgNVHQ8EBAMCBSAwEwYDVR0lBAwwCgYIKwYBBQUHAwEwDQYJKoZIhvcNAQEFBQAD\\n-ggEBAIJvnQjkEDFvLT7NiyFrO938BuxdQH2mX2N7Fz86myZLcGpr5NCdLvT9tD9f\\n-6KqrR8e839pYVPZY80cBpGTmRmzW3xLsmGCFHPHt4p1tkqSP1R5iLzKDe8jawHhD\\n-sch8P9URRhW9ZgBzA4xiv9FnIxZ70uDr04uX/sR/j41HGBS8YW6dJvr9Y2SpGqSS\\n-rR2btnNZ945dau6CPLRNd9Fls3Qjx03PnsmZ5ikSuV0pT1sPQmhhw7rBYV/b2ff+\\n-z/4cRtZrR00NVc74IEXLoujIjUUpFC83in10PKQmAvKYTeTdXns48eC4Cwqe8eaM\\n-N0YtxqQvSTsUo6vPM28NR99Fbow=\\n+MIIFLjCCAxYCAQEwDQYJKoZIhvcNAQEFBQAwYTELMAkGA1UEBhMCQVUxEzARBgNV\\n+BAgTClNvbWUtU3RhdGUxFTATBgNVBAoTDE9wZW5zdGFjayBDQTESMBAGA1UECxMJ\\n+R2xhbmNlIENBMRIwEAYDVQQDEwlHbGFuY2UgQ0EwHhcNMTIwMjA5MTcxMDUzWhcN\\n+MjIwMjA2MTcxMDUzWjBZMQswCQYDVQQGEwJBVTETMBEGA1UECBMKU29tZS1TdGF0\\n+ZTESMBAGA1UEChMJT3BlbnN0YWNrMQ8wDQYDVQQLEwZHbGFuY2UxEDAOBgNVBAMT\\n+BzAuMC4wLjAwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDXpUkQN6pu\\n+avo+gz3o1K4krVdPl1m7NjNJDyD/+ZH0EGNcEN7iag1qPE7JsjqGPNZsQK1dMoXb\\n+Sz+OSi9qvNeJnBcfwUx5qTAtwyAb9AxGkwuMafIU+lWbsclo+dPGsja01ywbXTCZ\\n+bF32iqnpOMYhfxWUdoQYiBkhxxhW9eMPKLS/KkP8/bx+Vaa2XJiAebqkd9nrksAA\\n+BeGc9mlafYBEmiChPdJEPw+1ePA4QVq9aPepDsqAKtGN8JLpmoC3BdxQQTbbwL3Q\\n+8fTXK4tCNUaVk4AbDy/McFq6y0ocQoBPJjihOY35mWG/OLtcI99yPOpWGnps/5aG\\n+/64DDJ2D67Fnaj6gKHV+6TXFO8KZxlnxtgtiZDJBZkneTBt9ArSOv+l6NBsumRz0\\n+iEJ4o4H1S2TSMnprAvX7WnGtc6Xi9gXahYcDHEelwwYzqAiTBv6hxSp4MZ2dNXa+\\n+KzOitC7ZbV2qsg0au0wjfE/oSQ3NvsvUr8nOmfutJTvHRAwbC1v4G/tuAsO7O0w2\\n+0u2B3u+pG06m5+rnEqp+rB9hmukRYTfgEFRRsVIvpFl/cwvPXKRcX03UIMx+lLr9\\n+Ft+ep7YooBhY3wY2kwCxD4lRYNmbwsCIVywZt40f/4ad98TkufR9NhsfycxGeqbr\\n+mTMFlZ8TTlmP82iohekKCOvoyEuTIWL2+wIDAQABMA0GCSqGSIb3DQEBBQUAA4IC\\n+AQBMUBgV0R+Qltf4Du7u/8IFmGAoKR/mktB7R1gRRAqsvecUt7kIwBexGdavGg1y\\n+0pU0+lgUZjJ20N1SlPD8gkNHfXE1fL6fmMjWz4dtYJjzRVhpufHPeBW4tl8DgHPN\\n+rBGAYQ+drDSXaEjiPQifuzKx8WS+DGA3ki4co5mPjVnVH1xvLIdFsk89z3b3YD1k\\n+yCJ/a9K36x6Z/c67JK7s6MWtrdRF9+MVnRKJ2PK4xznd1kBz16V+RA466wBDdARY\\n+vFbtkafbEqOb96QTonIZB7+fAldKDPZYnwPqasreLmaGOaM8sxtlPYAJ5bjDONbc\\n+AaXG8BMRQyO4FyH237otDKlxPyHOFV66BaffF5S8OlwIMiZoIvq+IcTZOdtDUSW2\\n+KHNLfe5QEDZdKjWCBrfqAfvNuG13m03WqfmcMHl3o/KiPJlx8l9Z4QEzZ9xcyQGL\\n+cncgeHM9wJtzi2cD/rTDNFsx/gxvoyutRmno7I3NRbKmpsXF4StZioU3USRspB07\\n+hYXOVnG3pS+PjVby7ThT3gvFHSocguOsxClx1epdUJAmJUbmM7NmOp5WVBVtMtC2\\n+Su4NG/xJciXitKzw+btb7C7RjO6OEqv/1X/oBDzKBWQAwxUC+lqmnM7W6oqWJFEM\\n+YfTLnrjs7Hj6ThMGcEnfvc46dWK3dz0RjsQzUxugPuEkLA==\\n -----END CERTIFICATE-----\\ndiff --git a/glance/tests/var/privatekey.key b/glance/tests/var/privatekey.key\\nindex 9da0a6c8..b63df3d2 100644\\n--- a/glance/tests/var/privatekey.key\\n+++ b/glance/tests/var/privatekey.key\\n@@ -1,27 +1,51 @@\\n -----BEGIN RSA PRIVATE KEY-----\\n-MIIEpQIBAAKCAQEA73OlzN/5bgOgrbPygVuxl9u/PXL/JA6etBi9vXO/UiJ5P5AD\\n-5OI3rg3+yBH9xHtgQhcOeGKPzITUlNYyTVbqDibtMZpxQxcP9YByxMzuRGiX8VWS\\n-x2cXnWrEJipZQ9DfGJN8GDZIla8kJQajC/PTrGHwl44RctsAsLnGvOszeFyWl1us\\n-pgSh7ySKQj8rRMqm7nZUkmtMEY8cyzD54iovYjHmlYeHsM9+MGKIbuSGwnE3vFKo\\n-ttcuuEOLbidMz2md1qoAGSY9hD2p3XVKgBQHzZAAAaPwDuJH8OcDMB8mXW6y9Cn4\\n-x7qxHdM9jbvOJ8FsPTi2JE6LWzAz/XFEfuo6mQIDAQABAoIBAQC6BwvBbiQXH0Re\\n-jtWRQA5p3zPk5olnluAfJLWMEPeLNPMjuZv83u7JD2BoSOnxErTGw6jfSBtVlcCd\\n-3Qb5ZNOzqPRPvB/QMoOYhHElidx2UxfwSz4cInCLQJ4g1HfDIuuf6TzYhpu/hnC7\\n-Pzu+lnBVlUVYSOwvYgtYQQwwSz4Se8Mwoh2OOOTgn4wvZDbiDrMvv2UUUL1nyvAB\\n-FdaywbD/dW8TqbnPSoj8uipq0yugDOyzzNQDM6+rN69qNrD2/vYaAsSaWxISLDqs\\n-fEI4M1+PeDmLigQeA7V3kEZWWDwHbS92LL8BxEmmeeHN5xwZyC8xqa1jt2A/S6Af\\n-Q7gkpG6BAoGBAP+jFn7HCCi/Lc+YEZO0km7fvfR48M6QW3ar+b1aQywJWJhbtU9E\\n-eoX1IcLxgce3+mUO05hGz3Rvz5JSDbmWXd6GTVsMRZqJeeCKbw9xirp5i4JjLzc8\\n-Vu2oOJhqtAa88FgpZJ3iPIrT38UBpmnrvv1nb2ZNMdZnTNhtj5WByLFpAoGBAO/K\\n-rVuvMq370P69Lo+iAr6+t4vwpF6pC/06B+OT5vldoiF57dOjFwndAKs9HCk9rS0/\\n-jTvo0a1tS9yU20cFLXMN98zho3BYs4BlEKpNwVmpopxcfGV6dbwka7delAEVZzyN\\n-TDW2P5Gyq9sYys+2ldvT2zTK8hHXZSh5JAp3V+mxAoGAC6G6Fk6sGl6IkReURSpE\\n-N3NKy2LtYhjDcKTmmi0PPWO3ekdB+rdc89dxj9M5WoMOi6afDiC6s8uaoEfHhBhJ\\n-cSSfRHNMf3md6A+keglqjI2XQXmN3m+KbQnoeVbxlhTmwrwvbderdY2qcuZeUhd9\\n-+z3HndoJWH4eywJBNEZRgXECgYEAjtTeEDe6a1IMuj/7xQiOtAmsEQolDlGJV6vC\\n-WTeXJEA2u9QB6sdBiNmAdX9wD8yyI7qwKNhUVQY+YsS0HIij+t1+FibtEJV1Tmxk\\n-0dyA6CSYPKUGX/fiu0/CbbZDWKXkGXhcxb2p/eI8ZcRNwg4TE58M+lRMfn4bvlDy\\n-O928mvECgYEA18MfGUZENZmC9ismsqrr9uVevfB08U5b+KRjSOyI2ZwOXnzcvbc3\\n-zt9Tp35bcpQMAxPVT2B5htXeXqhUAJMkFEajpNZGDEKlCRB2XvMeA1Dn5fSk2dBB\\n-ADeqQczoXT2+VgXLxRJJPucYCzi3kzo0OBUsHc9Z/HZNyr8LrUgd5lI=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\\n -----END RSA PRIVATE KEY-----",
         "def connect(self):\\n\\t\\tsock = socket.create_connection((self.host, self.port), self.timeout)\\n\\t\\tif self._tunnel_host:\\n\\t\\t\\tself.sock = sock\\n\\t\\t\\tself._tunnel()\\n\\t\\tif self.insecure is True:\\n\\t\\t\\tself.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n\\t\\telse:\\n\\t\\t\\tself.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)",
         "def connect(self):\\n\\t\\tsock = socket.create_connection((self.host, self.port), self.timeout)\\n\\t\\tif self._tunnel_host:\\n\\t\\t\\tself.sock = sock\\n\\t\\t\\tself._tunnel()\\n\\t\\tif self.ca_file:\\n\\t\\t\\tself.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n\\t\\telse:\\n\\t\\t\\tself.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)",
         "def connect(self)",
         null,
         "Implement a bug in the connect method to trigger a Wrong Logical Expression Used as Branch Condition (WLEC) fault. The function should fail due to changing the SSL certificate validation condition from self.insecure to self.ca_file.",
         "Alter the behavior of the connect function to introduce Wrong Logical Expression Used as Branch Condition and create incorrect SSL certificate validation logic, causing potential security vulnerabilities.",
         "Alter the behavior of the connect function to create improper SSL certificate validation.",
         "openstack",
         "2.6.0",
         "['test_ssl.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WLEC"
        ],
        [
         "20",
         "^c shouldn't leave incomplete images in cache\\n\\nFixes LP bug 1031842\\n\\nUse a finally clause for the xattr and sqlite\\nimage cache implementations of open_for_write()\\nsuch that if the commit() or rollback() aren't\\ncalled and the image remains in the incomplete\\ndir that it is moved to the invalid dir",
         "security",
         null,
         "https://github.com/python/cpython/commit/a30887aa3b7a220a1f722e94fa69201e5878e766",
         "a30887aa3b7a220a1f722e94fa69201e5878e766",
         "PySecDB",
         "diff --git a/glance/image_cache/drivers/sqlite.py b/glance/image_cache/drivers/sqlite.py\\nindex a98c5cfa..4bc81448 100644\\n--- a/glance/image_cache/drivers/sqlite.py\\n+++ b/glance/image_cache/drivers/sqlite.py\\n@@ -315,8 +315,8 @@ class Driver(base.Driver):\\n\\t\\t\\t\\t if os.path.exists(incomplete_path):\\n\\t\\t\\t\\t\\t invalid_path = self.get_image_filepath(image_id, 'invalid')\\n \\n-\\t\\t\\t\\t\\tLOG.debug(_(\"Fetch of cache file failed, rolling back \"\\n-\\t\\t\\t\\t\\t\\t\\t\\t\"by moving '%(incomplete_path)s' to \"\\n+\\t\\t\\t\\t\\tLOG.debug(_(\"Fetch of cache file failed (%(e)s), rolling \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\"back by moving '%(incomplete_path)s' to \"\\n\\t\\t\\t\\t\\t\\t\\t\\t \"'%(invalid_path)s'\") % locals())\\n\\t\\t\\t\\t\\t os.rename(incomplete_path, invalid_path)\\n \\n@@ -332,6 +332,14 @@ class Driver(base.Driver):\\n\\t\\t\\t raise\\n\\t\\t else:\\n\\t\\t\\t commit()\\n+\\t\\tfinally:\\n+\\t\\t\\t# if the generator filling the cache file neither raises an\\n+\\t\\t\\t# exception, nor completes fetching all data, neither rollback\\n+\\t\\t\\t# nor commit will have been called, so the incomplete file\\n+\\t\\t\\t# will persist - in that case remove it as it is unusable\\n+\\t\\t\\t# example: ^c from client fetch\\n+\\t\\t\\tif os.path.exists(incomplete_path):\\n+\\t\\t\\t\\trollback('incomplete fetch')\\n \\n\\t @contextmanager\\n\\t def open_for_read(self, image_id):\\ndiff --git a/glance/image_cache/drivers/xattr.py b/glance/image_cache/drivers/xattr.py\\nindex 58e5ef7a..4dd336fe 100644\\n--- a/glance/image_cache/drivers/xattr.py\\n+++ b/glance/image_cache/drivers/xattr.py\\n@@ -289,7 +289,7 @@ class Driver(base.Driver):\\n\\t\\t\\t set_attr('error', \"%s\" % e)\\n \\n\\t\\t\\t invalid_path = self.get_image_filepath(image_id, 'invalid')\\n-\\t\\t\\tLOG.debug(_(\"Fetch of cache file failed, rolling back by \"\\n+\\t\\t\\tLOG.debug(_(\"Fetch of cache file failed (%(e)s), rolling back by \"\\n\\t\\t\\t\\t\\t\\t \"moving '%(incomplete_path)s' to \"\\n\\t\\t\\t\\t\\t\\t \"'%(invalid_path)s'\") % locals())\\n\\t\\t\\t os.rename(incomplete_path, invalid_path)\\n@@ -302,6 +302,14 @@ class Driver(base.Driver):\\n\\t\\t\\t raise\\n\\t\\t else:\\n\\t\\t\\t commit()\\n+\\t\\tfinally:\\n+\\t\\t\\t# if the generator filling the cache file neither raises an\\n+\\t\\t\\t# exception, nor completes fetching all data, neither rollback\\n+\\t\\t\\t# nor commit will have been called, so the incomplete file\\n+\\t\\t\\t# will persist - in that case remove it as it is unusable\\n+\\t\\t\\t# example: ^c from client fetch\\n+\\t\\t\\tif os.path.exists(incomplete_path):\\n+\\t\\t\\t\\trollback('incomplete fetch')\\n \\n\\t @contextmanager\\n\\t def open_for_read(self, image_id):\\ndiff --git a/glance/tests/unit/test_image_cache.py b/glance/tests/unit/test_image_cache.py\\nindex 73402edb..ce1758b3 100644\\n--- a/glance/tests/unit/test_image_cache.py\\n+++ b/glance/tests/unit/test_image_cache.py\\n@@ -221,6 +221,100 @@ class ImageCacheTestCase(object):\\n\\t\\t self.assertEqual(self.cache.get_queued_images(),\\n\\t\\t\\t\\t\\t\\t  ['0', '1', '2'])\\n \\n+\\tdef test_open_for_write_good(self):\\n+\\t\\t\"\"\"\\n+\\t\\tTest to see if open_for_write works in normal case\\n+\\t\\t\"\"\"\\n+\\n+\\t\\t# test a good case\\n+\\t\\timage_id = '1'\\n+\\t\\tself.assertFalse(self.cache.is_cached(image_id))\\n+\\t\\twith self.cache.driver.open_for_write(image_id) as cache_file:\\n+\\t\\t\\tcache_file.write('a')\\n+\\t\\tself.assertTrue(self.cache.is_cached(image_id),\\n+\\t\\t\\t\\t\\t\\t\"Image %s was NOT cached!\" % image_id)\\n+\\t\\t# make sure it has tidied up\\n+\\t\\tincomplete_file_path = os.path.join(self.cache_dir,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'incomplete', image_id)\\n+\\t\\tinvalid_file_path = os.path.join(self.cache_dir, 'invalid', image_id)\\n+\\t\\tself.assertFalse(os.path.exists(incomplete_file_path))\\n+\\t\\tself.assertFalse(os.path.exists(invalid_file_path))\\n+\\n+\\tdef test_open_for_write_with_exception(self):\\n+\\t\\t\"\"\"\\n+\\t\\tTest to see if open_for_write works in a failure case for each driver\\n+\\t\\tThis case is where an exception is raised while the file is being\\n+\\t\\twritten. The image is partially filled in cache and filling wont resume\\n+\\t\\tso verify the image is moved to invalid/ directory\\n+\\t\\t\"\"\"\\n+\\t\\t# test a case where an exception is raised while the file is open\\n+\\t\\timage_id = '1'\\n+\\t\\tself.assertFalse(self.cache.is_cached(image_id))\\n+\\t\\ttry:\\n+\\t\\t\\twith self.cache.driver.open_for_write(image_id) as cache_file:\\n+\\t\\t\\t\\traise IOError\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\tself.assertEqual(type(e), IOError)\\n+\\t\\tself.assertFalse(self.cache.is_cached(image_id),\\n+\\t\\t\\t\\t\\t\\t \"Image %s was cached!\" % image_id)\\n+\\t\\t# make sure it has tidied up\\n+\\t\\tincomplete_file_path = os.path.join(self.cache_dir,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'incomplete', image_id)\\n+\\t\\tinvalid_file_path = os.path.join(self.cache_dir, 'invalid', image_id)\\n+\\t\\tself.assertFalse(os.path.exists(incomplete_file_path))\\n+\\t\\tself.assertTrue(os.path.exists(invalid_file_path))\\n+\\n+\\tdef test_caching_iterator(self):\\n+\\t\\t\"\"\"\\n+\\t\\tTest to see if the caching iterator interacts properly with the driver\\n+\\t\\tWhen the iterator completes going through the data the driver should\\n+\\t\\thave closed the image and placed it correctly\\n+\\t\\t\"\"\"\\n+\\t\\t# test a case where an exception NOT raised while the file is open,\\n+\\t\\t# and a consuming iterator completes\\n+\\t\\tdef consume(image_id):\\n+\\t\\t\\tdata = ['a', 'b', 'c', 'd', 'e', 'f']\\n+\\t\\t\\tcaching_iter = self.cache.get_caching_iter(image_id, iter(data))\\n+\\t\\t\\tself.assertEqual(list(caching_iter), data)\\n+\\n+\\t\\timage_id = '1'\\n+\\t\\tself.assertFalse(self.cache.is_cached(image_id))\\n+\\t\\tconsume(image_id)\\n+\\t\\tself.assertTrue(self.cache.is_cached(image_id),\\n+\\t\\t\\t\\t\\t\\t\"Image %s was NOT cached!\" % image_id)\\n+\\t\\t# make sure it has tidied up\\n+\\t\\tincomplete_file_path = os.path.join(self.cache_dir,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'incomplete', image_id)\\n+\\t\\tinvalid_file_path = os.path.join(self.cache_dir, 'invalid', image_id)\\n+\\t\\tself.assertFalse(os.path.exists(incomplete_file_path))\\n+\\t\\tself.assertFalse(os.path.exists(invalid_file_path))\\n+\\n+\\tdef test_caching_iterator_falloffend(self):\\n+\\t\\t\"\"\"\\n+\\t\\tTest to see if the caching iterator interacts properly with the driver\\n+\\t\\tin a case where the iterator is only partially consumed. In this case\\n+\\t\\tthe image is only partially filled in cache and filling wont resume.\\n+\\t\\tWhen the iterator goes out of scope the driver should have closed the\\n+\\t\\timage and moved it from incomplete/ to invalid/\\n+\\t\\t\"\"\"\\n+\\t\\t# test a case where a consuming iterator just stops.\\n+\\t\\tdef falloffend(image_id):\\n+\\t\\t\\tdata = ['a', 'b', 'c', 'd', 'e', 'f']\\n+\\t\\t\\tcaching_iter = self.cache.get_caching_iter(image_id, iter(data))\\n+\\t\\t\\tself.assertEqual(caching_iter.next(), 'a')\\n+\\n+\\t\\timage_id = '1'\\n+\\t\\tself.assertFalse(self.cache.is_cached(image_id))\\n+\\t\\tfalloffend(image_id)\\n+\\t\\tself.assertFalse(self.cache.is_cached(image_id),\\n+\\t\\t\\t\\t\\t\\t \"Image %s was cached!\" % image_id)\\n+\\t\\t# make sure it has tidied up\\n+\\t\\tincomplete_file_path = os.path.join(self.cache_dir,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'incomplete', image_id)\\n+\\t\\tinvalid_file_path = os.path.join(self.cache_dir, 'invalid', image_id)\\n+\\t\\tself.assertFalse(os.path.exists(incomplete_file_path))\\n+\\t\\tself.assertTrue(os.path.exists(invalid_file_path))\\n+\\n \\n class TestImageCacheXattr(test_utils.BaseTestCase,\\n\\t\\t\\t\\t\\t\\t   ImageCacheTestCase):",
         "def rollback(e):\\n\\t\\t\\twith self.get_db() as db:\\n\\t\\t\\t\\tif os.path.exists(incomplete_path):\\n\\t\\t\\t\\t\\tinvalid_path = self.get_image_filepath(image_id, 'invalid')\\n\\t\\t\\t\\t\\tLOG.debug(_(\"Fetch of cache file failed (%(e)s), rolling \"\\n\\t\\t\\t\\t\\t\\t\\t\\t\"back by moving '%(incomplete_path)s' to \"\\n\\t\\t\\t\\t\\t\\t\\t\\t\"'%(invalid_path)s'\") % locals())\\n\\t\\t\\t\\t\\tos.rename(incomplete_path, invalid_path)\\n\\t\\t\\t\\tdb.execute(, (image_id, ))\\n\\t\\t\\t\\tdb.commit()\\n\\t\\ttry:\\n\\t\\t\\twith open(incomplete_path, 'wb') as cache_file:\\n\\t\\t\\t\\tyield cache_file\\n\\t\\texcept Exception as e:\\n\\t\\t\\trollback(e)\\n\\t\\t\\traise\\n\\t\\telse:\\n\\t\\t\\tcommit()\\n\\t\\tfinally:\\n\\t\\t\\tif os.path.exists(incomplete_path):\\n\\t\\t\\t\\trollback('incomplete fetch')\\n\\t@contextmanager",
         "def rollback(e):\\n\\t\\t\\twith self.get_db() as db:\\n\\t\\t\\t\\tif os.path.exists(incomplete_path):\\n\\t\\t\\t\\t\\tinvalid_path = self.get_image_filepath(image_id, 'invalid')\\n\\t\\t\\t\\t\\tLOG.debug(_(\"Fetch of cache file failed, rolling back \"\\n\\t\\t\\t\\t\\t\\t\\t\\t\"by moving '%(incomplete_path)s' to \"\\n\\t\\t\\t\\t\\t\\t\\t\\t\"'%(invalid_path)s'\") % locals())\\n\\t\\t\\t\\t\\tos.rename(incomplete_path, invalid_path)\\n\\t\\t\\t\\tdb.execute(, (image_id, ))\\n\\t\\t\\t\\tdb.commit()\\n\\t\\ttry:\\n\\t\\t\\twith open(incomplete_path, 'wb') as cache_file:\\n\\t\\t\\t\\tyield cache_file\\n\\t\\texcept Exception as e:\\n\\t\\t\\trollback(e)\\n\\t\\t\\traise\\n\\t\\telse:\\n\\t\\t\\tcommit()\\n\\t@contextmanager",
         "def rollback(e)",
         null,
         "Alter the behavior of the rollback function to introduce a Missing Sparsely Spaced Parts of Algorithm (MLPS) fault. The function should fail due to missing the finally block that handles incomplete fetches, potentially causing corrupted cache files.",
         "Modify the rollback function to introduce a missing sparsely spaced part of algorithm fault. Change the function by removing the error handling cleanup logic, potentially leaving corrupted cache files.",
         "Modify the rollback function to introduce missing cleanup logic in error handling.",
         "openstack",
         "2.6.0",
         "['test_image_cache.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MLPS"
        ],
        [
         "21",
         "New -k/--insecure command line option\\n\\nFix for bug 929591.\\n\\nChange glance to require server certificate validation\\nby default when using https. The standard system\\nCA file will be used if available (and an alternative was not\\nprovided).\\n\\nThe --insecure option can be used by clients to skip server\\ncertificate validation if appropriate.\\n\\n  If the standard CA file is not suitable they will need to provide\\n  a CA file or else create an 'insecure' glance client.\\n  certificate validation.\\n  system CA file is installed then that file will be used by default.\\n  It probably makes sense for the glance package to have a\\n  dependency on whichever package provides the default CA bundle.\\n  (In Ubuntu this is 'ca-certificates')",
         "security",
         null,
         "https://github.com/python/cpython/commit/0f0fe2ba1b772e6964241c0631683b306fff23c0",
         "0f0fe2ba1b772e6964241c0631683b306fff23c0",
         "PySecDB",
         "diff --git a/bin/glance b/bin/glance\\nindex fd44f248..8aefea53 100755\\n--- a/bin/glance\\n+++ b/bin/glance\\n@@ -754,7 +754,7 @@ def get_client(options):\\n\\t\\t\\t\\t\\t\\t\\t\\t use_ssl=use_ssl,\\n\\t\\t\\t\\t\\t\\t\\t\\t auth_tok=options.auth_token or \\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t os.getenv('OS_TOKEN'),\\n-\\t\\t\\t\\t\\t\\t\\t\\tcreds=creds)\\n+\\t\\t\\t\\t\\t\\t\\t\\tcreds=creds, insecure=options.insecure)\\n \\n \\n def create_options(parser):\\n@@ -781,6 +781,12 @@ def create_options(parser):\\n\\t\\t\\t\\t\\t\\t\\t\"(http/https) of the glance server, for example \"\\n\\t\\t\\t\\t\\t\\t\\t\"-U https://localhost:\" + str(DEFAULT_PORT) +\\n\\t\\t\\t\\t\\t\\t\\t\"/v1 Default: None\")\\n+\\tparser.add_option('-k', '--insecure', dest=\"insecure\",\\n+\\t\\t\\t\\t\\t  default=False, action=\"store_true\",\\n+\\t\\t\\t\\t\\t  help=\"Explicitly allow glance to perform \\\"insecure\\\" \"\\n+\\t\\t\\t\\t\\t  \"SSL (https) requests. The server's certificate will \"\\n+\\t\\t\\t\\t\\t  \"not be verified against any certificate authorities. \"\\n+\\t\\t\\t\\t\\t  \"This option should be used with caution.\")\\n\\t parser.add_option('-A', '--auth_token', dest=\"auth_token\",\\n\\t\\t\\t\\t\\t   metavar=\"TOKEN\", default=None,\\n\\t\\t\\t\\t\\t   help=\"Authentication token to use to identify the \"\\n@@ -810,7 +816,7 @@ def create_options(parser):\\n\\t\\t\\t\\t\\t   help=\"Sort results by this image attribute.\")\\n\\t parser.add_option('--sort_dir', dest=\"sort_dir\", metavar=\"[desc|asc]\",\\n\\t\\t\\t\\t\\t   help=\"Sort results in this direction.\")\\n-\\tparser.add_option('-f', '--force', dest=\"force\", metavar=\"FORCE\",\\n+\\tparser.add_option('-f', '--force', dest=\"force\",\\n\\t\\t\\t\\t\\t   default=False, action=\"store_true\",\\n\\t\\t\\t\\t\\t   help=\"Prevent select actions from requesting \"\\n\\t\\t\\t\\t\\t\\t\\t\"user confirmation\")\\ndiff --git a/doc/source/glance.rst b/doc/source/glance.rst\\nindex 1a86f4c9..e105eb48 100644\\n--- a/doc/source/glance.rst\\n+++ b/doc/source/glance.rst\\n@@ -100,6 +100,10 @@ a brief help message, like so::\\n\\t\\t\\t\\t\\t\\t   specify the hostname, port and protocol (http/https)\\n\\t\\t\\t\\t\\t\\t   of the glance server, for example -U\\n\\t\\t\\t\\t\\t\\t   https://localhost:9292/v1 Default: None\\n+\\t-k, --insecure\\t\\tExplicitly allow glance to perform insecure SSL\\n+\\t\\t\\t\\t\\t\\t  requests. The server certificate will not be\\n+\\t\\t\\t\\t\\t\\t  verified against any certificate authorities.\\n+\\t\\t\\t\\t\\t\\t  This option should be used with caution.\\n\\t --limit=LIMIT\\t\\t Page size to use while requesting image metadata\\n\\t --marker=MARKER\\t   Image index after which to begin pagination\\n\\t --sort_key=KEY\\t\\tSort results by this image attribute.\\n@@ -153,7 +157,7 @@ Important Information about Uploading Images\\n Before we go over the commands for adding an image to Glance, it is\\n important to understand that Glance **does not currently inspect** the image\\n files you add to it. In other words, **Glance only understands what you tell it,\\n-via attributes and custom properties**. \\n+via attributes and custom properties**.\\n \\n If the file extension of the file you upload to Glance ends in '.vhd', Glance\\n **does not** know that the image you are uploading has a disk format of ``vhd``.\\ndiff --git a/doc/source/man/glance.rst b/doc/source/man/glance.rst\\nindex 16ecdc11..ae174f9a 100644\\n--- a/doc/source/man/glance.rst\\n+++ b/doc/source/man/glance.rst\\n@@ -78,10 +78,10 @@ OPTIONS\\n \\n   **-v, --verbose**\\n\\t\\t Print more verbose output\\n- \\n+\\n   **-d, --debug**\\n\\t\\t Print more verbose output\\n- \\n+\\n   **-H ADDRESS, --host=ADDRESS**\\n\\t\\t Address of Glance API host. Default: 0.0.0.0\\n \\n@@ -90,10 +90,15 @@ OPTIONS\\n \\n   **-U URL, --url=URL**\\n\\t\\t URL of Glance service. This option can be used to specify the hostname,\\n-\\t\\tport and protocol (http/https) of the glance server, for example \\n-\\t\\t-U https://localhost:9292/v1 \\n+\\t\\tport and protocol (http/https) of the glance server, for example\\n+\\t\\t-U https://localhost:9292/v1\\n\\t\\t Default: None\\n \\n+  **-k, --insecure**\\n+\\t\\tExplicitly allow glance to perform insecure SSL (https) requests.\\n+\\t\\tThe server certificate will not be verified against any certificate\\n+\\t\\tauthorities. This option should be used with caution.\\n+\\n   **-A TOKEN, --auth_token=TOKEN**\\n\\t\\t Authentication token to use to identify the client to the glance server\\n \\ndiff --git a/glance/common/client.py b/glance/common/client.py\\nindex 9a3c3bfb..9e08c15a 100644\\n--- a/glance/common/client.py\\n+++ b/glance/common/client.py\\n@@ -148,13 +148,14 @@ class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\t \"\"\"\\n \\n\\t def __init__(self, host, port, key_file, cert_file,\\n-\\t\\t\\t\\t ca_file, timeout=None):\\n+\\t\\t\\t\\t ca_file, timeout=None, insecure=False):\\n\\t\\t httplib.HTTPSConnection.__init__(self, host, port, key_file=key_file,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  cert_file=cert_file)\\n\\t\\t self.key_file = key_file\\n\\t\\t self.cert_file = cert_file\\n\\t\\t self.ca_file = ca_file\\n\\t\\t self.timeout = timeout\\n+\\t\\tself.insecure = insecure\\n \\n\\t def connect(self):\\n\\t\\t \"\"\"\\n@@ -170,14 +171,14 @@ class HTTPSClientAuthConnection(httplib.HTTPSConnection):\\n\\t\\t if self._tunnel_host:\\n\\t\\t\\t self.sock = sock\\n\\t\\t\\t self._tunnel()\\n-\\t\\t# If there's no CA File, don't force Server Certificate Check\\n-\\t\\tif self.ca_file:\\n+\\t\\t# Check CA file unless 'insecure' is specificed\\n+\\t\\tif self.insecure is True:\\n\\t\\t\\t self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n\\t\\t else:\\n\\t\\t\\t self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_NONE)\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tca_certs=self.ca_file,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcert_reqs=ssl.CERT_REQUIRED)\\n \\n \\n class BaseClient(object):\\n@@ -186,6 +187,12 @@ class BaseClient(object):\\n \\n\\t DEFAULT_PORT = 80\\n\\t DEFAULT_DOC_ROOT = None\\n+\\t# Standard CA file locations for Debian/Ubuntu, RedHat/Fedora,\\n+\\t# Suse, FreeBSD/OpenBSD\\n+\\tDEFAULT_CA_FILE_PATH = '/etc/ssl/certs/ca-certificates.crt:'\\\\n+\\t\\t'/etc/pki/tls/certs/ca-bundle.crt:'\\\\n+\\t\\t'/etc/ssl/ca-bundle.pem:'\\\\n+\\t\\t'/etc/ssl/cert.pem'\\n \\n\\t OK_RESPONSE_CODES = (\\n\\t\\t httplib.OK,\\n@@ -203,8 +210,8 @@ class BaseClient(object):\\n\\t )\\n \\n\\t def __init__(self, host, port=None, use_ssl=False, auth_tok=None,\\n-\\t\\t\\t\\t creds=None, doc_root=None,\\n-\\t\\t\\t\\t key_file=None, cert_file=None, ca_file=None):\\n+\\t\\t\\t\\t creds=None, doc_root=None, key_file=None,\\n+\\t\\t\\t\\t cert_file=None, ca_file=None, insecure=False):\\n\\t\\t \"\"\"\\n\\t\\t Creates a new client to some service.\\n \\n@@ -231,6 +238,8 @@ class BaseClient(object):\\n\\t\\t\\t\\t\\t\\t If use_ssl is True, and this param is None (the\\n\\t\\t\\t\\t\\t\\t default), then an environ variable\\n\\t\\t\\t\\t\\t\\t GLANCE_CLIENT_CA_FILE is looked for.\\n+\\t\\t:param insecure: Optional. If set then the server's certificate\\n+\\t\\t\\t\\t\\t\\t will not be verified.\\n\\t\\t \"\"\"\\n\\t\\t self.host = host\\n\\t\\t self.port = port or self.DEFAULT_PORT\\n@@ -286,7 +295,15 @@ class BaseClient(object):\\n\\t\\t\\t\\t msg = _(\"The CA file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t \"exist\") % ca_file\\n\\t\\t\\t\\t raise exception.ClientConnectionError(msg)\\n+\\n+\\t\\t\\tif ca_file is None:\\n+\\t\\t\\t\\tfor ca in self.DEFAULT_CA_FILE_PATH.split(\":\"):\\n+\\t\\t\\t\\t\\tif os.path.exists(ca):\\n+\\t\\t\\t\\t\\t\\tca_file = ca\\n+\\t\\t\\t\\t\\t\\tbreak\\n+\\n\\t\\t\\t self.connect_kwargs['ca_file'] = ca_file\\n+\\t\\t\\tself.connect_kwargs['insecure'] = insecure\\n \\n\\t def set_auth_token(self, auth_tok):\\n\\t\\t \"\"\"\\ndiff --git a/glance/tests/functional/test_ssl.py b/glance/tests/functional/test_ssl.py\\nindex b0fdf622..4c94d1cf 100644\\n--- a/glance/tests/functional/test_ssl.py\\n+++ b/glance/tests/functional/test_ssl.py\\n@@ -40,6 +40,8 @@ import os\\n import tempfile\\n import unittest\\n \\n+from glance import client as glance_client\\n+from glance.common import exception\\n from glance.common import utils\\n from glance.store.location import get_location_from_uri\\n from glance.tests import functional\\n@@ -62,6 +64,12 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t self.inited = False\\n\\t\\t self.disabled = True\\n \\n+\\t\\t# Test key/cert/CA file created as per:\\n+\\t\\t#   http://blog.didierstevens.com/2008/12/30/\\n+\\t\\t#\\t howto-make-your-own-cert-with-openssl/\\n+\\t\\t# Note that for these tests certificate.crt had to\\n+\\t\\t# be created with 'Common Name' set to 0.0.0.0\\n+\\n\\t\\t self.key_file = os.path.join(TEST_VAR_DIR, 'privatekey.key')\\n\\t\\t if not os.path.exists(self.key_file):\\n\\t\\t\\t self.disabled_message = \"Could not find private key file\"\\n@@ -69,11 +77,17 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t\\t return\\n \\n\\t\\t self.cert_file = os.path.join(TEST_VAR_DIR, 'certificate.crt')\\n-\\t\\tif not os.path.exists(self.key_file):\\n+\\t\\tif not os.path.exists(self.cert_file):\\n\\t\\t\\t self.disabled_message = \"Could not find certificate file\"\\n\\t\\t\\t self.inited = True\\n\\t\\t\\t return\\n \\n+\\t\\tself.ca_file = os.path.join(TEST_VAR_DIR, 'ca.crt')\\n+\\t\\tif not os.path.exists(self.ca_file):\\n+\\t\\t\\tself.disabled_message = \"Could not find CA file\"\\n+\\t\\t\\tself.inited = True\\n+\\t\\t\\treturn\\n+\\n\\t\\t self.inited = True\\n\\t\\t self.disabled = False\\n \\n@@ -1230,3 +1244,94 @@ class TestSSL(functional.FunctionalTest):\\n\\t\\t self.assertEqual(response.status, 404)\\n \\n\\t\\t self.stop_servers()\\n+\\n+\\t@skip_if_disabled\\n+\\tdef test_certificate_validation(self):\\n+\\t\\t\"\"\"\\n+\\t\\tCheck SSL client cerificate verification\\n+\\t\\t\"\"\"\\n+\\t\\tself.cleanup()\\n+\\t\\tself.start_servers(**self.__dict__.copy())\\n+\\n+\\t\\t# 0. GET /images\\n+\\t\\t# Verify no public images\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\t# 1. POST /images with public image named Image1\\n+\\t\\theaders = {'Content-Type': 'application/octet-stream',\\n+\\t\\t\\t\\t   'X-Image-Meta-Name': 'Image1',\\n+\\t\\t\\t\\t   'X-Image-Meta-Status': 'active',\\n+\\t\\t\\t\\t   'X-Image-Meta-Container-Format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Disk-Format': 'vdi',\\n+\\t\\t\\t\\t   'X-Image-Meta-Size': '19',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True'}\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 201)\\n+\\t\\tdata = json.loads(content)\\n+\\n+\\t\\timage_id = data['image']['id']\\n+\\n+\\t\\t# 2. Attempt to delete the image *without* CA file\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\tsecure_cli = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  use_ssl=True, insecure=False)\\n+\\t\\ttry:\\n+\\t\\t\\tsecure_cli.delete_image(image_id)\\n+\\t\\t\\tself.fail(\"Client with no CA file deleted image %s\" % image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tpass\\n+\\n+\\t\\t# 3. Delete the image with a secure client *with* CA file\\n+\\t\\tsecure_cli2 = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   use_ssl=True, ca_file=self.ca_file,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   insecure=False)\\n+\\t\\ttry:\\n+\\t\\t\\tsecure_cli2.delete_image(image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tself.fail(\"Secure client failed to delete image %s\" % image_id)\\n+\\n+\\t\\t# Verify image is deleted\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\t# 4. POST another image\\n+\\t\\theaders = {'Content-Type': 'application/octet-stream',\\n+\\t\\t\\t\\t   'X-Image-Meta-Name': 'Image1',\\n+\\t\\t\\t\\t   'X-Image-Meta-Status': 'active',\\n+\\t\\t\\t\\t   'X-Image-Meta-Container-Format': 'ovf',\\n+\\t\\t\\t\\t   'X-Image-Meta-Disk-Format': 'vdi',\\n+\\t\\t\\t\\t   'X-Image-Meta-Size': '19',\\n+\\t\\t\\t\\t   'X-Image-Meta-Is-Public': 'True'}\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'POST', headers=headers)\\n+\\t\\tself.assertEqual(response.status, 201)\\n+\\t\\tdata = json.loads(content)\\n+\\n+\\t\\timage_id = data['image']['id']\\n+\\n+\\t\\t# 5. Delete the image with an insecure client\\n+\\t\\tinsecure_cli = glance_client.Client(host=\"0.0.0.0\", port=self.api_port,\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tuse_ssl=True, insecure=True)\\n+\\t\\ttry:\\n+\\t\\t\\tinsecure_cli.delete_image(image_id)\\n+\\t\\texcept exception.ClientConnectionError, e:\\n+\\t\\t\\tself.fail(\"Insecure client failed to delete image\")\\n+\\n+\\t\\t# Verify image is deleted\\n+\\t\\tpath = \"https://%s:%d/v1/images\" % (\"0.0.0.0\", self.api_port)\\n+\\t\\thttps = httplib2.Http(disable_ssl_certificate_validation=True)\\n+\\t\\tresponse, content = https.request(path, 'GET')\\n+\\t\\tself.assertEqual(response.status, 200)\\n+\\t\\tself.assertEqual(content, '{\"images\": []}')\\n+\\n+\\t\\tself.stop_servers()\\ndiff --git a/glance/tests/var/ca.crt b/glance/tests/var/ca.crt\\nnew file mode 100644\\nindex 00000000..9d66ca62\\n--- /dev/null\\n+++ b/glance/tests/var/ca.crt\\n@@ -0,0 +1,35 @@\\n+-----BEGIN CERTIFICATE-----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\\n+WoRMgEwjGJWqzhJZUYpUAQ==\\n+-----END CERTIFICATE-----\\ndiff --git a/glance/tests/var/certificate.crt b/glance/tests/var/certificate.crt\\nindex 9bb6dd1d..3c1aa636 100644\\n--- a/glance/tests/var/certificate.crt\\n+++ b/glance/tests/var/certificate.crt\\n@@ -1,18 +1,30 @@\\n -----BEGIN CERTIFICATE-----\\n-MIIC4DCCAcigAwIBAgIBATANBgkqhkiG9w0BAQUFADATMREwDwYDVQQDEwhNeVRl\\n-c3RDQTAeFw0xMTA3MjExNTA1NDZaFw0xMjA3MjAxNTA1NDZaMCMxEDAOBgNVBAMT\\n-B2FobWFkcGMxDzANBgNVBAoTBnNlcnZlcjCCASIwDQYJKoZIhvcNAQEBBQADggEP\\n-ADCCAQoCggEBAO9zpczf+W4DoK2z8oFbsZfbvz1y/yQOnrQYvb1zv1IieT+QA+Ti\\n-N64N/sgR/cR7YEIXDnhij8yE1JTWMk1W6g4m7TGacUMXD/WAcsTM7kRol/FVksdn\\n-F51qxCYqWUPQ3xiTfBg2SJWvJCUGowvz06xh8JeOEXLbALC5xrzrM3hclpdbrKYE\\n-oe8kikI/K0TKpu52VJJrTBGPHMsw+eIqL2Ix5pWHh7DPfjBiiG7khsJxN7xSqLbX\\n-LrhDi24nTM9pndaqABkmPYQ9qd11SoAUB82QAAGj8A7iR/DnAzAfJl1usvQp+Me6\\n-sR3TPY27zifBbD04tiROi1swM/1xRH7qOpkCAwEAAaMvMC0wCQYDVR0TBAIwADAL\\n-BgNVHQ8EBAMCBSAwEwYDVR0lBAwwCgYIKwYBBQUHAwEwDQYJKoZIhvcNAQEFBQAD\\n-ggEBAIJvnQjkEDFvLT7NiyFrO938BuxdQH2mX2N7Fz86myZLcGpr5NCdLvT9tD9f\\n-6KqrR8e839pYVPZY80cBpGTmRmzW3xLsmGCFHPHt4p1tkqSP1R5iLzKDe8jawHhD\\n-sch8P9URRhW9ZgBzA4xiv9FnIxZ70uDr04uX/sR/j41HGBS8YW6dJvr9Y2SpGqSS\\n-rR2btnNZ945dau6CPLRNd9Fls3Qjx03PnsmZ5ikSuV0pT1sPQmhhw7rBYV/b2ff+\\n-z/4cRtZrR00NVc74IEXLoujIjUUpFC83in10PKQmAvKYTeTdXns48eC4Cwqe8eaM\\n-N0YtxqQvSTsUo6vPM28NR99Fbow=\\n+MIIFLjCCAxYCAQEwDQYJKoZIhvcNAQEFBQAwYTELMAkGA1UEBhMCQVUxEzARBgNV\\n+BAgTClNvbWUtU3RhdGUxFTATBgNVBAoTDE9wZW5zdGFjayBDQTESMBAGA1UECxMJ\\n+R2xhbmNlIENBMRIwEAYDVQQDEwlHbGFuY2UgQ0EwHhcNMTIwMjA5MTcxMDUzWhcN\\n+MjIwMjA2MTcxMDUzWjBZMQswCQYDVQQGEwJBVTETMBEGA1UECBMKU29tZS1TdGF0\\n+ZTESMBAGA1UEChMJT3BlbnN0YWNrMQ8wDQYDVQQLEwZHbGFuY2UxEDAOBgNVBAMT\\n+BzAuMC4wLjAwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQDXpUkQN6pu\\n+avo+gz3o1K4krVdPl1m7NjNJDyD/+ZH0EGNcEN7iag1qPE7JsjqGPNZsQK1dMoXb\\n+Sz+OSi9qvNeJnBcfwUx5qTAtwyAb9AxGkwuMafIU+lWbsclo+dPGsja01ywbXTCZ\\n+bF32iqnpOMYhfxWUdoQYiBkhxxhW9eMPKLS/KkP8/bx+Vaa2XJiAebqkd9nrksAA\\n+BeGc9mlafYBEmiChPdJEPw+1ePA4QVq9aPepDsqAKtGN8JLpmoC3BdxQQTbbwL3Q\\n+8fTXK4tCNUaVk4AbDy/McFq6y0ocQoBPJjihOY35mWG/OLtcI99yPOpWGnps/5aG\\n+/64DDJ2D67Fnaj6gKHV+6TXFO8KZxlnxtgtiZDJBZkneTBt9ArSOv+l6NBsumRz0\\n+iEJ4o4H1S2TSMnprAvX7WnGtc6Xi9gXahYcDHEelwwYzqAiTBv6hxSp4MZ2dNXa+\\n+KzOitC7ZbV2qsg0au0wjfE/oSQ3NvsvUr8nOmfutJTvHRAwbC1v4G/tuAsO7O0w2\\n+0u2B3u+pG06m5+rnEqp+rB9hmukRYTfgEFRRsVIvpFl/cwvPXKRcX03UIMx+lLr9\\n+Ft+ep7YooBhY3wY2kwCxD4lRYNmbwsCIVywZt40f/4ad98TkufR9NhsfycxGeqbr\\n+mTMFlZ8TTlmP82iohekKCOvoyEuTIWL2+wIDAQABMA0GCSqGSIb3DQEBBQUAA4IC\\n+AQBMUBgV0R+Qltf4Du7u/8IFmGAoKR/mktB7R1gRRAqsvecUt7kIwBexGdavGg1y\\n+0pU0+lgUZjJ20N1SlPD8gkNHfXE1fL6fmMjWz4dtYJjzRVhpufHPeBW4tl8DgHPN\\n+rBGAYQ+drDSXaEjiPQifuzKx8WS+DGA3ki4co5mPjVnVH1xvLIdFsk89z3b3YD1k\\n+yCJ/a9K36x6Z/c67JK7s6MWtrdRF9+MVnRKJ2PK4xznd1kBz16V+RA466wBDdARY\\n+vFbtkafbEqOb96QTonIZB7+fAldKDPZYnwPqasreLmaGOaM8sxtlPYAJ5bjDONbc\\n+AaXG8BMRQyO4FyH237otDKlxPyHOFV66BaffF5S8OlwIMiZoIvq+IcTZOdtDUSW2\\n+KHNLfe5QEDZdKjWCBrfqAfvNuG13m03WqfmcMHl3o/KiPJlx8l9Z4QEzZ9xcyQGL\\n+cncgeHM9wJtzi2cD/rTDNFsx/gxvoyutRmno7I3NRbKmpsXF4StZioU3USRspB07\\n+hYXOVnG3pS+PjVby7ThT3gvFHSocguOsxClx1epdUJAmJUbmM7NmOp5WVBVtMtC2\\n+Su4NG/xJciXitKzw+btb7C7RjO6OEqv/1X/oBDzKBWQAwxUC+lqmnM7W6oqWJFEM\\n+YfTLnrjs7Hj6ThMGcEnfvc46dWK3dz0RjsQzUxugPuEkLA==\\n -----END CERTIFICATE-----\\ndiff --git a/glance/tests/var/privatekey.key b/glance/tests/var/privatekey.key\\nindex 9da0a6c8..b63df3d2 100644\\n--- a/glance/tests/var/privatekey.key\\n+++ b/glance/tests/var/privatekey.key\\n@@ -1,27 +1,51 @@\\n -----BEGIN RSA PRIVATE KEY-----\\n-MIIEpQIBAAKCAQEA73OlzN/5bgOgrbPygVuxl9u/PXL/JA6etBi9vXO/UiJ5P5AD\\n-5OI3rg3+yBH9xHtgQhcOeGKPzITUlNYyTVbqDibtMZpxQxcP9YByxMzuRGiX8VWS\\n-x2cXnWrEJipZQ9DfGJN8GDZIla8kJQajC/PTrGHwl44RctsAsLnGvOszeFyWl1us\\n-pgSh7ySKQj8rRMqm7nZUkmtMEY8cyzD54iovYjHmlYeHsM9+MGKIbuSGwnE3vFKo\\n-ttcuuEOLbidMz2md1qoAGSY9hD2p3XVKgBQHzZAAAaPwDuJH8OcDMB8mXW6y9Cn4\\n-x7qxHdM9jbvOJ8FsPTi2JE6LWzAz/XFEfuo6mQIDAQABAoIBAQC6BwvBbiQXH0Re\\n-jtWRQA5p3zPk5olnluAfJLWMEPeLNPMjuZv83u7JD2BoSOnxErTGw6jfSBtVlcCd\\n-3Qb5ZNOzqPRPvB/QMoOYhHElidx2UxfwSz4cInCLQJ4g1HfDIuuf6TzYhpu/hnC7\\n-Pzu+lnBVlUVYSOwvYgtYQQwwSz4Se8Mwoh2OOOTgn4wvZDbiDrMvv2UUUL1nyvAB\\n-FdaywbD/dW8TqbnPSoj8uipq0yugDOyzzNQDM6+rN69qNrD2/vYaAsSaWxISLDqs\\n-fEI4M1+PeDmLigQeA7V3kEZWWDwHbS92LL8BxEmmeeHN5xwZyC8xqa1jt2A/S6Af\\n-Q7gkpG6BAoGBAP+jFn7HCCi/Lc+YEZO0km7fvfR48M6QW3ar+b1aQywJWJhbtU9E\\n-eoX1IcLxgce3+mUO05hGz3Rvz5JSDbmWXd6GTVsMRZqJeeCKbw9xirp5i4JjLzc8\\n-Vu2oOJhqtAa88FgpZJ3iPIrT38UBpmnrvv1nb2ZNMdZnTNhtj5WByLFpAoGBAO/K\\n-rVuvMq370P69Lo+iAr6+t4vwpF6pC/06B+OT5vldoiF57dOjFwndAKs9HCk9rS0/\\n-jTvo0a1tS9yU20cFLXMN98zho3BYs4BlEKpNwVmpopxcfGV6dbwka7delAEVZzyN\\n-TDW2P5Gyq9sYys+2ldvT2zTK8hHXZSh5JAp3V+mxAoGAC6G6Fk6sGl6IkReURSpE\\n-N3NKy2LtYhjDcKTmmi0PPWO3ekdB+rdc89dxj9M5WoMOi6afDiC6s8uaoEfHhBhJ\\n-cSSfRHNMf3md6A+keglqjI2XQXmN3m+KbQnoeVbxlhTmwrwvbderdY2qcuZeUhd9\\n-+z3HndoJWH4eywJBNEZRgXECgYEAjtTeEDe6a1IMuj/7xQiOtAmsEQolDlGJV6vC\\n-WTeXJEA2u9QB6sdBiNmAdX9wD8yyI7qwKNhUVQY+YsS0HIij+t1+FibtEJV1Tmxk\\n-0dyA6CSYPKUGX/fiu0/CbbZDWKXkGXhcxb2p/eI8ZcRNwg4TE58M+lRMfn4bvlDy\\n-O928mvECgYEA18MfGUZENZmC9ismsqrr9uVevfB08U5b+KRjSOyI2ZwOXnzcvbc3\\n-zt9Tp35bcpQMAxPVT2B5htXeXqhUAJMkFEajpNZGDEKlCRB2XvMeA1Dn5fSk2dBB\\n-ADeqQczoXT2+VgXLxRJJPucYCzi3kzo0OBUsHc9Z/HZNyr8LrUgd5lI=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\\n -----END RSA PRIVATE KEY-----",
         "class BaseClient(object):\\n\\tDEFAULT_PORT = 80\\n\\tDEFAULT_DOC_ROOT = None\\n\\tDEFAULT_CA_FILE_PATH = '/etc/ssl/certs/ca-certificates.crt:'\\\\n\\t\\t'/etc/pki/tls/certs/ca-bundle.crt:'\\\\n\\t\\t'/etc/ssl/ca-bundle.pem:'\\\\n\\t\\t'/etc/ssl/cert.pem'\\n\\tOK_RESPONSE_CODES = (\\n\\t\\thttplib.OK,\\n\\t\\thttplib.CREATED,\\n\\t\\thttplib.ACCEPTED,\\n\\t\\thttplib.NO_CONTENT,\\n\\t)\\n\\tREDIRECT_RESPONSE_CODES = (\\n\\t\\thttplib.MOVED_PERMANENTLY,\\n\\t\\thttplib.FOUND,\\n\\t\\thttplib.SEE_OTHER,\\n\\t\\thttplib.USE_PROXY,\\n\\t\\thttplib.TEMPORARY_REDIRECT,\\n\\t)\\n\\tdef __init__(self, host, port=None, use_ssl=False, auth_tok=None,\\n\\t\\t\\t\\t creds=None, doc_root=None, key_file=None,\\n\\t\\t\\t\\t cert_file=None, ca_file=None, insecure=False):\\n\\t\\tself.host = host\\n\\t\\tself.port = port or self.DEFAULT_PORT\\n\\t\\tself.use_ssl = use_ssl\\n\\t\\tself.auth_tok = auth_tok\\n\\t\\tself.creds = creds or {}\\n\\t\\tself.connection = None\\n\\t\\tself.doc_root = (doc_root if doc_root is not None\\n\\t\\t\\t\\t\\t\\t else self.DEFAULT_DOC_ROOT)\\n\\t\\tself.auth_plugin = self.make_auth_plugin(self.creds)\\n\\t\\tself.connect_kwargs = {}\\n\\t\\tif use_ssl:\\n\\t\\t\\tif key_file is None:\\n\\t\\t\\t\\tkey_file = os.environ.get('GLANCE_CLIENT_KEY_FILE')\\n\\t\\t\\tif cert_file is None:\\n\\t\\t\\t\\tcert_file = os.environ.get('GLANCE_CLIENT_CERT_FILE')\\n\\t\\t\\tif ca_file is None:\\n\\t\\t\\t\\tca_file = os.environ.get('GLANCE_CLIENT_CA_FILE')\\n\\t\\t\\tif cert_file is not None and key_file is None:\\n\\t\\t\\t\\tmsg = _(\"You have selected to use SSL in connecting, \"\\n\\t\\t\\t\\t\\t\\t\"and you have supplied a cert, \"\\n\\t\\t\\t\\t\\t\\t\"however you have failed to supply either a \"\\n\\t\\t\\t\\t\\t\\t\"key_file parameter or set the \"\\n\\t\\t\\t\\t\\t\\t\"GLANCE_CLIENT_KEY_FILE environ variable\")\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tif key_file is not None and cert_file is None:\\n\\t\\t\\t\\tmsg = _(\"You have selected to use SSL in connecting, \"\\n\\t\\t\\t\\t\\t\\t\"and you have supplied a key, \"\\n\\t\\t\\t\\t\\t\\t\"however you have failed to supply either a \"\\n\\t\\t\\t\\t\\t\\t\"cert_file parameter or set the \"\\n\\t\\t\\t\\t\\t\\t\"GLANCE_CLIENT_CERT_FILE environ variable\")\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tif key_file is not None and not os.path.exists(key_file):\\n\\t\\t\\t\\tmsg = _(\"The key file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t\"exist\") % key_file\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tself.connect_kwargs['key_file'] = key_file\\n\\t\\t\\tif cert_file is not None and not os.path.exists(cert_file):\\n\\t\\t\\t\\tmsg = _(\"The cert file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t\"exist\") % cert_file\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tself.connect_kwargs['cert_file'] = cert_file\\n\\t\\t\\tif ca_file is not None and not os.path.exists(ca_file):\\n\\t\\t\\t\\tmsg = _(\"The CA file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t\"exist\") % ca_file\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tif ca_file is None:\\n\\t\\t\\t\\tfor ca in self.DEFAULT_CA_FILE_PATH.split(\":\"):\\n\\t\\t\\t\\t\\tif os.path.exists(ca):\\n\\t\\t\\t\\t\\t\\tca_file = ca\\n\\t\\t\\t\\t\\t\\tbreak\\n\\t\\t\\tself.connect_kwargs['ca_file'] = ca_file\\n\\t\\t\\tself.connect_kwargs['insecure'] = insecure",
         "class BaseClient(object):\\n\\tDEFAULT_PORT = 80\\n\\tDEFAULT_DOC_ROOT = None\\n\\tOK_RESPONSE_CODES = (\\n\\t\\thttplib.OK,\\n\\t\\thttplib.CREATED,\\n\\t\\thttplib.ACCEPTED,\\n\\t\\thttplib.NO_CONTENT,\\n\\t)\\n\\tREDIRECT_RESPONSE_CODES = (\\n\\t\\thttplib.MOVED_PERMANENTLY,\\n\\t\\thttplib.FOUND,\\n\\t\\thttplib.SEE_OTHER,\\n\\t\\thttplib.USE_PROXY,\\n\\t\\thttplib.TEMPORARY_REDIRECT,\\n\\t)\\n\\tdef __init__(self, host, port=None, use_ssl=False, auth_tok=None,\\n\\t\\t\\t\\t creds=None, doc_root=None,\\n\\t\\t\\t\\t key_file=None, cert_file=None, ca_file=None):\\n\\t\\tself.host = host\\n\\t\\tself.port = port or self.DEFAULT_PORT\\n\\t\\tself.use_ssl = use_ssl\\n\\t\\tself.auth_tok = auth_tok\\n\\t\\tself.creds = creds or {}\\n\\t\\tself.connection = None\\n\\t\\tself.doc_root = (doc_root if doc_root is not None\\n\\t\\t\\t\\t\\t\\t else self.DEFAULT_DOC_ROOT)\\n\\t\\tself.auth_plugin = self.make_auth_plugin(self.creds)\\n\\t\\tself.connect_kwargs = {}\\n\\t\\tif use_ssl:\\n\\t\\t\\tif key_file is None:\\n\\t\\t\\t\\tkey_file = os.environ.get('GLANCE_CLIENT_KEY_FILE')\\n\\t\\t\\tif cert_file is None:\\n\\t\\t\\t\\tcert_file = os.environ.get('GLANCE_CLIENT_CERT_FILE')\\n\\t\\t\\tif ca_file is None:\\n\\t\\t\\t\\tca_file = os.environ.get('GLANCE_CLIENT_CA_FILE')\\n\\t\\t\\tif cert_file is not None and key_file is None:\\n\\t\\t\\t\\tmsg = _(\"You have selected to use SSL in connecting, \"\\n\\t\\t\\t\\t\\t\\t\"and you have supplied a cert, \"\\n\\t\\t\\t\\t\\t\\t\"however you have failed to supply either a \"\\n\\t\\t\\t\\t\\t\\t\"key_file parameter or set the \"\\n\\t\\t\\t\\t\\t\\t\"GLANCE_CLIENT_KEY_FILE environ variable\")\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tif key_file is not None and cert_file is None:\\n\\t\\t\\t\\tmsg = _(\"You have selected to use SSL in connecting, \"\\n\\t\\t\\t\\t\\t\\t\"and you have supplied a key, \"\\n\\t\\t\\t\\t\\t\\t\"however you have failed to supply either a \"\\n\\t\\t\\t\\t\\t\\t\"cert_file parameter or set the \"\\n\\t\\t\\t\\t\\t\\t\"GLANCE_CLIENT_CERT_FILE environ variable\")\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tif key_file is not None and not os.path.exists(key_file):\\n\\t\\t\\t\\tmsg = _(\"The key file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t\"exist\") % key_file\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tself.connect_kwargs['key_file'] = key_file\\n\\t\\t\\tif cert_file is not None and not os.path.exists(cert_file):\\n\\t\\t\\t\\tmsg = _(\"The cert file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t\"exist\") % cert_file\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tself.connect_kwargs['cert_file'] = cert_file\\n\\t\\t\\tif ca_file is not None and not os.path.exists(ca_file):\\n\\t\\t\\t\\tmsg = _(\"The CA file you specified %s does not \"\\n\\t\\t\\t\\t\\t\\t\"exist\") % ca_file\\n\\t\\t\\t\\traise exception.ClientConnectionError(msg)\\n\\t\\t\\tself.connect_kwargs['ca_file'] = ca_file",
         "class BaseClient(object)",
         null,
         "By modifying the BaseClient class initialization, you can trigger a Missing Large and Localized Part of the Algorithm (MLPS) fault. The function should fail due to removing the CA file path constant and its related logic, including the insecure parameter handling, causing potential security issues in SSL connections.",
         "Inject a bug in the BaseClient class to trigger a missing large and localized part of the algorithm (MLPS) fault. The function should fail due to the absence of default CA file handling and secure connection settings, potentially causing connection errors when default CA files are not found.",
         "Inject a bug in the BaseClient class to trigger a missing large and localized part of the algorithm (MLPS) fault.",
         "openstack",
         "2.6.0",
         "['test_ssl.py']",
         "https://github.com/Centrinix/openstack-glance",
         "MLPS"
        ],
        [
         "22",
         "To prevent remote code injection on Sheepdog store",
         "security",
         null,
         "https://github.com/python/cpython/commit/135faec747669a81dd0db7b4a786edc529a68960",
         "135faec747669a81dd0db7b4a786edc529a68960",
         "PySecDB",
         "diff --git a/glance/store/sheepdog.py b/glance/store/sheepdog.py\\nindex 11293f0e..7a0133c8 100644\\n--- a/glance/store/sheepdog.py\\n+++ b/glance/store/sheepdog.py\\n@@ -20,6 +20,7 @@ import hashlib\\n from oslo.config import cfg\\n \\n from glance.common import exception\\n+from glance.common import utils\\n from glance.openstack.common import excutils\\n import glance.openstack.common.log as logging\\n from glance.openstack.common import processutils\\n@@ -31,7 +32,7 @@ import glance.store.location\\n \\n LOG = logging.getLogger(__name__)\\n \\n-DEFAULT_ADDR = 'localhost'\\n+DEFAULT_ADDR = '127.0.0.1'\\n DEFAULT_PORT = 7000\\n DEFAULT_CHUNKSIZE = 64  # in MiB\\n \\n@@ -62,18 +63,14 @@ class SheepdogImage:\\n\\t\\t self.chunk_size = chunk_size\\n \\n\\t def _run_command(self, command, data, *params):\\n-\\t\\tcmd = (\"collie vdi %(command)s -a %(addr)s -p %(port)d %(name)s \"\\n-\\t\\t\\t   \"%(params)s\" %\\n-\\t\\t\\t   {\"command\": command,\\n-\\t\\t\\t\\t\"addr\": self.addr,\\n-\\t\\t\\t\\t\"port\": self.port,\\n-\\t\\t\\t\\t\"name\": self.name,\\n-\\t\\t\\t\\t\"params\": \" \".join(map(str, params))})\\n+\\t\\tcmd = [\"collie\", \"vdi\"]\\n+\\t\\tcmd.extend(command)\\n+\\t\\tcmd.extend([\"-a\", self.addr, \"-p\", self.port, self.name])\\n+\\t\\tcmd.extend(params)\\n \\n\\t\\t try:\\n-\\t\\t\\treturn processutils.execute(\\n-\\t\\t\\t\\tcmd, process_input=data, shell=True)[0]\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n+\\t\\t\\treturn processutils.execute(*cmd, process_input=data)[0]\\n+\\t\\texcept (processutils.ProcessExecutionError, OSError) as exc:\\n\\t\\t\\t LOG.error(exc)\\n\\t\\t\\t raise glance.store.BackendException(exc)\\n \\n@@ -83,7 +80,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t return long(out.split(' ')[3])\\n \\n\\t def read(self, offset, count):\\n@@ -93,7 +90,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi read -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\treturn self._run_command(\"read\", None, str(offset), str(count))\\n+\\t\\treturn self._run_command([\"read\"], None, str(offset), str(count))\\n \\n\\t def write(self, data, offset, count):\\n\\t\\t \"\"\"\\n@@ -102,7 +99,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi write -a address -p port image offset len\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"write\", data, str(offset), str(count))\\n+\\t\\tself._run_command([\"write\"], data, str(offset), str(count))\\n \\n\\t def create(self, size):\\n\\t\\t \"\"\"\\n@@ -110,7 +107,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi create -a address -p port image size\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"create\", None, str(size))\\n+\\t\\tself._run_command([\"create\"], None, str(size))\\n \\n\\t def delete(self):\\n\\t\\t \"\"\"\\n@@ -118,7 +115,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi delete -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tself._run_command(\"delete\", None)\\n+\\t\\tself._run_command([\"delete\"], None)\\n \\n\\t def exist(self):\\n\\t\\t \"\"\"\\n@@ -126,7 +123,7 @@ class SheepdogImage:\\n \\n\\t\\t Sheepdog Usage: collie vdi list -r -a address -p port image\\n\\t\\t \"\"\"\\n-\\t\\tout = self._run_command(\"list -r\", None)\\n+\\t\\tout = self._run_command([\"list\", \"-r\"], None)\\n\\t\\t if not out:\\n\\t\\t\\t return False\\n\\t\\t else:\\n@@ -137,7 +134,7 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t \"\"\"\\n\\t Class describing a Sheepdog URI. This is of the form:\\n \\n-\\t\\tsheepdog://image\\n+\\t\\tsheepdog://image-id\\n \\n\\t \"\"\"\\n \\n@@ -148,10 +145,14 @@ class StoreLocation(glance.store.location.StoreLocation):\\n\\t\\t return \"sheepdog://%s\" % self.image\\n \\n\\t def parse_uri(self, uri):\\n-\\t\\tif not uri.startswith('sheepdog://'):\\n-\\t\\t\\traise exception.BadStoreUri(uri, \"URI must start with %s://\" %\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'sheepdog')\\n-\\t\\tself.image = uri[11:]\\n+\\t\\tvalid_schema = 'sheepdog://'\\n+\\t\\tif not uri.startswith(valid_schema):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must start with %s://\") %\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvalid_schema)\\n+\\t\\tself.image = uri[len(valid_schema):]\\n+\\t\\tif not utils.is_uuid_like(self.image):\\n+\\t\\t\\traise exception.BadStoreUri(_(\"URI must contains well-formated \"\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \"image id\"))\\n \\n \\n class ImageIterator(object):\\n@@ -191,7 +192,7 @@ class Store(glance.store.base.Store):\\n \\n\\t\\t try:\\n\\t\\t\\t self.chunk_size = CONF.sheepdog_store_chunk_size * units.Mi\\n-\\t\\t\\tself.addr = CONF.sheepdog_store_address\\n+\\t\\t\\tself.addr = CONF.sheepdog_store_address.strip()\\n\\t\\t\\t self.port = CONF.sheepdog_store_port\\n\\t\\t except cfg.ConfigFileValueError as e:\\n\\t\\t\\t reason = _(\"Error in store configuration: %s\") % e\\n@@ -199,10 +200,18 @@ class Store(glance.store.base.Store):\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\n \\n+\\t\\tif ' ' in self.addr:\\n+\\t\\t\\treason = (_(\"Invalid address configuration of sheepdog store: %s\")\\n+\\t\\t\\t\\t\\t  % self.addr)\\n+\\t\\t\\tLOG.error(reason)\\n+\\t\\t\\traise exception.BadStoreConfiguration(store_name='sheepdog',\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  reason=reason)\\n+\\n\\t\\t try:\\n-\\t\\t\\tprocessutils.execute(\"collie\", shell=True)\\n-\\t\\texcept processutils.ProcessExecutionError as exc:\\n-\\t\\t\\treason = _(\"Error in store configuration: %s\") % exc\\n+\\t\\t\\tcmd = [\"collie\", \"vdi\", \"list\", \"-a\", self.addr, \"-p\", self.port]\\n+\\t\\t\\tprocessutils.execute(*cmd)\\n+\\t\\texcept Exception as e:\\n+\\t\\t\\treason = _(\"Error in store configuration: %s\") % e\\n\\t\\t\\t LOG.error(reason)\\n\\t\\t\\t raise exception.BadStoreConfiguration(store_name='sheepdog',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   reason=reason)\\ndiff --git a/glance/tests/unit/test_sheepdog_store.py b/glance/tests/unit/test_sheepdog_store.py\\nindex 02233497..7dc57ab2 100644\\n--- a/glance/tests/unit/test_sheepdog_store.py\\n+++ b/glance/tests/unit/test_sheepdog_store.py\\n@@ -56,4 +56,5 @@ class TestStore(base.StoreClearingUnitTest):\\n\\t\\t\\t\\t\\t\\t   'fake_image_id',\\n\\t\\t\\t\\t\\t\\t   utils.LimitingReader(six.StringIO('xx'), 1),\\n\\t\\t\\t\\t\\t\\t   2)\\n-\\t\\tself.assertEqual(called_commands, ['list -r', 'create', 'delete'])\\n+\\t\\tself.assertEqual([['list', '-r'], ['create'], ['delete']],\\n+\\t\\t\\t\\t\\t\\t called_commands)\\ndiff --git a/glance/tests/unit/test_store_location.py b/glance/tests/unit/test_store_location.py\\nindex 898fe8c7..df8d5d78 100644\\n--- a/glance/tests/unit/test_store_location.py\\n+++ b/glance/tests/unit/test_store_location.py\\n@@ -66,7 +66,7 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t\\t 'rbd://imagename',\\n\\t\\t\\t 'rbd://fsid/pool/image/snap',\\n\\t\\t\\t 'rbd://%2F/%2F/%2F/%2F',\\n-\\t\\t\\t'sheepdog://imagename',\\n+\\t\\t\\t'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c',\\n\\t\\t\\t 'cinder://12345678-9012-3455-6789-012345678901',\\n\\t\\t\\t 'vsphere://ip/folder/openstack_glance/2332298?dcPath=dc&dsName=ds',\\n\\t\\t ]\\n@@ -382,15 +382,18 @@ class TestStoreLocation(base.StoreClearingUnitTest):\\n\\t\\t \"\"\"\\n\\t\\t Test the specific StoreLocation for the Sheepdog store\\n\\t\\t \"\"\"\\n-\\t\\turi = 'sheepdog://imagename'\\n+\\t\\turi = 'sheepdog://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t loc = glance.store.sheepdog.StoreLocation({})\\n\\t\\t loc.parse_uri(uri)\\n-\\t\\tself.assertEqual('imagename', loc.image)\\n+\\t\\tself.assertEqual('244e75f1-9c69-4167-9db7-1aa7d1973f6c', loc.image)\\n \\n-\\t\\tbad_uri = 'sheepdog:/image'\\n+\\t\\tbad_uri = 'sheepdog:/244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n-\\t\\tbad_uri = 'http://image'\\n+\\t\\tbad_uri = 'http://244e75f1-9c69-4167-9db7-1aa7d1973f6c'\\n+\\t\\tself.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n+\\n+\\t\\tbad_uri = 'image; name'\\n\\t\\t self.assertRaises(exception.BadStoreUri, loc.parse_uri, bad_uri)\\n \\n\\t def test_vmware_store_location(self):",
         "def write(self, data, offset, count):\\n\\t\\tself._run_command([\"write\"], data, str(offset), str(count))",
         "def write(self, data, offset, count):\\n\\t\\tself._run_command(\"write\", data, str(offset), str(count))",
         "def write(self, data, offset, count)",
         null,
         "Alter the behavior of the write function to introduce a Wrong Variable Used in Parameter of Function Call (WPFV) fault. The function should fail due to passing an incorrect variable type to _run_command.",
         "Introduce an error in the write function where the wrong variable type is used in a function call. The function should fail due to incorrect parameter type in _run_command.",
         "Introduce an error in the write function where the wrong variable type is used in a function call.",
         "openstack",
         "3.9.0",
         "['test_sheepdog_store.py', 'test_store_location.py']",
         "https://github.com/Centrinix/openstack-glance",
         "WPFV"
        ],
        [
         "23",
         "Fix commenting thread notifications being sent to non-thread users",
         "security",
         "CVE-2022-21683",
         "https://github.com/python/cpython/commit/5fe901e5d86ed02dbbb63039a897582951266afd",
         "5fe901e5d86ed02dbbb63039a897582951266afd",
         "PySecDB",
         "diff --git a/wagtail/admin/tests/pages/test_edit_page.py b/wagtail/admin/tests/pages/test_edit_page.py\\nindex 7eab6481da..2d3e00cace 100644\\n--- a/wagtail/admin/tests/pages/test_edit_page.py\\n+++ b/wagtail/admin/tests/pages/test_edit_page.py\\n@@ -2100,6 +2100,7 @@ class TestCommenting(TestCase, WagtailTestUtils):\\n\\t\\t self.subscriber = self.create_user('subscriber')\\n\\t\\t self.non_subscriber = self.create_user('non-subscriber')\\n\\t\\t self.non_subscriber_2 = self.create_user('non-subscriber-2')\\n+\\t\\tself.never_emailed_user = self.create_user('never-emailed')\\n \\n\\t\\t PageSubscription.objects.create(\\n\\t\\t\\t page=self.child_page,\\n@@ -2113,6 +2114,23 @@ class TestCommenting(TestCase, WagtailTestUtils):\\n\\t\\t\\t comment_notifications=True\\n\\t\\t )\\n \\n+\\t\\t# Add comment and reply on a different page for the never_emailed_user\\n+\\t\\t# They should never be notified\\n+\\t\\tcomment_on_other_page = Comment.objects.create(\\n+\\t\\t\\tpage=self.root_page,\\n+\\t\\t\\tuser=self.never_emailed_user,\\n+\\t\\t\\ttext='a comment'\\n+\\t\\t)\\n+\\n+\\t\\tCommentReply.objects.create(\\n+\\t\\t\\tuser=self.never_emailed_user,\\n+\\t\\t\\tcomment=comment_on_other_page,\\n+\\t\\t\\ttext='a reply'\\n+\\t\\t)\\n+\\n+\\tdef assertNeverEmailedWrongUser(self):\\n+\\t\\tself.assertNotIn(self.never_emailed_user.email, [to for email in mail.outbox for to in email.to])\\n+\\n\\t def test_new_comment(self):\\n\\t\\t post_data = {\\n\\t\\t\\t 'title': \"I've been edited!\",\\n@@ -2144,6 +2162,7 @@ class TestCommenting(TestCase, WagtailTestUtils):\\n \\n\\t\\t # Check notification email\\n\\t\\t self.assertEqual(len(mail.outbox), 1)\\n+\\t\\tself.assertNeverEmailedWrongUser()\\n\\t\\t self.assertEqual(mail.outbox[0].to, [self.subscriber.email])\\n\\t\\t self.assertEqual(mail.outbox[0].subject, 'test@email.com has updated comments on \"I\\'ve been edited! (simple page)\"')\\n\\t\\t self.assertIn('New comments:\\n - \"A test comment\"\\n\\n', mail.outbox[0].body)\\n@@ -2283,6 +2302,7 @@ class TestCommenting(TestCase, WagtailTestUtils):\\n \\n\\t\\t # Check notification email\\n\\t\\t self.assertEqual(len(mail.outbox), 2)\\n+\\t\\tself.assertNeverEmailedWrongUser()\\n\\t\\t # The non subscriber created the comment, so should also get an email\\n\\t\\t self.assertEqual(mail.outbox[0].to, [self.non_subscriber.email])\\n\\t\\t self.assertEqual(mail.outbox[0].subject, 'test@email.com has updated comments on \"I\\'ve been edited! (simple page)\"')\\n@@ -2337,6 +2357,7 @@ class TestCommenting(TestCase, WagtailTestUtils):\\n \\n\\t\\t # Check notification email\\n\\t\\t self.assertEqual(len(mail.outbox), 1)\\n+\\t\\tself.assertNeverEmailedWrongUser()\\n\\t\\t self.assertEqual(mail.outbox[0].to, [self.subscriber.email])\\n\\t\\t self.assertEqual(mail.outbox[0].subject, 'test@email.com has updated comments on \"I\\'ve been edited! (simple page)\"')\\n\\t\\t self.assertIn('Deleted comments:\\n - \"A test comment\"\\n\\n', mail.outbox[0].body)\\n@@ -2398,6 +2419,7 @@ class TestCommenting(TestCase, WagtailTestUtils):\\n \\n\\t\\t # Check notification email\\n\\t\\t self.assertEqual(len(mail.outbox), 3)\\n+\\t\\tself.assertNeverEmailedWrongUser()\\n \\n\\t\\t recipients = [mail.to for mail in mail.outbox]\\n\\t\\t # The other non subscriber replied in the thread, so should get an email\\ndiff --git a/wagtail/admin/views/pages/edit.py b/wagtail/admin/views/pages/edit.py\\nindex 2edf11b450..9f942243f2 100644\\n--- a/wagtail/admin/views/pages/edit.py\\n+++ b/wagtail/admin/views/pages/edit.py\\n@@ -141,11 +141,11 @@ class EditView(TemplateResponseMixin, ContextMixin, HookResponseMixin, View):\\n\\t\\t # Get subscribers to individual threads\\n\\t\\t replies = CommentReply.objects.filter(comment_id__in=relevant_comment_ids)\\n\\t\\t comments = Comment.objects.filter(id__in=relevant_comment_ids)\\n-\\t\\tthread_users = get_user_model().objects.exclude(pk=self.request.user.pk).exclude(pk__in=subscribers.values_list('user_id', flat=True)).prefetch_related(\\n+\\t\\tthread_users = get_user_model().objects.exclude(pk=self.request.user.pk).exclude(pk__in=subscribers.values_list('user_id', flat=True)).filter(\\n+\\t\\t\\tQ(comment_replies__comment_id__in=relevant_comment_ids) | Q(**{('%s__pk__in' % COMMENTS_RELATION_NAME): relevant_comment_ids})\\n+\\t\\t).prefetch_related(\\n\\t\\t\\t Prefetch('comment_replies', queryset=replies),\\n\\t\\t\\t Prefetch(COMMENTS_RELATION_NAME, queryset=comments)\\n-\\t\\t).exclude(\\n-\\t\\t\\tQ(comment_replies__isnull=True) & Q(**{('%s__isnull' % COMMENTS_RELATION_NAME): True})\\n\\t\\t )\\n \\n\\t\\t # Skip if no recipients",
         "def send_commenting_notifications(self, changes):\\n\\t\\trelevant_comment_ids = []\\n\\t\\trelevant_comment_ids.extend(comment.pk for comment in changes['resolved_comments'])\\n\\t\\trelevant_comment_ids.extend(comment.pk for comment, replies in changes['new_replies'])\\n\\t\\tif (not changes['new_comments']\\n\\t\\t\\t\\tand not changes['deleted_comments']\\n\\t\\t\\t\\tand not changes['resolved_comments']\\n\\t\\t\\t\\tand not changes['new_replies']):\\n\\t\\t\\treturn\\n\\t\\tsubscribers = PageSubscription.objects.filter(page=self.page, comment_notifications=True).select_related('user')\\n\\t\\tglobal_recipient_users = [subscriber.user for subscriber in subscribers if subscriber.user != self.request.user]\\n\\t\\treplies = CommentReply.objects.filter(comment_id__in=relevant_comment_ids)\\n\\t\\tcomments = Comment.objects.filter(id__in=relevant_comment_ids)\\n\\t\\tthread_users = get_user_model().objects.exclude(pk=self.request.user.pk).exclude(pk__in=subscribers.values_list('user_id', flat=True)).filter(\\n\\t\\t\\tQ(comment_replies__comment_id__in=relevant_comment_ids) | Q(**{('%s__pk__in' % COMMENTS_RELATION_NAME): relevant_comment_ids})\\n\\t\\t).prefetch_related(\\n\\t\\t\\tPrefetch('comment_replies', queryset=replies),\\n\\t\\t\\tPrefetch(COMMENTS_RELATION_NAME, queryset=comments)\\n\\t\\t)\\n\\t\\tif not (global_recipient_users or thread_users):\\n\\t\\t\\treturn\\n\\t\\tthread_users = [(user, set(list(user.comment_replies.values_list('comment_id', flat=True)) + list(getattr(user, COMMENTS_RELATION_NAME).values_list('pk', flat=True)))) for user in thread_users]\\n\\t\\tmailed_users = set()\\n\\t\\tfor current_user, current_threads in thread_users:\\n\\t\\t\\tif current_user in mailed_users:\\n\\t\\t\\t\\tcontinue\\n\\t\\t\\tusers = [current_user]\\n\\t\\t\\tmailed_users.add(current_user)\\n\\t\\t\\tfor user, threads in thread_users:\\n\\t\\t\\t\\tif user not in mailed_users and threads == current_threads:\\n\\t\\t\\t\\t\\tusers.append(user)\\n\\t\\t\\t\\t\\tmailed_users.add(user)\\n\\t\\t\\tsend_notification(users, 'updated_comments', {\\n\\t\\t\\t\\t'page': self.page,\\n\\t\\t\\t\\t'editor': self.request.user,\\n\\t\\t\\t\\t'new_comments': [comment for comment in changes['new_comments'] if comment.pk in threads],\\n\\t\\t\\t\\t'resolved_comments': [comment for comment in changes['resolved_comments'] if comment.pk in threads],\\n\\t\\t\\t\\t'deleted_comments': [],\\n\\t\\t\\t\\t'replied_comments': [\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t'comment': comment,\\n\\t\\t\\t\\t\\t\\t'replies': replies,\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\tfor comment, replies in changes['new_replies']\\n\\t\\t\\t\\t\\tif comment.pk in threads\\n\\t\\t\\t\\t]\\n\\t\\t\\t})\\n\\t\\treturn send_notification(global_recipient_users, 'updated_comments', {\\n\\t\\t\\t'page': self.page,\\n\\t\\t\\t'editor': self.request.user,\\n\\t\\t\\t'new_comments': changes['new_comments'],\\n\\t\\t\\t'resolved_comments': changes['resolved_comments'],\\n\\t\\t\\t'deleted_comments': changes['deleted_comments'],\\n\\t\\t\\t'replied_comments': [\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t'comment': comment,\\n\\t\\t\\t\\t\\t'replies': replies,\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tfor comment, replies in changes['new_replies']\\n\\t\\t\\t]\\n\\t\\t})",
         "def send_commenting_notifications(self, changes):\\n\\t\\trelevant_comment_ids = []\\n\\t\\trelevant_comment_ids.extend(comment.pk for comment in changes['resolved_comments'])\\n\\t\\trelevant_comment_ids.extend(comment.pk for comment, replies in changes['new_replies'])\\n\\t\\tif (not changes['new_comments']\\n\\t\\t\\t\\tand not changes['deleted_comments']\\n\\t\\t\\t\\tand not changes['resolved_comments']\\n\\t\\t\\t\\tand not changes['new_replies']):\\n\\t\\t\\treturn\\n\\t\\tsubscribers = PageSubscription.objects.filter(page=self.page, comment_notifications=True).select_related('user')\\n\\t\\tglobal_recipient_users = [subscriber.user for subscriber in subscribers if subscriber.user != self.request.user]\\n\\t\\treplies = CommentReply.objects.filter(comment_id__in=relevant_comment_ids)\\n\\t\\tcomments = Comment.objects.filter(id__in=relevant_comment_ids)\\n\\t\\tthread_users = get_user_model().objects.exclude(pk=self.request.user.pk).exclude(pk__in=subscribers.values_list('user_id', flat=True)).prefetch_related(\\n\\t\\t\\tPrefetch('comment_replies', queryset=replies),\\n\\t\\t\\tPrefetch(COMMENTS_RELATION_NAME, queryset=comments)\\n\\t\\t).exclude(\\n\\t\\t\\tQ(comment_replies__isnull=True) & Q(**{('%s__isnull' % COMMENTS_RELATION_NAME): True})\\n\\t\\t)\\n\\t\\tif not (global_recipient_users or thread_users):\\n\\t\\t\\treturn\\n\\t\\tthread_users = [(user, set(list(user.comment_replies.values_list('comment_id', flat=True)) + list(getattr(user, COMMENTS_RELATION_NAME).values_list('pk', flat=True)))) for user in thread_users]\\n\\t\\tmailed_users = set()\\n\\t\\tfor current_user, current_threads in thread_users:\\n\\t\\t\\tif current_user in mailed_users:\\n\\t\\t\\t\\tcontinue\\n\\t\\t\\tusers = [current_user]\\n\\t\\t\\tmailed_users.add(current_user)\\n\\t\\t\\tfor user, threads in thread_users:\\n\\t\\t\\t\\tif user not in mailed_users and threads == current_threads:\\n\\t\\t\\t\\t\\tusers.append(user)\\n\\t\\t\\t\\t\\tmailed_users.add(user)\\n\\t\\t\\tsend_notification(users, 'updated_comments', {\\n\\t\\t\\t\\t'page': self.page,\\n\\t\\t\\t\\t'editor': self.request.user,\\n\\t\\t\\t\\t'new_comments': [comment for comment in changes['new_comments'] if comment.pk in threads],\\n\\t\\t\\t\\t'resolved_comments': [comment for comment in changes['resolved_comments'] if comment.pk in threads],\\n\\t\\t\\t\\t'deleted_comments': [],\\n\\t\\t\\t\\t'replied_comments': [\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t'comment': comment,\\n\\t\\t\\t\\t\\t\\t'replies': replies,\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\tfor comment, replies in changes['new_replies']\\n\\t\\t\\t\\t\\tif comment.pk in threads\\n\\t\\t\\t\\t]\\n\\t\\t\\t})\\n\\t\\treturn send_notification(global_recipient_users, 'updated_comments', {\\n\\t\\t\\t'page': self.page,\\n\\t\\t\\t'editor': self.request.user,\\n\\t\\t\\t'new_comments': changes['new_comments'],\\n\\t\\t\\t'resolved_comments': changes['resolved_comments'],\\n\\t\\t\\t'deleted_comments': changes['deleted_comments'],\\n\\t\\t\\t'replied_comments': [\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t'comment': comment,\\n\\t\\t\\t\\t\\t'replies': replies,\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tfor comment, replies in changes['new_replies']\\n\\t\\t\\t]\\n\\t\\t})",
         "def send_commenting_notifications(self, changes)",
         null,
         "Implement a bug in the send_commenting_notifications function to trigger a Wrong Logical Expression Used as Branch Condition (WLEC) fault and to induce incorrect filtering of thread users. The function should fail due to using an incorrect filtering condition in the exclude clause.",
         "Trigger a wrong logical expression used as branch condition (WLEC) fault within the send_commenting_notifications function. The function should fail due to incorrect filtering of thread users, potentially causing notifications to be sent to non-thread users.",
         "Trigger a wrong logical expression used as branch condition (WLEC) fault within the send_commenting_notifications function.",
         "clone_aveola",
         "3.7.0",
         "['test_edit_page.py']",
         "https://github.com/Hernandison/clone_aveola_t",
         "WLEC"
        ],
        [
         "24",
         "fix path traversal vulnerability (#156)\\n\\n\\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\\n```\\n>>> import os.path\\n>>> static = \"path/to/mySafeStaticDir\"\\n>>> malicious = \"/../../../../../etc/passwd\"\\n>>> os.path.join(t,malicious)\\n'/../../../../../etc/passwd'\\n```\\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\\n\\nIn this case, the problems occurs due to the following code :\\n\\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\\n\\nThe bug can be verified using a proof of concept similar to the one shown below.\\n\\n```\\n```\\n\\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `flask.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\\n\\n\\n\\n---------",
         "security",
         null,
         "https://github.com/python/cpython/commit/bd06f7839324bb85da6026d32762f1bf82231b93",
         "bd06f7839324bb85da6026d32762f1bf82231b93",
         "MoreFixes",
         "diff --git a/app/config.py b/app/config.py\\nindex 90cf228e8..b4e8f47fc 100644\\n--- a/app/config.py\\n+++ b/app/config.py\\n@@ -45,10 +45,13 @@ class ProductionConfig(Config):\\n \\n \\n class TestingConfig(Config):\\n+\\tDEBUG = True\\n\\t SQLALCHEMY_DATABASE_URI = os.environ.get(\"DATABASE_URL\") or \"sqlite:///\" + os.path.join(\\n\\t\\t basedir, \"database/testing.sqlite\"\\n\\t )\\n\\t LOG_EXCEPTIONS = True\\n+\\tTESTING = True\\n+\\tWTF_CSRF_ENABLED = False\\n \\n \\n config = {\\ndiff --git a/app/main/views.py b/app/main/views.py\\nindex 4070e7dea..ab6eb765d 100644\\n--- a/app/main/views.py\\n+++ b/app/main/views.py\\n@@ -1,4 +1,5 @@\\n from flask import render_template, redirect, request, jsonify, send_file, abort, current_app\\n+from werkzeug.security import safe_join\\n from flask_login import current_user, login_required, login_user, logout_user\\n from .. import db\\n from .. import plugins\\n@@ -678,8 +679,11 @@ def swapactionorder():  # TODO: sort out permissions for this (e.g. who has the\\n @main.route(\"/plugins/<path:path>\")\\n @login_required\\n def static_file(path):\\n-\\t# TODO: this looks a bit unsafe to me\\n-\\treturn send_file(\"../plugins/\" + path)\\n+\\tpath = safe_join(\"../plugins/\", path)\\n+\\tif path is None:\\n+\\t\\tabort(404)\\n+\\telse:\\n+\\t\\treturn send_file(path)\\n \\n \\n def str_to_bool(str):\\ndiff --git a/app/tests/test_main.py b/app/tests/test_main.py\\nindex 51fcc5d90..999874564 100644\\n--- a/app/tests/test_main.py\\n+++ b/app/tests/test_main.py\\n@@ -10,6 +10,32 @@ def test_instantiate_app():\\n\\t assert app is not None\\n \\n \\n+def test_issue129():\\n+\\t\"\"\"Test that the issue #129 is fixed.\"\"\"\\n+\\tapp = create_app(\"testing\")\\n+\\tmigrate = Migrate()\\n+\\n+\\t# make sure that testing DB does not exist\\n+\\tdb_path = app.config.get(\"SQLALCHEMY_DATABASE_URI\").replace(\"sqlite:///\", \"\")\\n+\\tif os.path.exists(db_path):\\n+\\t\\tos.remove(db_path)\\n+\\n+\\twith app.app_context():\\n+\\t\\tdb.init_app(app)\\n+\\t\\tmigrate.init_app(app, db)\\n+\\t\\tupgrade()\\n+\\n+\\t# recreate app to initialize activity table\\n+\\tapp = create_app(\"testing\")\\n+\\n+\\twith app.test_client() as c:\\n+\\t\\t# log in via HTTP\\n+\\t\\tr = c.post(\"/auth/login\", data={\"username\": \"admin\", \"password\": \"admin\"})\\n+\\t\\tassert r.status_code == 302\\n+\\t\\tr = c.get(\"/plugins/../README.md\")\\n+\\t\\tassert r.status_code == 404\\n+\\n+\\n def test_db_migrations():\\n\\t \"\"\"Test that the database migrations can be run.\"\"\"\\n\\t app = create_app(\"testing\")",
         "def static_file(path):\\n\\tpath = safe_join(\"../plugins/\", path)\\n\\tif path is None:\\n\\t\\tabort(404)\\n\\telse:\\n\\t\\treturn send_file(path)",
         "def static_file(path):\\n\\treturn send_file(\"../plugins/\" + path)",
         "def static_file(path)",
         null,
         "Alter the behavior of the static_file function to introduce Missing Function Call (MFC) fault. The function should fail due to not calling safe_join for path sanitization.",
         "Alter the behavior of the static_file function to introduce missing function call, causing potential path traversal vulnerabilities.",
         "Alter the behavior of the static_file function to introduce missing function call.",
         "msm",
         "3.8.0",
         "['test_main.py']",
         "https://github.com/HolgerGraef/MSM",
         "MFC"
        ],
        [
         "25",
         "ENH: Cast non-object arrays to float in np.poly\\n\\nCloses #5096. Casts integer arrays to np.double, to prevent\\ninteger overflow. Object arrays are left unchanged, to allow\\nuse of arbitrary precision objects.",
         "security",
         null,
         "https://github.com/python/cpython/commit/3a0587e545e959747d9b501dbf029a4cd6576547",
         "3a0587e545e959747d9b501dbf029a4cd6576547",
         "PySecDB",
         "diff --git a/doc/release/1.10.0-notes.rst b/doc/release/1.10.0-notes.rst\\nindex 553267cad..333ce2c77 100644\\n--- a/doc/release/1.10.0-notes.rst\\n+++ b/doc/release/1.10.0-notes.rst\\n@@ -37,6 +37,13 @@ and a bit faster.\\n Improvements\\n ============\\n \\n+`np.poly` now casts integer inputs to float\\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n+`np.poly` will now cast 1-dimensional input arrays of integer type to double\\n+precision floating point, to prevent integer overflow when computing the monic\\n+polynomial. It is still possible to obtain higher precision results by\\n+passing in an array of object type, filled e.g. with Python ints.\\n+\\n \\n Changes\\n =======\\ndiff --git a/numpy/lib/polynomial.py b/numpy/lib/polynomial.py\\nindex 7e4ec1485..2b867e244 100644\\n--- a/numpy/lib/polynomial.py\\n+++ b/numpy/lib/polynomial.py\\n@@ -12,10 +12,11 @@ import re\\n import warnings\\n import numpy.core.numeric as NX\\n \\n-from numpy.core import isscalar, abs, finfo, atleast_1d, hstack, dot\\n+from numpy.core import (isscalar, abs, finfo, atleast_1d, hstack, dot, array,\\n+\\t\\t\\t\\t\\t\\tones)\\n from numpy.lib.twodim_base import diag, vander\\n from numpy.lib.function_base import trim_zeros, sort_complex\\n-from numpy.lib.type_check import iscomplex, real, imag\\n+from numpy.lib.type_check import iscomplex, real, imag, mintypecode\\n from numpy.linalg import eigvals, lstsq, inv\\n \\n class RankWarning(UserWarning):\\n@@ -122,19 +123,24 @@ def poly(seq_of_zeros):\\n\\t \"\"\"\\n\\t seq_of_zeros = atleast_1d(seq_of_zeros)\\n\\t sh = seq_of_zeros.shape\\n+\\n\\t if len(sh) == 2 and sh[0] == sh[1] and sh[0] != 0:\\n\\t\\t seq_of_zeros = eigvals(seq_of_zeros)\\n\\t elif len(sh) == 1:\\n-\\t\\tpass\\n+\\t\\tdt = seq_of_zeros.dtype\\n+\\t\\t# Let object arrays slip through, e.g. for arbitrary precision\\n+\\t\\tif dt != object:\\n+\\t\\t\\tseq_of_zeros = seq_of_zeros.astype(mintypecode(dt.char))\\n\\t else:\\n\\t\\t raise ValueError(\"input must be 1d or non-empty square 2d array.\")\\n \\n\\t if len(seq_of_zeros) == 0:\\n\\t\\t return 1.0\\n-\\n-\\ta = [1]\\n+\\tdt = seq_of_zeros.dtype\\n+\\ta = ones((1,), dtype=dt)\\n\\t for k in range(len(seq_of_zeros)):\\n-\\t\\ta = NX.convolve(a, [1, -seq_of_zeros[k]], mode='full')\\n+\\t\\ta = NX.convolve(a, array([1, -seq_of_zeros[k]], dtype=dt),\\n+\\t\\t\\t\\t\\t\\tmode='full')\\n \\n\\t if issubclass(a.dtype.type, NX.complexfloating):\\n\\t\\t # if complex roots are all complex conjugates, the roots are real.\\ndiff --git a/numpy/lib/tests/test_polynomial.py b/numpy/lib/tests/test_polynomial.py\\nindex 02faa0283..5c15941e6 100644\\n--- a/numpy/lib/tests/test_polynomial.py\\n+++ b/numpy/lib/tests/test_polynomial.py\\n@@ -153,6 +153,9 @@ class TestDocs(TestCase):\\n\\t\\t assert_(p2[3] == Decimal(\"1.333333333333333333333333333\"))\\n\\t\\t assert_(p2[2] == Decimal('1.5'))\\n\\t\\t assert_(np.issubdtype(p2.coeffs.dtype, np.object_))\\n+\\t\\tp = np.poly([Decimal(1), Decimal(2)])\\n+\\t\\tassert_equal(np.poly([Decimal(1), Decimal(2)]),\\n+\\t\\t\\t\\t\\t [1, Decimal(-3), Decimal(2)])\\n \\n\\t def test_complex(self):\\n\\t\\t p = np.poly1d([3j, 2j, 1j])\\n@@ -173,5 +176,13 @@ class TestDocs(TestCase):\\n\\t\\t except ValueError:\\n\\t\\t\\t pass\\n \\n+\\tdef test_poly_int_overflow(self):\\n+\\t\\t\"\"\"\\n+\\t\\tRegression test for gh-5096.\\n+\\t\\t\"\"\"\\n+\\t\\tv = np.arange(1, 21)\\n+\\t\\tassert_almost_equal(np.poly(v), np.poly(np.diag(v)))\\n+\\n+\\n if __name__ == \"__main__\":\\n\\t run_module_suite()",
         "def poly(seq_of_zeros):\\n\\tseq_of_zeros = atleast_1d(seq_of_zeros)\\n\\tsh = seq_of_zeros.shape\\n\\tif len(sh) == 2 and sh[0] == sh[1] and sh[0] != 0:\\n\\t\\tseq_of_zeros = eigvals(seq_of_zeros)\\n\\telif len(sh) == 1:\\n\\t\\tdt = seq_of_zeros.dtype\\n\\t\\tif dt != object:\\n\\t\\t\\tseq_of_zeros = seq_of_zeros.astype(mintypecode(dt.char))\\n\\telse:\\n\\t\\traise ValueError(\"input must be 1d or non-empty square 2d array.\")\\n\\tif len(seq_of_zeros) == 0:\\n\\t\\treturn 1.0\\n\\tdt = seq_of_zeros.dtype\\n\\ta = ones((1,), dtype=dt)\\n\\tfor k in range(len(seq_of_zeros)):\\n\\t\\ta = NX.convolve(a, array([1, -seq_of_zeros[k]], dtype=dt),\\n\\t\\t\\t\\t\\t\\tmode='full')\\n\\tif issubclass(a.dtype.type, NX.complexfloating):\\n\\t\\troots = NX.asarray(seq_of_zeros, complex)\\n\\t\\tpos_roots = sort_complex(NX.compress(roots.imag > 0, roots))\\n\\t\\tneg_roots = NX.conjugate(sort_complex(\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tNX.compress(roots.imag < 0, roots)))\\n\\t\\tif (len(pos_roots) == len(neg_roots) and\\n\\t\\t\\t\\tNX.alltrue(neg_roots == pos_roots)):\\n\\t\\t\\ta = a.real.copy()\\n\\treturn a",
         "def poly(seq_of_zeros):\\n\\tseq_of_zeros = atleast_1d(seq_of_zeros)\\n\\tsh = seq_of_zeros.shape\\n\\tif len(sh) == 2 and sh[0] == sh[1] and sh[0] != 0:\\n\\t\\tseq_of_zeros = eigvals(seq_of_zeros)\\n\\telif len(sh) == 1:\\n\\t\\tpass\\n\\telse:\\n\\t\\traise ValueError(\"input must be 1d or non-empty square 2d array.\")\\n\\tif len(seq_of_zeros) == 0:\\n\\t\\treturn 1.0\\n\\ta = [1]\\n\\tfor k in range(len(seq_of_zeros)):\\n\\t\\ta = NX.convolve(a, [1, -seq_of_zeros[k]], mode='full')\\n\\tif issubclass(a.dtype.type, NX.complexfloating):\\n\\t\\troots = NX.asarray(seq_of_zeros, complex)\\n\\t\\tpos_roots = sort_complex(NX.compress(roots.imag > 0, roots))\\n\\t\\tneg_roots = NX.conjugate(sort_complex(\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tNX.compress(roots.imag < 0, roots)))\\n\\t\\tif (len(pos_roots) == len(neg_roots) and\\n\\t\\t\\t\\tNX.alltrue(neg_roots == pos_roots)):\\n\\t\\t\\ta = a.real.copy()\\n\\treturn a",
         "def poly(seq_of_zeros)",
         null,
         "Alter the behavior of the poly function to introduce a Wrong Data Types or Conversion Used (WSUIT) fault. The function should fail due to removing data type conversion logic, potentially causing type mismatches and calculation errors.",
         "To simulate incorrect numeric calculations, introduce a bug into the poly function by omitting type conversions. The function should fail due to not properly handling data types, potentially leading to integer overflow or incorrect polynomial calculations.",
         "To simulate incorrect numeric calculations, introduce a bug into the poly function by omitting type conversions.",
         "numpy",
         "3.0.0",
         "['test_polynomial.py']",
         "https://github.com/Mri-nal/mrinal-numpy",
         "WSUIT"
        ],
        [
         "26",
         "BUG: fixed failure of np.ma.median for 1-D even arrays.\\n\\nFor such arrays, the sum of the two entries closest to the middle was\\nnot divided by 2.  Now fixed, with test cases adapted to ensure this\\nstays OK.",
         "security",
         null,
         "https://github.com/python/cpython/commit/44e086d2129c85410a5ea13c79f3ff507a6d6453",
         "44e086d2129c85410a5ea13c79f3ff507a6d6453",
         "PySecDB",
         "diff --git a/numpy/ma/extras.py b/numpy/ma/extras.py\\nindex dadf032e0..97fb647e9 100644\\n--- a/numpy/ma/extras.py\\n+++ b/numpy/ma/extras.py\\n@@ -723,11 +723,12 @@ def _median(a, axis=None, out=None, overwrite_input=False):\\n\\t if asorted.ndim == 1:\\n\\t\\t counts = count(asorted)\\n\\t\\t idx, odd = divmod(count(asorted), 2)\\n-\\t\\tmid = asorted[idx + odd - 1 : idx + 1]\\n+\\t\\tmid = asorted[idx + odd - 1:idx + 1]\\n\\t\\t if np.issubdtype(asorted.dtype, np.inexact) and asorted.size > 0:\\n\\t\\t\\t # avoid inf / x = masked\\n\\t\\t\\t s = mid.sum(out=out)\\n-\\t\\t\\tnp.true_divide(s, 2., casting='unsafe')\\n+\\t\\t\\tif not odd:\\n+\\t\\t\\t\\ts = np.true_divide(s, 2., casting='safe', out=out)\\n\\t\\t\\t s = np.lib.utils._median_nancheck(asorted, s, axis, out)\\n\\t\\t else:\\n\\t\\t\\t s = mid.mean(out=out)\\ndiff --git a/numpy/ma/tests/test_extras.py b/numpy/ma/tests/test_extras.py\\nindex faee4f599..f11180672 100644\\n--- a/numpy/ma/tests/test_extras.py\\n+++ b/numpy/ma/tests/test_extras.py\\n@@ -672,12 +672,16 @@ class TestMedian(TestCase):\\n\\t\\t x = np.arange(9)\\n\\t\\t assert_equal(np.ma.median(x), 4.)\\n\\t\\t assert_(type(np.ma.median(x)) is not MaskedArray)\\n-\\t\\tx = range(9)\\n-\\t\\tassert_equal(np.ma.median(x), 4.)\\n+\\t\\tx = range(8)\\n+\\t\\tassert_equal(np.ma.median(x), 3.5)\\n\\t\\t assert_(type(np.ma.median(x)) is not MaskedArray)\\n\\t\\t x = 5\\n\\t\\t assert_equal(np.ma.median(x), 5.)\\n\\t\\t assert_(type(np.ma.median(x)) is not MaskedArray)\\n+\\t\\t# Regression test for gh-8409: even number of entries.\\n+\\t\\tx = [5., 5.]\\n+\\t\\tassert_equal(np.ma.median(x), 5.)\\n+\\t\\tassert_(type(np.ma.median(x)) is not MaskedArray)\\n \\n\\t def test_docstring_examples(self):\\n\\t\\t \"test the examples given in the docstring of ma.median\"",
         "def _median(a, axis=None, out=None, overwrite_input=False):\\n\\tif np.issubdtype(a.dtype, np.inexact):\\n\\t\\tfill_value = np.inf\\n\\telse:\\n\\t\\tfill_value = None\\n\\tif overwrite_input:\\n\\t\\tif axis is None:\\n\\t\\t\\tasorted = a.ravel()\\n\\t\\t\\tasorted.sort(fill_value=fill_value)\\n\\t\\telse:\\n\\t\\t\\ta.sort(axis=axis, fill_value=fill_value)\\n\\t\\t\\tasorted = a\\n\\telse:\\n\\t\\tasorted = sort(a, axis=axis, fill_value=fill_value)\\n\\tif axis is None:\\n\\t\\taxis = 0\\n\\telif axis < 0:\\n\\t\\taxis += asorted.ndim\\n\\tif asorted.ndim == 1:\\n\\t\\tcounts = count(asorted)\\n\\t\\tidx, odd = divmod(count(asorted), 2)\\n\\t\\tmid = asorted[idx + odd - 1:idx + 1]\\n\\t\\tif np.issubdtype(asorted.dtype, np.inexact) and asorted.size > 0:\\n\\t\\t\\ts = mid.sum(out=out)\\n\\t\\t\\tif not odd:\\n\\t\\t\\t\\ts = np.true_divide(s, 2., casting='safe', out=out)\\n\\t\\t\\ts = np.lib.utils._median_nancheck(asorted, s, axis, out)\\n\\t\\telse:\\n\\t\\t\\ts = mid.mean(out=out)\\n\\t\\tif np.ma.is_masked(s) and not np.all(asorted.mask):\\n\\t\\t\\treturn np.ma.minimum_fill_value(asorted)\\n\\t\\treturn s\\n\\tcounts = count(asorted, axis=axis)\\n\\th = counts // 2\\n\\taxes_grid = [np.arange(x) for i, x in enumerate(asorted.shape)\\n\\t\\t\\t\\t if i != axis]\\n\\tind = np.meshgrid(*axes_grid, sparse=True, indexing='ij')\\n\\tind.insert(axis, h - 1)\\n\\tlow = asorted[tuple(ind)]\\n\\tind[axis] = np.minimum(h, asorted.shape[axis] - 1)\\n\\thigh = asorted[tuple(ind)]\\n\\todd = counts % 2 == 1\\n\\tnp.copyto(low, high, where=odd)\\n\\ttry:\\n\\t\\tnp.copyto(low.mask, high.mask, where=odd)\\n\\texcept:\\n\\t\\tpass\\n\\tif np.issubdtype(asorted.dtype, np.inexact):\\n\\t\\ts = np.ma.sum([low, high], axis=0, out=out)\\n\\t\\tnp.true_divide(s.data, 2., casting='unsafe', out=s.data)\\n\\t\\ts = np.lib.utils._median_nancheck(asorted, s, axis, out)\\n\\telse:\\n\\t\\ts = np.ma.mean([low, high], axis=0, out=out)\\n\\tif np.ma.is_masked(s):\\n\\t\\trep = (~np.all(asorted.mask, axis=axis)) & s.mask\\n\\t\\ts.data[rep] = np.ma.minimum_fill_value(asorted)\\n\\t\\ts.mask[rep] = False\\n\\treturn s",
         "def _median(a, axis=None, out=None, overwrite_input=False):\\n\\tif np.issubdtype(a.dtype, np.inexact):\\n\\t\\tfill_value = np.inf\\n\\telse:\\n\\t\\tfill_value = None\\n\\tif overwrite_input:\\n\\t\\tif axis is None:\\n\\t\\t\\tasorted = a.ravel()\\n\\t\\t\\tasorted.sort(fill_value=fill_value)\\n\\t\\telse:\\n\\t\\t\\ta.sort(axis=axis, fill_value=fill_value)\\n\\t\\t\\tasorted = a\\n\\telse:\\n\\t\\tasorted = sort(a, axis=axis, fill_value=fill_value)\\n\\tif axis is None:\\n\\t\\taxis = 0\\n\\telif axis < 0:\\n\\t\\taxis += asorted.ndim\\n\\tif asorted.ndim == 1:\\n\\t\\tcounts = count(asorted)\\n\\t\\tidx, odd = divmod(count(asorted), 2)\\n\\t\\tmid = asorted[idx + odd - 1 : idx + 1]\\n\\t\\tif np.issubdtype(asorted.dtype, np.inexact) and asorted.size > 0:\\n\\t\\t\\ts = mid.sum(out=out)\\n\\t\\t\\tnp.true_divide(s, 2., casting='unsafe')\\n\\t\\t\\ts = np.lib.utils._median_nancheck(asorted, s, axis, out)\\n\\t\\telse:\\n\\t\\t\\ts = mid.mean(out=out)\\n\\t\\tif np.ma.is_masked(s) and not np.all(asorted.mask):\\n\\t\\t\\treturn np.ma.minimum_fill_value(asorted)\\n\\t\\treturn s\\n\\tcounts = count(asorted, axis=axis)\\n\\th = counts // 2\\n\\taxes_grid = [np.arange(x) for i, x in enumerate(asorted.shape)\\n\\t\\t\\t\\t if i != axis]\\n\\tind = np.meshgrid(*axes_grid, sparse=True, indexing='ij')\\n\\tind.insert(axis, h - 1)\\n\\tlow = asorted[tuple(ind)]\\n\\tind[axis] = np.minimum(h, asorted.shape[axis] - 1)\\n\\thigh = asorted[tuple(ind)]\\n\\todd = counts % 2 == 1\\n\\tnp.copyto(low, high, where=odd)\\n\\ttry:\\n\\t\\tnp.copyto(low.mask, high.mask, where=odd)\\n\\texcept:\\n\\t\\tpass\\n\\tif np.issubdtype(asorted.dtype, np.inexact):\\n\\t\\ts = np.ma.sum([low, high], axis=0, out=out)\\n\\t\\tnp.true_divide(s.data, 2., casting='unsafe', out=s.data)\\n\\t\\ts = np.lib.utils._median_nancheck(asorted, s, axis, out)\\n\\telse:\\n\\t\\ts = np.ma.mean([low, high], axis=0, out=out)\\n\\tif np.ma.is_masked(s):\\n\\t\\trep = (~np.all(asorted.mask, axis=axis)) & s.mask\\n\\t\\ts.data[rep] = np.ma.minimum_fill_value(asorted)\\n\\t\\ts.mask[rep] = False\\n\\treturn s",
         "def _median(a, axis=None, out=None, overwrite_input=False)",
         null,
         "Alter the behavior of the _median method to introduce a Wrong Value Assignment to Variable (WVAV) fault. The function should fail due to incorrect parameters in the true_divide call, causing wrong results in the variable assignment.",
         "Introduce an error in the function _median to simulate wrong value assignment to variable (WVAV). The function should fail due to incorrect parameter usage in division operation, potentially causing wrong median values.",
         "Introduce an error in the function _median to simulate wrong value assignment to variable (WVAV).",
         "numpy",
         "3.6.0",
         "['test_extras.py']",
         "https://github.com/Mri-nal/mrinal-numpy",
         "WVAV"
        ],
        [
         "27",
         "Make some fixes in mirr implementation to avoid overflow in summing booleans. Do some whitespace cleanup.",
         "security",
         null,
         "https://github.com/python/cpython/commit/4176f33526beb6f1efd0efd1cbdd89ab103c72b6",
         "4176f33526beb6f1efd0efd1cbdd89ab103c72b6",
         "PySecDB",
         "diff --git a/numpy/lib/financial.py b/numpy/lib/financial.py\\nindex 496e960fc..5d1e65f5c 100644\\n--- a/numpy/lib/financial.py\\n+++ b/numpy/lib/financial.py\\n@@ -625,17 +625,17 @@ def mirr(values, finance_rate, reinvest_rate):\\n \\n\\t \"\"\"\\n \\n-\\tvalues = np.asarray(values)\\n+\\tvalues = np.asarray(values, dtype=np.double)\\n\\t initial = values[0]\\n\\t values = values[1:]\\n\\t n = values.size\\n\\t pos = values > 0\\n\\t neg = values < 0\\n-\\tif not (pos.sum() > 0 and neg.sum() > 0):\\n+\\tif not (pos.any() and neg.any()):\\n\\t\\t return np.nan\\n\\t numer = np.abs(npv(reinvest_rate, values*pos))\\n\\t denom = np.abs(npv(finance_rate, values*neg))\\n-\\tif initial > 0:\\t\\t\\n-\\t\\treturn ((initial + numer) / denom)**(1.0/n)*(1+reinvest_rate) - 1\\n+\\tif initial > 0:\\n+\\t\\treturn ((initial + numer) / denom)**(1.0/n)*(1 + reinvest_rate) - 1\\n\\t else:\\n-\\t\\treturn ((numer / (-initial + denom)))**(1.0/n)*(1+reinvest_rate) - 1\\n+\\t\\treturn ((numer / (-initial + denom)))**(1.0/n)*(1 + reinvest_rate) - 1\\ndiff --git a/numpy/lib/tests/test_financial.py b/numpy/lib/tests/test_financial.py\\nindex 0ad3766bf..3c9703621 100644\\n--- a/numpy/lib/tests/test_financial.py\\n+++ b/numpy/lib/tests/test_financial.py\\n@@ -43,7 +43,7 @@ class TestFinancial(TestCase):\\n\\t\\t v2 = [-120000,39000,30000,21000,37000,46000]\\n\\t\\t assert_almost_equal(np.mirr(v2,0.10,0.12),\\n\\t\\t\\t\\t\\t\\t\\t 0.1344, 4)\\n-\\t   \\n+\\n\\t\\t v3 = [100,200,-50,300,-200]\\n\\t\\t assert_almost_equal(np.mirr(v3,0.05,0.06), 0.3428, 4)",
         "def mirr(values, finance_rate, reinvest_rate):\\n\\tvalues = np.asarray(values, dtype=np.double)\\n\\tinitial = values[0]\\n\\tvalues = values[1:]\\n\\tn = values.size\\n\\tpos = values > 0\\n\\tneg = values < 0\\n\\tif not (pos.any() and neg.any()):\\n\\t\\treturn np.nan\\n\\tnumer = np.abs(npv(reinvest_rate, values*pos))\\n\\tdenom = np.abs(npv(finance_rate, values*neg))\\n\\tif initial > 0:\\n\\t\\treturn ((initial + numer) / denom)**(1.0/n)*(1 + reinvest_rate) - 1\\n\\telse:\\n\\t\\treturn ((numer / (-initial + denom)))**(1.0/n)*(1 + reinvest_rate) - 1",
         "def mirr(values, finance_rate, reinvest_rate):\\n\\tvalues = np.asarray(values)\\n\\tinitial = values[0]\\n\\tvalues = values[1:]\\n\\tn = values.size\\n\\tpos = values > 0\\n\\tneg = values < 0\\n\\tif not (pos.sum() > 0 and neg.sum() > 0):\\n\\t\\treturn np.nan\\n\\tnumer = np.abs(npv(reinvest_rate, values*pos))\\n\\tdenom = np.abs(npv(finance_rate, values*neg))\\n\\tif initial > 0:\\t\\t\\n\\t\\treturn ((initial + numer) / denom)**(1.0/n)*(1+reinvest_rate) - 1\\n\\telse:\\n\\t\\treturn ((numer / (-initial + denom)))**(1.0/n)*(1+reinvest_rate) - 1",
         "def mirr(values, finance_rate, reinvest_rate)",
         null,
         "Create a Wrong Data Types or Conversion Used (WSUIT) fault by altering the mirr function. The function should fail due to removing dtype=np.double in np.asarray conversion and using sum() instead of any(), potentially causing incorrect type handling and calculations.",
         "Trigger a wrong data types conversion fault within the mirr function. The function should fail due to improper array type conversion and boolean operations, potentially causing calculation errors.",
         "Trigger a wrong data types conversion fault within the mirr function.",
         "numpy",
         "3.9.0",
         "['test_financial.py']",
         "https://github.com/Mri-nal/mrinal-numpy",
         "WSUIT"
        ],
        [
         "28",
         "BUG: Cast size to int64 when loading from archive\\n\\nPrevents overflow errors for large arrays on systems\\nwhere the default int type is int32.",
         "security",
         null,
         "https://github.com/python/cpython/commit/da668fc74653e5caae9f741461c4d20f9df6e5c1",
         "da668fc74653e5caae9f741461c4d20f9df6e5c1",
         "PySecDB",
         "diff --git a/numpy/lib/format.py b/numpy/lib/format.py\\nindex a0f2c5497..cfe0e62ac 100644\\n--- a/numpy/lib/format.py\\n+++ b/numpy/lib/format.py\\n@@ -623,7 +623,7 @@ def read_array(fp, allow_pickle=True, pickle_kwargs=None):\\n\\t if len(shape) == 0:\\n\\t\\t count = 1\\n\\t else:\\n-\\t\\tcount = numpy.multiply.reduce(shape)\\n+\\t\\tcount = numpy.multiply.reduce(shape, dtype=numpy.int64)\\n \\n\\t # Now read the actual data.\\n\\t if dtype.hasobject:\\ndiff --git a/numpy/lib/tests/test_format.py b/numpy/lib/tests/test_format.py\\nindex a091ef5b3..46b21707f 100644\\n--- a/numpy/lib/tests/test_format.py\\n+++ b/numpy/lib/tests/test_format.py\\n@@ -836,5 +836,19 @@ def test_large_file_support():\\n\\t assert_array_equal(r, d)\\n \\n \\n+@dec.slow\\n+def test_large_archive():\\n+\\ta = np.empty((2 ** 30, 2), dtype=np.uint8)\\n+\\tfname = os.path.join(tempdir, \"large_archive\")\\n+\\n+\\twith open(fname, \"wb\") as f:\\n+\\t\\tnp.savez(f, arr=a)\\n+\\n+\\twith open(fname, \"rb\") as f:\\n+\\t\\tnew_a = np.load(f)[\"arr\"]\\n+\\n+\\tassert a.shape == new_a.shape\\n+\\n+\\n if __name__ == \"__main__\":\\n\\t run_module_suite()",
         "def read_array(fp, allow_pickle=True, pickle_kwargs=None):\\n\\tversion = read_magic(fp)\\n\\t_check_version(version)\\n\\tshape, fortran_order, dtype = _read_array_header(fp, version)\\n\\tif len(shape) == 0:\\n\\t\\tcount = 1\\n\\telse:\\n\\t\\tcount = numpy.multiply.reduce(shape, dtype=numpy.int64)\\n\\tif dtype.hasobject:\\n\\t\\tif not allow_pickle:\\n\\t\\t\\traise ValueError(\"Object arrays cannot be loaded when \"\\n\\t\\t\\t\\t\\t\\t\\t \"allow_pickle=False\")\\n\\t\\tif pickle_kwargs is None:\\n\\t\\t\\tpickle_kwargs = {}\\n\\t\\ttry:\\n\\t\\t\\tarray = pickle.load(fp, **pickle_kwargs)\\n\\t\\texcept UnicodeError as err:\\n\\t\\t\\tif sys.version_info[0] >= 3:\\n\\t\\t\\t\\traise UnicodeError(\"Unpickling a python object failed: %r\\n\"\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"You may need to pass the encoding= option \"\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"to numpy.load\" % (err,))\\n\\t\\t\\traise\\n\\telse:\\n\\t\\tif isfileobj(fp):\\n\\t\\t\\tarray = numpy.fromfile(fp, dtype=dtype, count=count)\\n\\t\\telse:\\n\\t\\t\\tmax_read_count = BUFFER_SIZE // min(BUFFER_SIZE, dtype.itemsize)\\n\\t\\t\\tarray = numpy.empty(count, dtype=dtype)\\n\\t\\t\\tfor i in range(0, count, max_read_count):\\n\\t\\t\\t\\tread_count = min(max_read_count, count - i)\\n\\t\\t\\t\\tread_size = int(read_count * dtype.itemsize)\\n\\t\\t\\t\\tdata = _read_bytes(fp, read_size, \"array data\")\\n\\t\\t\\t\\tarray[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t count=read_count)\\n\\t\\tif fortran_order:\\n\\t\\t\\tarray.shape = shape[::-1]\\n\\t\\t\\tarray = array.transpose()\\n\\t\\telse:\\n\\t\\t\\tarray.shape = shape\\n\\treturn array",
         "def read_array(fp, allow_pickle=True, pickle_kwargs=None):\\n\\tversion = read_magic(fp)\\n\\t_check_version(version)\\n\\tshape, fortran_order, dtype = _read_array_header(fp, version)\\n\\tif len(shape) == 0:\\n\\t\\tcount = 1\\n\\telse:\\n\\t\\tcount = numpy.multiply.reduce(shape)\\n\\tif dtype.hasobject:\\n\\t\\tif not allow_pickle:\\n\\t\\t\\traise ValueError(\"Object arrays cannot be loaded when \"\\n\\t\\t\\t\\t\\t\\t\\t \"allow_pickle=False\")\\n\\t\\tif pickle_kwargs is None:\\n\\t\\t\\tpickle_kwargs = {}\\n\\t\\ttry:\\n\\t\\t\\tarray = pickle.load(fp, **pickle_kwargs)\\n\\t\\texcept UnicodeError as err:\\n\\t\\t\\tif sys.version_info[0] >= 3:\\n\\t\\t\\t\\traise UnicodeError(\"Unpickling a python object failed: %r\\n\"\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"You may need to pass the encoding= option \"\\n\\t\\t\\t\\t\\t\\t\\t\\t   \"to numpy.load\" % (err,))\\n\\t\\t\\traise\\n\\telse:\\n\\t\\tif isfileobj(fp):\\n\\t\\t\\tarray = numpy.fromfile(fp, dtype=dtype, count=count)\\n\\t\\telse:\\n\\t\\t\\tmax_read_count = BUFFER_SIZE // min(BUFFER_SIZE, dtype.itemsize)\\n\\t\\t\\tarray = numpy.empty(count, dtype=dtype)\\n\\t\\t\\tfor i in range(0, count, max_read_count):\\n\\t\\t\\t\\tread_count = min(max_read_count, count - i)\\n\\t\\t\\t\\tread_size = int(read_count * dtype.itemsize)\\n\\t\\t\\t\\tdata = _read_bytes(fp, read_size, \"array data\")\\n\\t\\t\\t\\tarray[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t count=read_count)\\n\\t\\tif fortran_order:\\n\\t\\t\\tarray.shape = shape[::-1]\\n\\t\\t\\tarray = array.transpose()\\n\\t\\telse:\\n\\t\\t\\tarray.shape = shape\\n\\treturn array",
         "def read_array(fp, allow_pickle=True, pickle_kwargs=None)",
         null,
         "To simulate incorrect handling of large arrays, introduce a bug into the read_array function to simulate Wrong Data Types or Conversion Used (WSUIT). The function should fail due to removing the explicit dtype=numpy.int64 from numpy.multiply.reduce.",
         "Inject a bug in the read_array function to trigger a wrong data types or conversion used (WSUIT) fault. The function should fail due to using numpy.multiply.reduce with the default int32 dtype instead of int64, potentially causing integer overflow for large arrays.",
         "Inject a bug in the read_array function to trigger a wrong data types or conversion used (WSUIT) fault.",
         "numpy",
         "3.5.0",
         "['test_format.py']",
         "https://github.com/Mri-nal/mrinal-numpy",
         "WSUIT"
        ],
        [
         "29",
         "Fix SSTI vulnerability in ad and consent pages (#517)\\n\\n\\nFixed an issue where users could pass arbitrary Python code to be executed on the server to the mode HTTP arg",
         "security",
         null,
         "https://github.com/python/cpython/commit/47787e15cecd66f2aa87687bf852ae0194a4335f",
         "47787e15cecd66f2aa87687bf852ae0194a4335f",
         "MoreFixes",
         "diff --git a/psiturk/experiment.py b/psiturk/experiment.py\\nindex a6904f6..7ba1c1e 100644\\n--- a/psiturk/experiment.py\\n+++ b/psiturk/experiment.py\\n@@ -380,9 +380,10 @@ def advertisement():\\n\\t\\t # even have accepted the HIT.\\n\\t\\t with open('templates/ad.html', 'r') as temp_file:\\n\\t\\t\\t ad_string = temp_file.read()\\n-\\t\\tad_string = insert_mode(ad_string, mode)\\n+\\t\\tad_string = insert_mode(ad_string)\\n\\t\\t return render_template_string(\\n\\t\\t\\t ad_string,\\n+\\t\\t\\tmode=mode,\\n\\t\\t\\t hitid=hit_id,\\n\\t\\t\\t assignmentid=assignment_id,\\n\\t\\t\\t workerid=worker_id\\n@@ -406,9 +407,10 @@ def give_consent():\\n\\t mode = request.args['mode']\\n\\t with open('templates/consent.html', 'r') as temp_file:\\n\\t\\t consent_string = temp_file.read()\\n-\\tconsent_string = insert_mode(consent_string, mode)\\n+\\tconsent_string = insert_mode(consent_string)\\n\\t return render_template_string(\\n\\t\\t consent_string,\\n+\\t\\tmode=mode,\\n\\t\\t hitid=hit_id,\\n\\t\\t assignmentid=assignment_id,\\n\\t\\t workerid=worker_id\\n@@ -731,7 +733,7 @@ def ppid():\\n # to avoid breaking backwards compatibility with old templates.\\n \\n \\n-def insert_mode(page_html, mode):\\n+def insert_mode(page_html):\\n\\t \"\"\" Insert mode \"\"\"\\n\\t page_html = page_html\\n\\t match_found = False\\n@@ -740,7 +742,7 @@ def insert_mode(page_html, mode):\\n\\t for match in matches:\\n\\t\\t match_found = True\\n\\t if match_found:\\n-\\t\\tnew_html = page_html[:match.end()] + \"&mode=\" + mode +\\\\n+\\t\\tnew_html = page_html[:match.end()] + '&mode={{ mode }}' +\\\\n\\t\\t\\t page_html[match.end():]\\n\\t\\t return new_html\\n\\t else:\\ndiff --git a/tests/test_psiturk.py b/tests/test_psiturk.py\\nindex 497f0a5..5229962 100644\\n--- a/tests/test_psiturk.py\\n+++ b/tests/test_psiturk.py\\n@@ -141,7 +141,7 @@ def test_insert_mode(psiturk_test_client):\\n\\t\\t ad_string = temp_file.read()\\n \\n\\t from psiturk.experiment import insert_mode\\n-\\tinsert_mode(ad_string, 'debug')\\n+\\tinsert_mode(ad_string)\\n \\n \\n class PsiTurkStandardTests(PsiturkUnitTest):",
         "def insert_mode(page_html):\\n\\tpage_html = page_html\\n\\tmatch_found = False\\n\\tmatches = re.finditer('workerId={{ workerid }}', page_html)\\n\\tmatch = None\\n\\tfor match in matches:\\n\\t\\tmatch_found = True\\n\\tif match_found:\\n\\t\\tnew_html = page_html[:match.end()] + '&mode={{ mode }}' +\\\\n\\t\\t\\tpage_html[match.end():]\\n\\t\\treturn new_html\\n\\telse:\\n\\t\\traise ExperimentError(\"insert_mode_failed\")",
         "def insert_mode(page_html, mode):\\n\\tpage_html = page_html\\n\\tmatch_found = False\\n\\tmatches = re.finditer('workerId={{ workerid }}', page_html)\\n\\tmatch = None\\n\\tfor match in matches:\\n\\t\\tmatch_found = True\\n\\tif match_found:\\n\\t\\tnew_html = page_html[:match.end()] + \"&mode=\" + mode +\\\\n\\t\\t\\tpage_html[match.end():]\\n\\t\\treturn new_html\\n\\telse:\\n\\t\\traise ExperimentError(\"insert_mode_failed\")",
         "def insert_mode(page_html, mode)",
         null,
         "Alter the behavior of the insert_mode function to introduce a wrong value assigned to variable (WVAV) fault. The function should fail due to using string concatenation instead of template interpolation.",
         "To simulate incorrect string handling, introduce a bug into the insert_mode function to simulate wrong value assigned to variable (WVAV). The function should fail due to unsafe string concatenation.",
         "To simulate incorrect string handling, introduce a bug into the insert_mode function to simulate wrong value assigned to variable (WVAV).",
         "psiturk",
         "3.7.0",
         "['test_psiturk.py']",
         "https://github.com/NYUCCL/psiTurk",
         "WVAV"
        ],
        [
         "30",
         "Fix SSTI vulnerability in ad and consent pages (#517)\\n\\n\\nFixed an issue where users could pass arbitrary Python code to be executed on the server to the mode HTTP arg",
         "security",
         null,
         "https://github.com/python/cpython/commit/47787e15cecd66f2aa87687bf852ae0194a4335f",
         "47787e15cecd66f2aa87687bf852ae0194a4335f",
         "MoreFixes",
         "diff --git a/psiturk/experiment.py b/psiturk/experiment.py\\nindex a6904f6..7ba1c1e 100644\\n--- a/psiturk/experiment.py\\n+++ b/psiturk/experiment.py\\n@@ -380,9 +380,10 @@ def advertisement():\\n\\t\\t # even have accepted the HIT.\\n\\t\\t with open('templates/ad.html', 'r') as temp_file:\\n\\t\\t\\t ad_string = temp_file.read()\\n-\\t\\tad_string = insert_mode(ad_string, mode)\\n+\\t\\tad_string = insert_mode(ad_string)\\n\\t\\t return render_template_string(\\n\\t\\t\\t ad_string,\\n+\\t\\t\\tmode=mode,\\n\\t\\t\\t hitid=hit_id,\\n\\t\\t\\t assignmentid=assignment_id,\\n\\t\\t\\t workerid=worker_id\\n@@ -406,9 +407,10 @@ def give_consent():\\n\\t mode = request.args['mode']\\n\\t with open('templates/consent.html', 'r') as temp_file:\\n\\t\\t consent_string = temp_file.read()\\n-\\tconsent_string = insert_mode(consent_string, mode)\\n+\\tconsent_string = insert_mode(consent_string)\\n\\t return render_template_string(\\n\\t\\t consent_string,\\n+\\t\\tmode=mode,\\n\\t\\t hitid=hit_id,\\n\\t\\t assignmentid=assignment_id,\\n\\t\\t workerid=worker_id\\n@@ -731,7 +733,7 @@ def ppid():\\n # to avoid breaking backwards compatibility with old templates.\\n \\n \\n-def insert_mode(page_html, mode):\\n+def insert_mode(page_html):\\n\\t \"\"\" Insert mode \"\"\"\\n\\t page_html = page_html\\n\\t match_found = False\\n@@ -740,7 +742,7 @@ def insert_mode(page_html, mode):\\n\\t for match in matches:\\n\\t\\t match_found = True\\n\\t if match_found:\\n-\\t\\tnew_html = page_html[:match.end()] + \"&mode=\" + mode +\\\\n+\\t\\tnew_html = page_html[:match.end()] + '&mode={{ mode }}' +\\\\n\\t\\t\\t page_html[match.end():]\\n\\t\\t return new_html\\n\\t else:\\ndiff --git a/tests/test_psiturk.py b/tests/test_psiturk.py\\nindex 497f0a5..5229962 100644\\n--- a/tests/test_psiturk.py\\n+++ b/tests/test_psiturk.py\\n@@ -141,7 +141,7 @@ def test_insert_mode(psiturk_test_client):\\n\\t\\t ad_string = temp_file.read()\\n \\n\\t from psiturk.experiment import insert_mode\\n-\\tinsert_mode(ad_string, 'debug')\\n+\\tinsert_mode(ad_string)\\n \\n \\n class PsiTurkStandardTests(PsiturkUnitTest):",
         "def advertisement():\\n\\tuser_agent_string = request.user_agent.string\\n\\tuser_agent_obj = user_agents.parse(user_agent_string)\\n\\tbrowser_ok = True\\n\\tbrowser_exclude_rule = CONFIG.get('Task Parameters', 'browser_exclude_rule')\\n\\tfor rule in browser_exclude_rule.split(','):\\n\\t\\tmyrule = rule.strip()\\n\\t\\tif myrule in [\"mobile\", \"tablet\", \"touchcapable\", \"pc\", \"bot\"]:\\n\\t\\t\\tif (myrule == \"mobile\" and user_agent_obj.is_mobile) or\\\\n\\t\\t\\t   (myrule == \"tablet\" and user_agent_obj.is_tablet) or\\\\n\\t\\t\\t   (myrule == \"touchcapable\" and user_agent_obj.is_touch_capable) or\\\\n\\t\\t\\t   (myrule == \"pc\" and user_agent_obj.is_pc) or\\\\n\\t\\t\\t   (myrule == \"bot\" and user_agent_obj.is_bot):\\n\\t\\t\\t\\tbrowser_ok = False\\n\\t\\telif myrule == \"Safari\" or myrule == \"safari\":\\n\\t\\t\\tif \"Chrome\" in user_agent_string and \"Safari\" in user_agent_string:\\n\\t\\t\\t\\tpass\\n\\t\\t\\telif \"Safari\" in user_agent_string:\\n\\t\\t\\t\\tbrowser_ok = False\\n\\t\\telif myrule in user_agent_string:\\n\\t\\t\\tbrowser_ok = False\\n\\tif not browser_ok:\\n\\t\\traise ExperimentError('browser_type_not_allowed')\\n\\tif not ('hitId' in request.args and 'assignmentId' in request.args):\\n\\t\\traise ExperimentError('hit_assign_worker_id_not_set_in_mturk')\\n\\thit_id = request.args['hitId']\\n\\tassignment_id = request.args['assignmentId']\\n\\tmode = request.args['mode']\\n\\tif hit_id[:5] == \"debug\":\\n\\t\\tdebug_mode = True\\n\\telse:\\n\\t\\tdebug_mode = False\\n\\talready_in_db = False\\n\\tif 'workerId' in request.args:\\n\\t\\tworker_id = request.args['workerId']\\n\\t\\tnrecords = Participant.query.\\\\n\\t\\t\\tfilter(Participant.assignmentid != assignment_id).\\\\n\\t\\t\\tfilter(Participant.workerid == worker_id).\\\\n\\t\\t\\tcount()\\n\\t\\tif nrecords > 0:  \\n\\t\\t\\talready_in_db = True\\n\\telse:  \\n\\t\\tworker_id = None\\n\\ttry:\\n\\t\\tpart = Participant.query.\\\\n\\t\\t\\tfilter(Participant.hitid == hit_id).\\\\n\\t\\t\\tfilter(Participant.assignmentid == assignment_id).\\\\n\\t\\t\\tfilter(Participant.workerid == worker_id).\\\\n\\t\\t\\tone()\\n\\t\\tstatus = part.status\\n\\texcept exc.SQLAlchemyError:\\n\\t\\tstatus = None\\n\\tallow_repeats = CONFIG.getboolean('Task Parameters', 'allow_repeats')\\n\\tif (status == STARTED or status == QUITEARLY) and not debug_mode:\\n\\t\\traise ExperimentError('already_started_exp_mturk')\\n\\telif status == COMPLETED or (status == SUBMITTED and not already_in_db):\\n\\t\\treturn render_template(\\n\\t\\t\\t'thanks-mturksubmit.html',\\n\\t\\t\\tusing_sandbox=(mode == \"sandbox\"),\\n\\t\\t\\thitid=hit_id,\\n\\t\\t\\tassignmentid=assignment_id,\\n\\t\\t\\tworkerid=worker_id\\n\\t\\t)\\n\\telif already_in_db and not (debug_mode or allow_repeats):\\n\\t\\traise ExperimentError('already_did_exp_hit')\\n\\telif status == ALLOCATED or not status or debug_mode:\\n\\t\\twith open('templates/ad.html', 'r') as temp_file:\\n\\t\\t\\tad_string = temp_file.read()\\n\\t\\tad_string = insert_mode(ad_string)\\n\\t\\treturn render_template_string(\\n\\t\\t\\tad_string,\\n\\t\\t\\tmode=mode,\\n\\t\\t\\thitid=hit_id,\\n\\t\\t\\tassignmentid=assignment_id,\\n\\t\\t\\tworkerid=worker_id\\n\\t\\t)\\n\\telse:\\n\\t\\traise ExperimentError('status_incorrectly_set')",
         "def advertisement():\\n\\tuser_agent_string = request.user_agent.string\\n\\tuser_agent_obj = user_agents.parse(user_agent_string)\\n\\tbrowser_ok = True\\n\\tbrowser_exclude_rule = CONFIG.get('Task Parameters', 'browser_exclude_rule')\\n\\tfor rule in browser_exclude_rule.split(','):\\n\\t\\tmyrule = rule.strip()\\n\\t\\tif myrule in [\"mobile\", \"tablet\", \"touchcapable\", \"pc\", \"bot\"]:\\n\\t\\t\\tif (myrule == \"mobile\" and user_agent_obj.is_mobile) or\\\\n\\t\\t\\t   (myrule == \"tablet\" and user_agent_obj.is_tablet) or\\\\n\\t\\t\\t   (myrule == \"touchcapable\" and user_agent_obj.is_touch_capable) or\\\\n\\t\\t\\t   (myrule == \"pc\" and user_agent_obj.is_pc) or\\\\n\\t\\t\\t   (myrule == \"bot\" and user_agent_obj.is_bot):\\n\\t\\t\\t\\tbrowser_ok = False\\n\\t\\telif myrule == \"Safari\" or myrule == \"safari\":\\n\\t\\t\\tif \"Chrome\" in user_agent_string and \"Safari\" in user_agent_string:\\n\\t\\t\\t\\tpass\\n\\t\\t\\telif \"Safari\" in user_agent_string:\\n\\t\\t\\t\\tbrowser_ok = False\\n\\t\\telif myrule in user_agent_string:\\n\\t\\t\\tbrowser_ok = False\\n\\tif not browser_ok:\\n\\t\\traise ExperimentError('browser_type_not_allowed')\\n\\tif not ('hitId' in request.args and 'assignmentId' in request.args):\\n\\t\\traise ExperimentError('hit_assign_worker_id_not_set_in_mturk')\\n\\thit_id = request.args['hitId']\\n\\tassignment_id = request.args['assignmentId']\\n\\tmode = request.args['mode']\\n\\tif hit_id[:5] == \"debug\":\\n\\t\\tdebug_mode = True\\n\\telse:\\n\\t\\tdebug_mode = False\\n\\talready_in_db = False\\n\\tif 'workerId' in request.args:\\n\\t\\tworker_id = request.args['workerId']\\n\\t\\tnrecords = Participant.query.\\\\n\\t\\t\\tfilter(Participant.assignmentid != assignment_id).\\\\n\\t\\t\\tfilter(Participant.workerid == worker_id).\\\\n\\t\\t\\tcount()\\n\\t\\tif nrecords > 0:  \\n\\t\\t\\talready_in_db = True\\n\\telse:  \\n\\t\\tworker_id = None\\n\\ttry:\\n\\t\\tpart = Participant.query.\\\\n\\t\\t\\tfilter(Participant.hitid == hit_id).\\\\n\\t\\t\\tfilter(Participant.assignmentid == assignment_id).\\\\n\\t\\t\\tfilter(Participant.workerid == worker_id).\\\\n\\t\\t\\tone()\\n\\t\\tstatus = part.status\\n\\texcept exc.SQLAlchemyError:\\n\\t\\tstatus = None\\n\\tallow_repeats = CONFIG.getboolean('Task Parameters', 'allow_repeats')\\n\\tif (status == STARTED or status == QUITEARLY) and not debug_mode:\\n\\t\\traise ExperimentError('already_started_exp_mturk')\\n\\telif status == COMPLETED or (status == SUBMITTED and not already_in_db):\\n\\t\\treturn render_template(\\n\\t\\t\\t'thanks-mturksubmit.html',\\n\\t\\t\\tusing_sandbox=(mode == \"sandbox\"),\\n\\t\\t\\thitid=hit_id,\\n\\t\\t\\tassignmentid=assignment_id,\\n\\t\\t\\tworkerid=worker_id\\n\\t\\t)\\n\\telif already_in_db and not (debug_mode or allow_repeats):\\n\\t\\traise ExperimentError('already_did_exp_hit')\\n\\telif status == ALLOCATED or not status or debug_mode:\\n\\t\\twith open('templates/ad.html', 'r') as temp_file:\\n\\t\\t\\tad_string = temp_file.read()\\n\\t\\tad_string = insert_mode(ad_string, mode)\\n\\t\\treturn render_template_string(\\n\\t\\t\\tad_string,\\n\\t\\t\\thitid=hit_id,\\n\\t\\t\\tassignmentid=assignment_id,\\n\\t\\t\\tworkerid=worker_id\\n\\t\\t)\\n\\telse:\\n\\t\\traise ExperimentError('status_incorrectly_set')",
         "def advertisement()",
         null,
         "Inject a bug in the advertisement function to trigger a Wrong Function Called with Different Parameters (WFCD) fault. The function should fail due to changing insert_mode(ad_string) to insert_mode(ad_string, mode), causing incorrect template rendering.",
         "Modify the advertisement function to introduce a wrong function called with different parameters (WFCD) fault. The function should fail due to passing an extra parameter to insert_mode, potentially causing template rendering issues.",
         "Modify the advertisement function to introduce incorrect function parameter passing.",
         "psiturk",
         "3.9.0",
         "['test_psiturk.py']",
         "https://github.com/NYUCCL/psiTurk",
         "WFCD"
        ],
        [
         "31",
         "Fix SSTI vulnerability in ad and consent pages (#517)\\n\\n\\nFixed an issue where users could pass arbitrary Python code to be executed on the server to the mode HTTP arg",
         "security",
         null,
         "https://github.com/python/cpython/commit/47787e15cecd66f2aa87687bf852ae0194a4335f",
         "47787e15cecd66f2aa87687bf852ae0194a4335f",
         "MoreFixes",
         "diff --git a/psiturk/experiment.py b/psiturk/experiment.py\\nindex a6904f6..7ba1c1e 100644\\n--- a/psiturk/experiment.py\\n+++ b/psiturk/experiment.py\\n@@ -380,9 +380,10 @@ def advertisement():\\n\\t\\t # even have accepted the HIT.\\n\\t\\t with open('templates/ad.html', 'r') as temp_file:\\n\\t\\t\\t ad_string = temp_file.read()\\n-\\t\\tad_string = insert_mode(ad_string, mode)\\n+\\t\\tad_string = insert_mode(ad_string)\\n\\t\\t return render_template_string(\\n\\t\\t\\t ad_string,\\n+\\t\\t\\tmode=mode,\\n\\t\\t\\t hitid=hit_id,\\n\\t\\t\\t assignmentid=assignment_id,\\n\\t\\t\\t workerid=worker_id\\n@@ -406,9 +407,10 @@ def give_consent():\\n\\t mode = request.args['mode']\\n\\t with open('templates/consent.html', 'r') as temp_file:\\n\\t\\t consent_string = temp_file.read()\\n-\\tconsent_string = insert_mode(consent_string, mode)\\n+\\tconsent_string = insert_mode(consent_string)\\n\\t return render_template_string(\\n\\t\\t consent_string,\\n+\\t\\tmode=mode,\\n\\t\\t hitid=hit_id,\\n\\t\\t assignmentid=assignment_id,\\n\\t\\t workerid=worker_id\\n@@ -731,7 +733,7 @@ def ppid():\\n # to avoid breaking backwards compatibility with old templates.\\n \\n \\n-def insert_mode(page_html, mode):\\n+def insert_mode(page_html):\\n\\t \"\"\" Insert mode \"\"\"\\n\\t page_html = page_html\\n\\t match_found = False\\n@@ -740,7 +742,7 @@ def insert_mode(page_html, mode):\\n\\t for match in matches:\\n\\t\\t match_found = True\\n\\t if match_found:\\n-\\t\\tnew_html = page_html[:match.end()] + \"&mode=\" + mode +\\\\n+\\t\\tnew_html = page_html[:match.end()] + '&mode={{ mode }}' +\\\\n\\t\\t\\t page_html[match.end():]\\n\\t\\t return new_html\\n\\t else:\\ndiff --git a/tests/test_psiturk.py b/tests/test_psiturk.py\\nindex 497f0a5..5229962 100644\\n--- a/tests/test_psiturk.py\\n+++ b/tests/test_psiturk.py\\n@@ -141,7 +141,7 @@ def test_insert_mode(psiturk_test_client):\\n\\t\\t ad_string = temp_file.read()\\n \\n\\t from psiturk.experiment import insert_mode\\n-\\tinsert_mode(ad_string, 'debug')\\n+\\tinsert_mode(ad_string)\\n \\n \\n class PsiTurkStandardTests(PsiturkUnitTest):",
         "def give_consent():\\n\\tif not ('hitId' in request.args and 'assignmentId' in request.args and\\n\\t\\t\\t'workerId' in request.args):\\n\\t\\traise ExperimentError('hit_assign_worker_id_not_set_in_consent')\\n\\thit_id = request.args['hitId']\\n\\tassignment_id = request.args['assignmentId']\\n\\tworker_id = request.args['workerId']\\n\\tmode = request.args['mode']\\n\\twith open('templates/consent.html', 'r') as temp_file:\\n\\t\\tconsent_string = temp_file.read()\\n\\tconsent_string = insert_mode(consent_string)\\n\\treturn render_template_string(\\n\\t\\tconsent_string,\\n\\t\\tmode=mode,\\n\\t\\thitid=hit_id,\\n\\t\\tassignmentid=assignment_id,\\n\\t\\tworkerid=worker_id\\n\\t)",
         "def give_consent():\\n\\tif not ('hitId' in request.args and 'assignmentId' in request.args and\\n\\t\\t\\t'workerId' in request.args):\\n\\t\\traise ExperimentError('hit_assign_worker_id_not_set_in_consent')\\n\\thit_id = request.args['hitId']\\n\\tassignment_id = request.args['assignmentId']\\n\\tworker_id = request.args['workerId']\\n\\tmode = request.args['mode']\\n\\twith open('templates/consent.html', 'r') as temp_file:\\n\\t\\tconsent_string = temp_file.read()\\n\\tconsent_string = insert_mode(consent_string, mode)\\n\\treturn render_template_string(\\n\\t\\tconsent_string,\\n\\t\\thitid=hit_id,\\n\\t\\tassignmentid=assignment_id,\\n\\t\\tworkerid=worker_id\\n\\t)",
         "def give_consent()",
         null,
         "Alter the behavior of the give_consent function to introduce a Wrong Function Called with Different Parameters (WFCD) fault. The function should fail due to calling insert_mode() with an extra mode parameter instead of using it in render_template_string().",
         "Modify the give_consent function to introduce a wrong function called with different parameters (WFCD) fault. Change the function to call template functions with incorrect parameters, potentially causing template rendering issues.",
         "Modify the give_consent function to introduce incorrect function calls with wrong parameters.",
         "psiturk",
         "3.9.0",
         "['test_psiturk.py']",
         "https://github.com/NYUCCL/psiTurk",
         "WFCD"
        ],
        [
         "32",
         "warn when the server stops listening for connections because its in overflow",
         "security",
         null,
         "https://github.com/python/cpython/commit/866ceac9d51e2a9f3434cce55aa478fd455e07f1",
         "866ceac9d51e2a9f3434cce55aa478fd455e07f1",
         "PySecDB",
         "diff --git a/src/waitress/server.py b/src/waitress/server.py\\nindex b053c69..639b9de 100644\\n--- a/src/waitress/server.py\\n+++ b/src/waitress/server.py\\n@@ -179,6 +179,7 @@ class BaseWSGIServer(wasyncore.dispatcher):\\n\\t next_channel_cleanup = 0\\n\\t socketmod = socket  # test shim\\n\\t asyncore = wasyncore  # test shim\\n+\\tin_connection_overflow = False\\n \\n\\t def __init__(\\n\\t\\t self,\\n@@ -296,7 +297,26 @@ class BaseWSGIServer(wasyncore.dispatcher):\\n\\t\\t if now >= self.next_channel_cleanup:\\n\\t\\t\\t self.next_channel_cleanup = now + self.adj.cleanup_interval\\n\\t\\t\\t self.maintenance(now)\\n-\\t\\treturn self.accepting and len(self._map) < self.adj.connection_limit\\n+\\n+\\t\\tif (\\n+\\t\\t\\tnot self.in_connection_overflow\\n+\\t\\t\\tand len(self._map) >= self.adj.connection_limit\\n+\\t\\t):\\n+\\t\\t\\tself.in_connection_overflow = True\\n+\\t\\t\\tself.logger.warning(\\n+\\t\\t\\t\\t'server active connections reached the connection limit, '\\n+\\t\\t\\t\\t'no longer accepting new connections'\\n+\\t\\t\\t)\\n+\\t\\telif (\\n+\\t\\t\\tself.in_connection_overflow\\n+\\t\\t\\tand len(self._map) < self.adj.connection_limit\\n+\\t\\t):\\n+\\t\\t\\tself.in_connection_overflow = False\\n+\\t\\t\\tself.logger.info(\\n+\\t\\t\\t\\t'server active connections dropped below the connection limit, '\\n+\\t\\t\\t\\t'listening again'\\n+\\t\\t\\t)\\n+\\t\\treturn self.accepting and not self.in_connection_overflow\\n \\n\\t def writable(self):\\n\\t\\t return False\\ndiff --git a/tests/test_server.py b/tests/test_server.py\\nindex 05f6b4e..508b382 100644\\n--- a/tests/test_server.py\\n+++ b/tests/test_server.py\\n@@ -185,6 +185,7 @@ class TestWSGIServer(unittest.TestCase):\\n\\t\\t inst.adj = DummyAdj\\n\\t\\t inst._map = {\"a\": 1, \"b\": 2}\\n\\t\\t self.assertFalse(inst.readable())\\n+\\t\\tself.assertTrue(inst.in_connection_overflow)\\n \\n\\t def test_readable_maplen_lt_connection_limit(self):\\n\\t\\t inst = self._makeOneWithMap()\\n@@ -192,6 +193,19 @@ class TestWSGIServer(unittest.TestCase):\\n\\t\\t inst.adj = DummyAdj\\n\\t\\t inst._map = {}\\n\\t\\t self.assertTrue(inst.readable())\\n+\\t\\tself.assertFalse(inst.in_connection_overflow)\\n+\\n+\\tdef test_readable_maplen_toggles_connection_overflow(self):\\n+\\t\\tinst = self._makeOneWithMap()\\n+\\t\\tinst.accepting = True\\n+\\t\\tinst.adj = DummyAdj\\n+\\t\\tinst._map = {\"a\": 1, \"b\": 2}\\n+\\t\\tself.assertFalse(inst.in_connection_overflow)\\n+\\t\\tself.assertFalse(inst.readable())\\n+\\t\\tself.assertTrue(inst.in_connection_overflow)\\n+\\t\\tinst._map = {}\\n+\\t\\tself.assertTrue(inst.readable())\\n+\\t\\tself.assertFalse(inst.in_connection_overflow)\\n \\n\\t def test_readable_maintenance_false(self):\\n\\t\\t import time",
         "def readable(self):\\n\\t\\tnow = time.time()\\n\\t\\tif now >= self.next_channel_cleanup:\\n\\t\\t\\tself.next_channel_cleanup = now + self.adj.cleanup_interval\\n\\t\\t\\tself.maintenance(now)\\n\\t\\tif (\\n\\t\\t\\tnot self.in_connection_overflow\\n\\t\\t\\tand len(self._map) >= self.adj.connection_limit\\n\\t\\t):\\n\\t\\t\\tself.in_connection_overflow = True\\n\\t\\t\\tself.logger.warning(\\n\\t\\t\\t\\t'server active connections reached the connection limit, '\\n\\t\\t\\t\\t'no longer accepting new connections'\\n\\t\\t\\t)\\n\\t\\telif (\\n\\t\\t\\tself.in_connection_overflow\\n\\t\\t\\tand len(self._map) < self.adj.connection_limit\\n\\t\\t):\\n\\t\\t\\tself.in_connection_overflow = False\\n\\t\\t\\tself.logger.info(\\n\\t\\t\\t\\t'server active connections dropped below the connection limit, '\\n\\t\\t\\t\\t'listening again'\\n\\t\\t\\t)\\n\\t\\treturn self.accepting and not self.in_connection_overflow",
         "def readable(self):\\n\\t\\tnow = time.time()\\n\\t\\tif now >= self.next_channel_cleanup:\\n\\t\\t\\tself.next_channel_cleanup = now + self.adj.cleanup_interval\\n\\t\\t\\tself.maintenance(now)\\n\\t\\treturn self.accepting and len(self._map) < self.adj.connection_limit",
         "def readable(self)",
         null,
         "Modify the readable method to introduce a Missing Large Part of the Algorithm (MLPL) fault. The function should fail due to removing the connection overflow handling logic, causing the method to incorrectly handle connection limits.",
         "Introduce an error in the function readable to simulate missing large part of the algorithm (MLPL). The function should fail due to not implementing the connection overflow monitoring and logging functionality.",
         "Introduce an error in the function readable to simulate missing large part of the algorithm (MLPL).",
         "waitress",
         "3.5.0",
         "['test_server.py']",
         "https://github.com/Pylons/waitress",
         "MLPL"
        ],
        [
         "33",
         "Upon receiving invalid Content-Length bail\\n\\nInstead of attempting to continue processing the request, we instead\\nraise a ParsingError and return a HTTP Bad Request to the client.\\n\\nThis also catches the case where two Content-Length's are sent, and are\\nfolded together using HTTP header folding.",
         "security",
         "CVE-2019-16786",
         "https://github.com/python/cpython/commit/575994cd42e83fd772a5f7ec98b2c56751bd3f65",
         "575994cd42e83fd772a5f7ec98b2c56751bd3f65",
         "PySecDB",
         "diff --git a/waitress/parser.py b/waitress/parser.py\\nindex e2970cb..c537964 100644\\n--- a/waitress/parser.py\\n+++ b/waitress/parser.py\\n@@ -254,7 +254,8 @@ class HTTPRequestParser(object):\\n\\t\\t\\t try:\\n\\t\\t\\t\\t cl = int(headers.get(\"CONTENT_LENGTH\", 0))\\n\\t\\t\\t except ValueError:\\n-\\t\\t\\t\\tcl = 0\\n+\\t\\t\\t\\traise ParsingError(\"Content-Length is invalid\")\\n+\\n\\t\\t\\t self.content_length = cl\\n\\t\\t\\t if cl > 0:\\n\\t\\t\\t\\t buf = OverflowableBuffer(self.adj.inbuf_overflow)\\ndiff --git a/waitress/tests/test_parser.py b/waitress/tests/test_parser.py\\nindex 463e0b2..aa01d9d 100644\\n--- a/waitress/tests/test_parser.py\\n+++ b/waitress/tests/test_parser.py\\n@@ -167,9 +167,28 @@ class TestHTTPRequestParser(unittest.TestCase):\\n\\t\\t\\t self.assertTrue(False)\\n \\n\\t def test_parse_header_bad_content_length(self):\\n+\\t\\tfrom waitress.parser import ParsingError\\n+\\n\\t\\t data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: abc\\r\\n\"\\n-\\t\\tself.parser.parse_header(data)\\n-\\t\\tself.assertEqual(self.parser.body_rcv, None)\\n+\\n+\\t\\ttry:\\n+\\t\\t\\tself.parser.parse_header(data)\\n+\\t\\texcept ParsingError as e:\\n+\\t\\t\\tself.assertIn(\"Content-Length is invalid\", e.args[0])\\n+\\t\\telse:  # pragma: nocover\\n+\\t\\t\\tself.assertTrue(False)\\n+\\n+\\tdef test_parse_header_multiple_content_length(self):\\n+\\t\\tfrom waitress.parser import ParsingError\\n+\\n+\\t\\tdata = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: 10\\r\\ncontent-length: 20\\r\\n\"\\n+\\n+\\t\\ttry:\\n+\\t\\t\\tself.parser.parse_header(data)\\n+\\t\\texcept ParsingError as e:\\n+\\t\\t\\tself.assertIn(\"Content-Length is invalid\", e.args[0])\\n+\\t\\telse:  # pragma: nocover\\n+\\t\\t\\tself.assertTrue(False)\\n \\n\\t def test_parse_header_11_te_chunked(self):\\n\\t\\t # NB: test that capitalization of header value is unimportant",
         "def parse_header(self, header_plus):\\n\\t\\tindex = header_plus.find(b\"\\r\\n\")\\n\\t\\tif index >= 0:\\n\\t\\t\\tfirst_line = header_plus[:index].rstrip()\\n\\t\\t\\theader = header_plus[index + 2 :]\\n\\t\\telse:\\n\\t\\t\\traise ParsingError(\"HTTP message header invalid\")\\n\\t\\tif b\"\\r\" in first_line or b\"\\n\" in first_line:\\n\\t\\t\\traise ParsingError(\"Bare CR or LF found in HTTP message\")\\n\\t\\tself.first_line = first_line  \\n\\t\\tlines = get_header_lines(header)\\n\\t\\theaders = self.headers\\n\\t\\tfor line in lines:\\n\\t\\t\\tindex = line.find(b\":\")\\n\\t\\t\\tif index > 0:\\n\\t\\t\\t\\tkey = line[:index]\\n\\t\\t\\t\\tif key != key.strip():\\n\\t\\t\\t\\t\\traise ParsingError(\"Invalid whitespace after field-name\")\\n\\t\\t\\t\\tif b\"_\" in key:\\n\\t\\t\\t\\t\\tcontinue\\n\\t\\t\\t\\tvalue = line[index + 1 :].strip()\\n\\t\\t\\t\\tkey1 = tostr(key.upper().replace(b\"-\", b\"_\"))\\n\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\theaders[key1] += tostr(b\", \" + value)\\n\\t\\t\\t\\texcept KeyError:\\n\\t\\t\\t\\t\\theaders[key1] = tostr(value)\\n\\t\\tcommand, uri, version = crack_first_line(first_line)\\n\\t\\tversion = tostr(version)\\n\\t\\tcommand = tostr(command)\\n\\t\\tself.command = command\\n\\t\\tself.version = version\\n\\t\\t(\\n\\t\\t\\tself.proxy_scheme,\\n\\t\\t\\tself.proxy_netloc,\\n\\t\\t\\tself.path,\\n\\t\\t\\tself.query,\\n\\t\\t\\tself.fragment,\\n\\t\\t) = split_uri(uri)\\n\\t\\tself.url_scheme = self.adj.url_scheme\\n\\t\\tconnection = headers.get(\"CONNECTION\", \"\")\\n\\t\\tif version == \"1.0\":\\n\\t\\t\\tif connection.lower() != \"keep-alive\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif version == \"1.1\":\\n\\t\\t\\tte = headers.pop(\"TRANSFER_ENCODING\", \"\")\\n\\t\\t\\tif te.lower() == \"chunked\":\\n\\t\\t\\t\\tself.chunked = True\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = ChunkedReceiver(buf)\\n\\t\\t\\texpect = headers.get(\"EXPECT\", \"\").lower()\\n\\t\\t\\tself.expect_continue = expect == \"100-continue\"\\n\\t\\t\\tif connection.lower() == \"close\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif not self.chunked:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tcl = int(headers.get(\"CONTENT_LENGTH\", 0))\\n\\t\\t\\texcept ValueError:\\n\\t\\t\\t\\traise ParsingError(\"Content-Length is invalid\")\\n\\t\\t\\tself.content_length = cl\\n\\t\\t\\tif cl > 0:\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = FixedStreamReceiver(cl, buf)",
         "def parse_header(self, header_plus):\\n\\t\\tindex = header_plus.find(b\"\\r\\n\")\\n\\t\\tif index >= 0:\\n\\t\\t\\tfirst_line = header_plus[:index].rstrip()\\n\\t\\t\\theader = header_plus[index + 2 :]\\n\\t\\telse:\\n\\t\\t\\traise ParsingError(\"HTTP message header invalid\")\\n\\t\\tif b\"\\r\" in first_line or b\"\\n\" in first_line:\\n\\t\\t\\traise ParsingError(\"Bare CR or LF found in HTTP message\")\\n\\t\\tself.first_line = first_line  \\n\\t\\tlines = get_header_lines(header)\\n\\t\\theaders = self.headers\\n\\t\\tfor line in lines:\\n\\t\\t\\tindex = line.find(b\":\")\\n\\t\\t\\tif index > 0:\\n\\t\\t\\t\\tkey = line[:index]\\n\\t\\t\\t\\tif key != key.strip():\\n\\t\\t\\t\\t\\traise ParsingError(\"Invalid whitespace after field-name\")\\n\\t\\t\\t\\tif b\"_\" in key:\\n\\t\\t\\t\\t\\tcontinue\\n\\t\\t\\t\\tvalue = line[index + 1 :].strip()\\n\\t\\t\\t\\tkey1 = tostr(key.upper().replace(b\"-\", b\"_\"))\\n\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\theaders[key1] += tostr(b\", \" + value)\\n\\t\\t\\t\\texcept KeyError:\\n\\t\\t\\t\\t\\theaders[key1] = tostr(value)\\n\\t\\tcommand, uri, version = crack_first_line(first_line)\\n\\t\\tversion = tostr(version)\\n\\t\\tcommand = tostr(command)\\n\\t\\tself.command = command\\n\\t\\tself.version = version\\n\\t\\t(\\n\\t\\t\\tself.proxy_scheme,\\n\\t\\t\\tself.proxy_netloc,\\n\\t\\t\\tself.path,\\n\\t\\t\\tself.query,\\n\\t\\t\\tself.fragment,\\n\\t\\t) = split_uri(uri)\\n\\t\\tself.url_scheme = self.adj.url_scheme\\n\\t\\tconnection = headers.get(\"CONNECTION\", \"\")\\n\\t\\tif version == \"1.0\":\\n\\t\\t\\tif connection.lower() != \"keep-alive\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif version == \"1.1\":\\n\\t\\t\\tte = headers.pop(\"TRANSFER_ENCODING\", \"\")\\n\\t\\t\\tif te.lower() == \"chunked\":\\n\\t\\t\\t\\tself.chunked = True\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = ChunkedReceiver(buf)\\n\\t\\t\\texpect = headers.get(\"EXPECT\", \"\").lower()\\n\\t\\t\\tself.expect_continue = expect == \"100-continue\"\\n\\t\\t\\tif connection.lower() == \"close\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif not self.chunked:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tcl = int(headers.get(\"CONTENT_LENGTH\", 0))\\n\\t\\t\\texcept ValueError:\\n\\t\\t\\t\\tcl = 0\\n\\t\\t\\tself.content_length = cl\\n\\t\\t\\tif cl > 0:\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = FixedStreamReceiver(cl, buf)",
         "def parse_header(self, header_plus)",
         null,
         "Alter the behavior of the parse_header function to introduce a Wrong Algorithm Logic Relocation (WALR) fault. The function should fail due to relocating error handling logic by setting cl = 0 instead of raising ParsingError when the Content-Length header is invalid.",
         "Introduce an error in the parse_header function to simulate wrong algorithm logic relocation (WALR). The function should fail due to misplaced error handling logic that silently uses 0 as content length instead of raising an error.",
         "Introduce an error in the parse_header function to simulate wrong algorithm logic relocation (WALR).",
         "waitress",
         "3.7.0",
         "['test_parser.py']",
         "https://github.com/Pylons/waitress",
         "WALR"
        ],
        [
         "34",
         "Be more strict in parsing Content-Length\\n\\nValidate that we are only parsing digits and nothing else. RFC7230 is\\nexplicit in that the Content-Length can only exist of 1*DIGIT and may\\nnot include any additional sign information.\\n\\nThe Python int() function parses `+10` as `10` which means we were more\\nlenient than the standard intended.",
         "security",
         "CVE-2022-24761",
         "https://github.com/python/cpython/commit/1f6059f4c4a3a0b256b4027eda64fb9fc311b0a6",
         "1f6059f4c4a3a0b256b4027eda64fb9fc311b0a6",
         "PySecDB",
         "diff --git a/src/waitress/parser.py b/src/waitress/parser.py\\nindex a6e4d98..ff16a40 100644\\n--- a/src/waitress/parser.py\\n+++ b/src/waitress/parser.py\\n@@ -23,6 +23,7 @@ from urllib.parse import unquote_to_bytes\\n \\n from waitress.buffers import OverflowableBuffer\\n from waitress.receiver import ChunkedReceiver, FixedStreamReceiver\\n+from waitress.rfc7230 import HEADER_FIELD_RE, ONLY_DIGIT_RE\\n from waitress.utilities import (\\n\\t BadRequest,\\n\\t RequestEntityTooLarge,\\n@@ -31,8 +32,6 @@ from waitress.utilities import (\\n\\t find_double_newline,\\n )\\n \\n-from .rfc7230 import HEADER_FIELD\\n-\\n \\n def unquote_bytes_to_wsgi(bytestring):\\n\\t return unquote_to_bytes(bytestring).decode(\"latin-1\")\\n@@ -221,7 +220,7 @@ class HTTPRequestParser:\\n\\t\\t headers = self.headers\\n \\n\\t\\t for line in lines:\\n-\\t\\t\\theader = HEADER_FIELD.match(line)\\n+\\t\\t\\theader = HEADER_FIELD_RE.match(line)\\n \\n\\t\\t\\t if not header:\\n\\t\\t\\t\\t raise ParsingError(\"Invalid header\")\\n@@ -317,11 +316,12 @@ class HTTPRequestParser:\\n\\t\\t\\t\\t self.connection_close = True\\n \\n\\t\\t if not self.chunked:\\n-\\t\\t\\ttry:\\n-\\t\\t\\t\\tcl = int(headers.get(\"CONTENT_LENGTH\", 0))\\n-\\t\\t\\texcept ValueError:\\n+\\t\\t\\tcl = headers.get(\"CONTENT_LENGTH\", \"0\")\\n+\\n+\\t\\t\\tif not ONLY_DIGIT_RE.match(cl.encode(\"latin-1\")):\\n\\t\\t\\t\\t raise ParsingError(\"Content-Length is invalid\")\\n \\n+\\t\\t\\tcl = int(cl)\\n\\t\\t\\t self.content_length = cl\\n \\n\\t\\t\\t if cl > 0:\\ndiff --git a/tests/test_parser.py b/tests/test_parser.py\\nindex aacef26..868c122 100644\\n--- a/tests/test_parser.py\\n+++ b/tests/test_parser.py\\n@@ -193,6 +193,26 @@ class TestHTTPRequestParser(unittest.TestCase):\\n\\t\\t else:  # pragma: nocover\\n\\t\\t\\t self.assertTrue(False)\\n \\n+\\tdef test_parse_header_bad_content_length_plus(self):\\n+\\t\\tdata = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: +10\\r\\n\"\\n+\\n+\\t\\ttry:\\n+\\t\\t\\tself.parser.parse_header(data)\\n+\\t\\texcept ParsingError as e:\\n+\\t\\t\\tself.assertIn(\"Content-Length is invalid\", e.args[0])\\n+\\t\\telse:  # pragma: nocover\\n+\\t\\t\\tself.assertTrue(False)\\n+\\n+\\tdef test_parse_header_bad_content_length_minus(self):\\n+\\t\\tdata = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: -10\\r\\n\"\\n+\\n+\\t\\ttry:\\n+\\t\\t\\tself.parser.parse_header(data)\\n+\\t\\texcept ParsingError as e:\\n+\\t\\t\\tself.assertIn(\"Content-Length is invalid\", e.args[0])\\n+\\t\\telse:  # pragma: nocover\\n+\\t\\t\\tself.assertTrue(False)\\n+\\n\\t def test_parse_header_multiple_content_length(self):\\n\\t\\t data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: 10\\r\\ncontent-length: 20\\r\\n\"",
         "def parse_header(self, header_plus):\\n\\t\\tindex = header_plus.find(b\"\\r\\n\")\\n\\t\\tif index >= 0:\\n\\t\\t\\tfirst_line = header_plus[:index].rstrip()\\n\\t\\t\\theader = header_plus[index + 2 :]\\n\\t\\telse:\\n\\t\\t\\traise ParsingError(\"HTTP message header invalid\")\\n\\t\\tif b\"\\r\" in first_line or b\"\\n\" in first_line:\\n\\t\\t\\traise ParsingError(\"Bare CR or LF found in HTTP message\")\\n\\t\\tself.first_line = first_line  \\n\\t\\tlines = get_header_lines(header)\\n\\t\\theaders = self.headers\\n\\t\\tfor line in lines:\\n\\t\\t\\theader = HEADER_FIELD_RE.match(line)\\n\\t\\t\\tif not header:\\n\\t\\t\\t\\traise ParsingError(\"Invalid header\")\\n\\t\\t\\tkey, value = header.group(\"name\", \"value\")\\n\\t\\t\\tif b\"_\" in key:\\n\\t\\t\\t\\tcontinue\\n\\t\\t\\tvalue = value.strip(b\" \\t\")\\n\\t\\t\\tkey1 = key.upper().replace(b\"-\", b\"_\").decode(\"latin-1\")\\n\\t\\t\\ttry:\\n\\t\\t\\t\\theaders[key1] += (b\", \" + value).decode(\"latin-1\")\\n\\t\\t\\texcept KeyError:\\n\\t\\t\\t\\theaders[key1] = value.decode(\"latin-1\")\\n\\t\\tcommand, uri, version = crack_first_line(first_line)\\n\\t\\tself.request_uri = uri.decode(\"latin-1\")\\n\\t\\tversion = version.decode(\"latin-1\")\\n\\t\\tcommand = command.decode(\"latin-1\")\\n\\t\\tself.command = command\\n\\t\\tself.version = version\\n\\t\\t(\\n\\t\\t\\tself.proxy_scheme,\\n\\t\\t\\tself.proxy_netloc,\\n\\t\\t\\tself.path,\\n\\t\\t\\tself.query,\\n\\t\\t\\tself.fragment,\\n\\t\\t) = split_uri(uri)\\n\\t\\tself.url_scheme = self.adj.url_scheme\\n\\t\\tconnection = headers.get(\"CONNECTION\", \"\")\\n\\t\\tif version == \"1.0\":\\n\\t\\t\\tif connection.lower() != \"keep-alive\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif version == \"1.1\":\\n\\t\\t\\tte = headers.pop(\"TRANSFER_ENCODING\", \"\")\\n\\t\\t\\tencodings = [\\n\\t\\t\\t\\tencoding.strip(\" \\t\").lower() for encoding in te.split(\",\") if encoding\\n\\t\\t\\t]\\n\\t\\t\\tfor encoding in encodings:\\n\\t\\t\\t\\tif encoding not in {\"chunked\"}:\\n\\t\\t\\t\\t\\traise TransferEncodingNotImplemented(\\n\\t\\t\\t\\t\\t\\t\"Transfer-Encoding requested is not supported.\"\\n\\t\\t\\t\\t\\t)\\n\\t\\t\\tif encodings and encodings[-1] == \"chunked\":\\n\\t\\t\\t\\tself.chunked = True\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = ChunkedReceiver(buf)\\n\\t\\t\\telif encodings:  \\n\\t\\t\\t\\traise TransferEncodingNotImplemented(\\n\\t\\t\\t\\t\\t\"Transfer-Encoding requested is not supported.\"\\n\\t\\t\\t\\t)\\n\\t\\t\\texpect = headers.get(\"EXPECT\", \"\").lower()\\n\\t\\t\\tself.expect_continue = expect == \"100-continue\"\\n\\t\\t\\tif connection.lower() == \"close\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif not self.chunked:\\n\\t\\t\\tcl = headers.get(\"CONTENT_LENGTH\", \"0\")\\n\\t\\t\\tif not ONLY_DIGIT_RE.match(cl.encode(\"latin-1\")):\\n\\t\\t\\t\\traise ParsingError(\"Content-Length is invalid\")\\n\\t\\t\\tcl = int(cl)\\n\\t\\t\\tself.content_length = cl\\n\\t\\t\\tif cl > 0:\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = FixedStreamReceiver(cl, buf)",
         "def parse_header(self, header_plus):\\n\\t\\tindex = header_plus.find(b\"\\r\\n\")\\n\\t\\tif index >= 0:\\n\\t\\t\\tfirst_line = header_plus[:index].rstrip()\\n\\t\\t\\theader = header_plus[index + 2 :]\\n\\t\\telse:\\n\\t\\t\\traise ParsingError(\"HTTP message header invalid\")\\n\\t\\tif b\"\\r\" in first_line or b\"\\n\" in first_line:\\n\\t\\t\\traise ParsingError(\"Bare CR or LF found in HTTP message\")\\n\\t\\tself.first_line = first_line  \\n\\t\\tlines = get_header_lines(header)\\n\\t\\theaders = self.headers\\n\\t\\tfor line in lines:\\n\\t\\t\\theader = HEADER_FIELD.match(line)\\n\\t\\t\\tif not header:\\n\\t\\t\\t\\traise ParsingError(\"Invalid header\")\\n\\t\\t\\tkey, value = header.group(\"name\", \"value\")\\n\\t\\t\\tif b\"_\" in key:\\n\\t\\t\\t\\tcontinue\\n\\t\\t\\tvalue = value.strip(b\" \\t\")\\n\\t\\t\\tkey1 = key.upper().replace(b\"-\", b\"_\").decode(\"latin-1\")\\n\\t\\t\\ttry:\\n\\t\\t\\t\\theaders[key1] += (b\", \" + value).decode(\"latin-1\")\\n\\t\\t\\texcept KeyError:\\n\\t\\t\\t\\theaders[key1] = value.decode(\"latin-1\")\\n\\t\\tcommand, uri, version = crack_first_line(first_line)\\n\\t\\tself.request_uri = uri.decode(\"latin-1\")\\n\\t\\tversion = version.decode(\"latin-1\")\\n\\t\\tcommand = command.decode(\"latin-1\")\\n\\t\\tself.command = command\\n\\t\\tself.version = version\\n\\t\\t(\\n\\t\\t\\tself.proxy_scheme,\\n\\t\\t\\tself.proxy_netloc,\\n\\t\\t\\tself.path,\\n\\t\\t\\tself.query,\\n\\t\\t\\tself.fragment,\\n\\t\\t) = split_uri(uri)\\n\\t\\tself.url_scheme = self.adj.url_scheme\\n\\t\\tconnection = headers.get(\"CONNECTION\", \"\")\\n\\t\\tif version == \"1.0\":\\n\\t\\t\\tif connection.lower() != \"keep-alive\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif version == \"1.1\":\\n\\t\\t\\tte = headers.pop(\"TRANSFER_ENCODING\", \"\")\\n\\t\\t\\tencodings = [\\n\\t\\t\\t\\tencoding.strip(\" \\t\").lower() for encoding in te.split(\",\") if encoding\\n\\t\\t\\t]\\n\\t\\t\\tfor encoding in encodings:\\n\\t\\t\\t\\tif encoding not in {\"chunked\"}:\\n\\t\\t\\t\\t\\traise TransferEncodingNotImplemented(\\n\\t\\t\\t\\t\\t\\t\"Transfer-Encoding requested is not supported.\"\\n\\t\\t\\t\\t\\t)\\n\\t\\t\\tif encodings and encodings[-1] == \"chunked\":\\n\\t\\t\\t\\tself.chunked = True\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = ChunkedReceiver(buf)\\n\\t\\t\\telif encodings:  \\n\\t\\t\\t\\traise TransferEncodingNotImplemented(\\n\\t\\t\\t\\t\\t\"Transfer-Encoding requested is not supported.\"\\n\\t\\t\\t\\t)\\n\\t\\t\\texpect = headers.get(\"EXPECT\", \"\").lower()\\n\\t\\t\\tself.expect_continue = expect == \"100-continue\"\\n\\t\\t\\tif connection.lower() == \"close\":\\n\\t\\t\\t\\tself.connection_close = True\\n\\t\\tif not self.chunked:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tcl = int(headers.get(\"CONTENT_LENGTH\", 0))\\n\\t\\t\\texcept ValueError:\\n\\t\\t\\t\\traise ParsingError(\"Content-Length is invalid\")\\n\\t\\t\\tself.content_length = cl\\n\\t\\t\\tif cl > 0:\\n\\t\\t\\t\\tbuf = OverflowableBuffer(self.adj.inbuf_overflow)\\n\\t\\t\\t\\tself.body_rcv = FixedStreamReceiver(cl, buf)",
         "def parse_header(self, header_plus)",
         null,
         "Inject a bug in the parse_header method to trigger a Wrong Function Called with Same Parameters (WFCS) fault. The function should fail due to using HEADER_FIELD instead of HEADER_FIELD_RE in the match() call, potentially causing incorrect header parsing.",
         "Modify the parse_header function to introduce a wrong function called with same parameters fault. Change the function so that it uses an incorrect but similar regular expression object for header matching, potentially causing header parsing failures.",
         "Modify the parse_header function to use an incorrect but similar function for header matching.",
         "waitress",
         "3.7.0",
         "['test_parser.py']",
         "https://github.com/Pylons/waitress",
         "WFCS"
        ],
        [
         "35",
         "sync _redirect_safe with upstream",
         "security",
         "CVE-2020-26275",
         "https://github.com/python/cpython/commit/20c84e8d6deca063e43f6bdbd27ecaea41af3791",
         "20c84e8d6deca063e43f6bdbd27ecaea41af3791",
         "PySecDB",
         "diff --git a/jupyter_server/auth/login.py b/jupyter_server/auth/login.py\\nindex 4d93cc192..db4b89718 100644\\n--- a/jupyter_server/auth/login.py\\n+++ b/jupyter_server/auth/login.py\\n@@ -36,14 +36,19 @@ class LoginHandler(JupyterHandler):\\n\\t\\t \"\"\"\\n\\t\\t if default is None:\\n\\t\\t\\t default = self.base_url\\n-\\t\\tif not url.startswith(self.base_url):\\n+\\t\\t# protect chrome users from mishandling unescaped backslashes.\\n+\\t\\t# \\ is not valid in urls, but some browsers treat it as /\\n+\\t\\t# instead of %5C, causing `\\\\` to behave as `//`\\n+\\t\\turl = url.replace(\"\\\\\", \"%5C\")\\n+\\t\\tparsed = urlparse(url)\\n+\\t\\tif parsed.netloc or not (parsed.path + \"/\").startswith(self.base_url):\\n\\t\\t\\t # require that next_url be absolute path within our path\\n\\t\\t\\t allow = False\\n\\t\\t\\t # OR pass our cross-origin check\\n-\\t\\t\\tif '://' in url:\\n+\\t\\t\\tif parsed.netloc:\\n\\t\\t\\t\\t # if full URL, run our cross-origin check:\\n-\\t\\t\\t\\tparsed = urlparse(url.lower())\\n\\t\\t\\t\\t origin = '%s://%s' % (parsed.scheme, parsed.netloc)\\n+\\t\\t\\t\\torigin = origin.lower()\\n\\t\\t\\t\\t if self.allow_origin:\\n\\t\\t\\t\\t\\t allow = self.allow_origin == origin\\n\\t\\t\\t\\t elif self.allow_origin_pat:\\n@@ -77,9 +82,11 @@ class LoginHandler(JupyterHandler):\\n\\t\\t\\t\\t self.set_login_cookie(self, uuid.uuid4().hex)\\n\\t\\t\\t elif self.token and self.token == typed_password:\\n\\t\\t\\t\\t self.set_login_cookie(self, uuid.uuid4().hex)\\n-\\t\\t\\t\\tif new_password and self.settings.get('allow_password_change'):\\n-\\t\\t\\t\\t\\tconfig_dir = self.settings.get('config_dir')\\n-\\t\\t\\t\\t\\tconfig_file = os.path.join(config_dir, 'jupyter_server_config.json')\\n+\\t\\t\\t\\tif new_password and self.settings.get(\"allow_password_change\"):\\n+\\t\\t\\t\\t\\tconfig_dir = self.settings.get(\"config_dir\")\\n+\\t\\t\\t\\t\\tconfig_file = os.path.join(\\n+\\t\\t\\t\\t\\t\\tconfig_dir, \"jupyter_notebook_config.json\"\\n+\\t\\t\\t\\t\\t)\\n\\t\\t\\t\\t\\t set_password(new_password, config_file=config_file)\\n\\t\\t\\t\\t\\t self.log.info(\"Wrote hashed password to %s\" % config_file)\\n\\t\\t\\t else:\\ndiff --git a/tests/auth/test_login.py b/tests/auth/test_login.py\\nnew file mode 100644\\nindex 000000000..ebf2a5a1d\\n--- /dev/null\\n+++ b/tests/auth/test_login.py\\n@@ -0,0 +1,95 @@\\n+\"\"\"Tests for login redirects\"\"\"\\n+\\n+from functools import partial\\n+from urllib.parse import urlencode\\n+\\n+import pytest\\n+from tornado.httpclient import HTTPClientError\\n+from tornado.httputil import url_concat, parse_cookie\\n+\\n+from jupyter_server.utils import url_path_join\\n+\\n+\\n+# override default config to ensure a non-empty base url is used\\n+@pytest.fixture\\n+def jp_base_url():\\n+\\treturn \"/a%40b/\"\\n+\\n+\\n+@pytest.fixture\\n+def jp_server_config(jp_base_url):\\n+\\treturn {\\n+\\t\\t\"ServerApp\": {\\n+\\t\\t\\t\"base_url\": jp_base_url,\\n+\\t\\t},\\n+\\t}\\n+\\n+\\n+async def _login(jp_serverapp, http_server_client, jp_base_url, next):\\n+\\t# first: request login page with no creds\\n+\\tlogin_url = url_path_join(jp_base_url, \"login\")\\n+\\tfirst = await http_server_client.fetch(login_url)\\n+\\tcookie_header = first.headers[\"Set-Cookie\"]\\n+\\tcookies = parse_cookie(cookie_header)\\n+\\n+\\t# second, submit login form with credentials\\n+\\ttry:\\n+\\t\\tresp = await http_server_client.fetch(\\n+\\t\\t\\turl_concat(login_url, {\"next\": next}),\\n+\\t\\t\\tmethod=\"POST\",\\n+\\t\\t\\tbody=urlencode(\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\t\"password\": jp_serverapp.token,\\n+\\t\\t\\t\\t\\t\"_xsrf\": cookies.get(\"_xsrf\", \"\"),\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t),\\n+\\t\\t\\theaders={\"Cookie\": cookie_header},\\n+\\t\\t\\tfollow_redirects=False,\\n+\\t\\t)\\n+\\texcept HTTPClientError as e:\\n+\\t\\tif e.code != 302:\\n+\\t\\t\\traise\\n+\\t\\treturn e.response.headers[\"Location\"]\\n+\\telse:\\n+\\t\\tassert resp.code == 302, \"Should have returned a redirect!\"\\n+\\n+\\n+@pytest.fixture\\n+def login(jp_serverapp, http_server_client, jp_base_url):\\n+\\t\"\"\"Fixture to return a function to login to a Jupyter server\\n+\\n+\\tby submitting the login page form\\n+\\t\"\"\"\\n+\\tyield partial(_login, jp_serverapp, http_server_client, jp_base_url)\\n+\\n+\\n+@pytest.mark.parametrize(\\n+\\t\"bad_next\",\\n+\\t(\\n+\\t\\tr\"\\\\tree\",\\n+\\t\\t\"//some-host\",\\n+\\t\\t\"//host{base_url}tree\",\\n+\\t\\t\"https://google.com\",\\n+\\t\\t\"/absolute/not/base_url\",\\n+\\t),\\n+)\\n+async def test_next_bad(login, jp_base_url, bad_next):\\n+\\tbad_next = bad_next.format(base_url=jp_base_url)\\n+\\turl = await login(bad_next)\\n+\\tassert url == jp_base_url\\n+\\n+\\n+@pytest.mark.parametrize(\\n+\\t\"next_path\",\\n+\\t(\\n+\\t\\t\"tree/\",\\n+\\t\\t\"//{base_url}tree\",\\n+\\t\\t\"notebooks/notebook.ipynb\",\\n+\\t\\t\"tree//something\",\\n+\\t),\\n+)\\n+async def test_next_ok(login, jp_base_url, next_path):\\n+\\tnext_path = next_path.format(base_url=jp_base_url)\\n+\\texpected = jp_base_url + next_path\\n+\\tactual = await login(next=expected)\\n+\\tassert actual == expected",
         "def post(self):\\n\\t\\ttyped_password = self.get_argument('password', default=u'')\\n\\t\\tnew_password = self.get_argument('new_password', default=u'')\\n\\t\\tif self.get_login_available(self.settings):\\n\\t\\t\\tif self.passwd_check(self.hashed_password, typed_password) and not new_password:\\n\\t\\t\\t\\tself.set_login_cookie(self, uuid.uuid4().hex)\\n\\t\\t\\telif self.token and self.token == typed_password:\\n\\t\\t\\t\\tself.set_login_cookie(self, uuid.uuid4().hex)\\n\\t\\t\\t\\tif new_password and self.settings.get(\"allow_password_change\"):\\n\\t\\t\\t\\t\\tconfig_dir = self.settings.get(\"config_dir\")\\n\\t\\t\\t\\t\\tconfig_file = os.path.join(\\n\\t\\t\\t\\t\\t\\tconfig_dir, \"jupyter_notebook_config.json\"\\n\\t\\t\\t\\t\\t)\\n\\t\\t\\t\\t\\tset_password(new_password, config_file=config_file)\\n\\t\\t\\t\\t\\tself.log.info(\"Wrote hashed password to %s\" % config_file)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.set_status(401)\\n\\t\\t\\t\\tself._render(message={'error': 'Invalid credentials'})\\n\\t\\t\\t\\treturn",
         "def post(self):\\n\\t\\ttyped_password = self.get_argument('password', default=u'')\\n\\t\\tnew_password = self.get_argument('new_password', default=u'')\\n\\t\\tif self.get_login_available(self.settings):\\n\\t\\t\\tif self.passwd_check(self.hashed_password, typed_password) and not new_password:\\n\\t\\t\\t\\tself.set_login_cookie(self, uuid.uuid4().hex)\\n\\t\\t\\telif self.token and self.token == typed_password:\\n\\t\\t\\t\\tself.set_login_cookie(self, uuid.uuid4().hex)\\n\\t\\t\\t\\tif new_password and self.settings.get('allow_password_change'):\\n\\t\\t\\t\\t\\tconfig_dir = self.settings.get('config_dir')\\n\\t\\t\\t\\t\\tconfig_file = os.path.join(config_dir, 'jupyter_server_config.json')\\n\\t\\t\\t\\t\\tset_password(new_password, config_file=config_file)\\n\\t\\t\\t\\t\\tself.log.info(\"Wrote hashed password to %s\" % config_file)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.set_status(401)\\n\\t\\t\\t\\tself._render(message={'error': 'Invalid credentials'})\\n\\t\\t\\t\\treturn",
         "def post(self)",
         null,
         "Implement a bug in the post function to trigger a Wrong Value Used in Parameter of Function Call (WPFL) fault. The function should fail due to using 'jupyter_server_config.json' instead of 'jupyter_notebook_config.json'.",
         "Introduce an error in the function post using wrong literal value in function parameter. The function should fail due to using an incorrect configuration file name, causing password changes to be written to the wrong file.",
         "Introduce an error in the function post using wrong literal value in function parameter.",
         "jupyter",
         "3.8.0",
         "['test_login.py']",
         "https://github.com/SolarisYan/jupyter_server",
         "WPFL"
        ],
        [
         "36",
         "Fix CVE-2017-11610 by disabling object traversal in XML-RPC dispatch",
         "security",
         "CVE-2017-11610",
         "https://github.com/python/cpython/commit/058f46141e346b18dee0497ba11203cb81ecb19e",
         "058f46141e346b18dee0497ba11203cb81ecb19e",
         "MoreFixes",
         "diff --git a/supervisor/tests/test_xmlrpc.py b/supervisor/tests/test_xmlrpc.py\\nindex 22042ad..856b5f9 100644\\n--- a/supervisor/tests/test_xmlrpc.py\\n+++ b/supervisor/tests/test_xmlrpc.py\\n@@ -269,28 +269,89 @@ class XMLRPCHandlerTests(unittest.TestCase):\\n\\t\\t self.assertEqual(request._error, 500)\\n \\n class TraverseTests(unittest.TestCase):\\n-\\tdef test_underscore(self):\\n+\\tdef test_security_disallows_underscore_methods(self):\\n\\t\\t from supervisor import xmlrpc\\n-\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse, None, '_', None)\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\tclass A:\\n+\\t\\t\\tdef _danger(self):\\n+\\t\\t\\t\\treturn True\\n+\\t\\troot = Root()\\n+\\t\\troot.a = A()\\n+\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse,\\n+\\t\\t\\troot, 'a._danger', [])\\n+\\n+\\tdef test_security_disallows_object_traversal(self):\\n+\\t\\tfrom supervisor import xmlrpc\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\tclass A:\\n+\\t\\t\\tpass\\n+\\t\\tclass B:\\n+\\t\\t\\tdef danger(self):\\n+\\t\\t\\t\\treturn True\\n+\\t\\troot = Root()\\n+\\t\\troot.a = A()\\n+\\t\\troot.a.b = B()\\n+\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse,\\n+\\t\\t\\troot, 'a.b.danger', [])\\n+\\n+\\tdef test_namespace_name_not_found(self):\\n+\\t\\tfrom supervisor import xmlrpc\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\troot = Root()\\n+\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse,\\n+\\t\\t\\troot, 'notfound.hello', None)\\n \\n-\\tdef test_notfound(self):\\n+\\tdef test_method_name_not_found(self):\\n\\t\\t from supervisor import xmlrpc\\n-\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse, None, 'foo', None)\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\tclass A:\\n+\\t\\t\\tpass\\n+\\t\\troot = Root()\\n+\\t\\troot.a = A()\\n+\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse,\\n+\\t\\t\\troot, 'a.notfound', [])\\n \\n-\\tdef test_badparams(self):\\n+\\tdef test_method_name_exists_but_is_not_a_method(self):\\n\\t\\t from supervisor import xmlrpc\\n-\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse, self,\\n-\\t\\t\\t\\t\\t\\t  'test_badparams', (1, 2, 3))\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\tclass A:\\n+\\t\\t\\tpass\\n+\\t\\tclass B:\\n+\\t\\t\\tpass\\n+\\t\\troot = Root()\\n+\\t\\troot.a = A()\\n+\\t\\troot.a.b = B()\\n+\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse,\\n+\\t\\t\\troot, 'a.b', [])  # b is not a method\\n+\\n+\\tdef test_bad_params(self):\\n+\\t\\tfrom supervisor import xmlrpc\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\tclass A:\\n+\\t\\t\\tdef hello(self, name):\\n+\\t\\t\\t\\treturn \"Hello %s\" % name\\n+\\t\\troot = Root()\\n+\\t\\troot.a = A()\\n+\\t\\tself.assertRaises(xmlrpc.RPCError, xmlrpc.traverse,\\n+\\t\\t\\troot, 'a.hello', [\"there\", \"extra\"])  # too many params\\n \\n\\t def test_success(self):\\n\\t\\t from supervisor import xmlrpc\\n-\\t\\tL = []\\n-\\t\\tclass Dummy:\\n-\\t\\t\\tdef foo(self, a):\\n-\\t\\t\\t\\tL.append(a)\\n-\\t\\tdummy = Dummy()\\n-\\t\\txmlrpc.traverse(dummy, 'foo', [1])\\n-\\t\\tself.assertEqual(L, [1])\\n+\\t\\tclass Root:\\n+\\t\\t\\tpass\\n+\\t\\tclass A:\\n+\\t\\t\\tdef hello(self, name):\\n+\\t\\t\\t\\treturn \"Hello %s\" % name\\n+\\t\\troot = Root()\\n+\\t\\troot.a = A()\\n+\\t\\tresult = xmlrpc.traverse(root, 'a.hello', [\"there\"])\\n+\\t\\tself.assertEqual(result, \"Hello there\")\\n \\n class SupervisorTransportTests(unittest.TestCase):\\n\\t def _getTargetClass(self):\\ndiff --git a/supervisor/xmlrpc.py b/supervisor/xmlrpc.py\\nindex 339e19e..9a37c73 100644\\n--- a/supervisor/xmlrpc.py\\n+++ b/supervisor/xmlrpc.py\\n@@ -428,18 +428,27 @@ class supervisor_xmlrpc_handler(xmlrpc_handler):\\n\\t\\t return traverse(self.rpcinterface, method, params)\\n \\n def traverse(ob, method, params):\\n-\\tpath = method.split('.')\\n-\\tfor name in path:\\n-\\t\\tif name.startswith('_'):\\n-\\t\\t\\t# security (don't allow things that start with an underscore to\\n-\\t\\t\\t# be called remotely)\\n-\\t\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n-\\t\\tob = getattr(ob, name, None)\\n-\\t\\tif ob is None:\\n-\\t\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n+\\tdotted_parts = method.split('.')\\n+\\t# security (CVE-2017-11610, don't allow object traversal)\\n+\\tif len(dotted_parts) != 2:\\n+\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n+\\tnamespace, method = dotted_parts\\n+\\n+\\t# security (don't allow methods that start with an underscore to\\n+\\t# be called remotely)\\n+\\tif method.startswith('_'):\\n+\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n+\\n+\\trpcinterface = getattr(ob, namespace, None)\\n+\\tif rpcinterface is None:\\n+\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n+\\n+\\tfunc = getattr(rpcinterface, method, None)\\n+\\tif not isinstance(func, types.MethodType):\\n+\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n \\n\\t try:\\n-\\t\\treturn ob(*params)\\n+\\t\\treturn func(*params)\\n\\t except TypeError:\\n\\t\\t raise RPCError(Faults.INCORRECT_PARAMETERS)",
         "def traverse(ob, method, params):\\n\\tdotted_parts = method.split('.')\\n\\tif len(dotted_parts) != 2:\\n\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n\\tnamespace, method = dotted_parts\\n\\tif method.startswith('_'):\\n\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n\\trpcinterface = getattr(ob, namespace, None)\\n\\tif rpcinterface is None:\\n\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n\\tfunc = getattr(rpcinterface, method, None)\\n\\tif not isinstance(func, types.MethodType):\\n\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n\\ttry:\\n\\t\\treturn func(*params)\\n\\texcept TypeError:\\n\\t\\traise RPCError(Faults.INCORRECT_PARAMETERS)\\nclass SupervisorTransport(xmlrpclib.Transport):\\n\\tconnection = None\\n\\t_use_datetime = 0",
         "def traverse(ob, method, params):\\n\\tpath = method.split('.')\\n\\tfor name in path:\\n\\t\\tif name.startswith('_'):\\n\\t\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n\\t\\tob = getattr(ob, name, None)\\n\\t\\tif ob is None:\\n\\t\\t\\traise RPCError(Faults.UNKNOWN_METHOD)\\n\\ttry:\\n\\t\\treturn ob(*params)\\n\\texcept TypeError:\\n\\t\\traise RPCError(Faults.INCORRECT_PARAMETERS)\\nclass SupervisorTransport(xmlrpclib.Transport):\\n\\tconnection = None\\n\\t_use_datetime = 0",
         "def traverse(ob, method, params)",
         null,
         "To simulate incorrect method traversal, introduce a bug into the traverse function to simulate Wrong Algorithm Large Modifications (WALL). The function should fail due to completely changing the method traversal logic.",
         "Introduce an error in the traverse function to simulate wrong algorithm large modifications (WALL). The function should fail due to fundamentally changing how method traversal works, potentially allowing unauthorized access through XML-RPC requests.",
         "Introduce an error in the traverse function to simulate wrong algorithm large modifications (WALL).",
         "supervisor",
         "2.7.0",
         "['test_xmlrpc.py']",
         "https://github.com/Supervisor/supervisor",
         "WALL"
        ],
        [
         "37",
         "reports: Escape user names in generated reports\\n\\nThis avoids stored XSS.",
         "security",
         "CVE-2022-24710",
         "https://github.com/python/cpython/commit/22d577b1f1e88665a88b4569380148030e0f8389",
         "22d577b1f1e88665a88b4569380148030e0f8389",
         "PySecDB",
         "diff --git a/weblate/trans/tests/test_reports.py b/weblate/trans/tests/test_reports.py\\nindex fa27f3c7a8..8766020eec 100644\\n--- a/weblate/trans/tests/test_reports.py\\n+++ b/weblate/trans/tests/test_reports.py\\n@@ -31,7 +31,7 @@ COUNTS_DATA = [\\n\\t\\t \"count\": 1,\\n\\t\\t \"count_edit\": 0,\\n\\t\\t \"count_new\": 1,\\n-\\t\\t\"name\": \"Weblate Test\",\\n+\\t\\t\"name\": \"Weblate <b>Test</b>\",\\n\\t\\t \"words\": 2,\\n\\t\\t \"words_edit\": 0,\\n\\t\\t \"words_new\": 2,\\n@@ -62,7 +62,9 @@ class BaseReportsTest(ViewTestCase):\\n\\t def setUp(self):\\n\\t\\t super().setUp()\\n\\t\\t self.user.is_superuser = True\\n+\\t\\tself.user.full_name = \"Weblate <b>Test</b>\"\\n\\t\\t self.user.save()\\n+\\t\\tself.maxDiff = None\\n \\n\\t def add_change(self):\\n\\t\\t self.edit_unit(\"Hello, world!\\n\", \"Nazdar svete!\\n\")\\n@@ -87,7 +89,14 @@ class ReportsTest(BaseReportsTest):\\n\\t\\t\\t translation__component=self.component,\\n\\t\\t )\\n\\t\\t self.assertEqual(\\n-\\t\\t\\tdata, [{\"Czech\": [(\"weblate@example.org\", \"Weblate Test\", expected_count)]}]\\n+\\t\\t\\tdata,\\n+\\t\\t\\t[\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\t\"Czech\": [\\n+\\t\\t\\t\\t\\t\\t(\"weblate@example.org\", \"Weblate <b>Test</b>\", expected_count)\\n+\\t\\t\\t\\t\\t]\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t],\\n\\t\\t )\\n \\n\\t def test_credits_more(self):\\n@@ -126,7 +135,7 @@ class ReportsComponentTest(BaseReportsTest):\\n\\t\\t self.assertEqual(response.status_code, 200)\\n\\t\\t self.assertJSONEqual(\\n\\t\\t\\t response.content.decode(),\\n-\\t\\t\\t[{\"Czech\": [[\"weblate@example.org\", \"Weblate Test\", 1]]}],\\n+\\t\\t\\t[{\"Czech\": [[\"weblate@example.org\", \"Weblate <b>Test</b>\", 1]]}],\\n\\t\\t )\\n \\n\\t def test_credits_view_rst(self):\\n@@ -134,7 +143,13 @@ class ReportsComponentTest(BaseReportsTest):\\n\\t\\t self.assertEqual(response.status_code, 200)\\n\\t\\t self.assertEqual(\\n\\t\\t\\t response.content.decode(),\\n-\\t\\t\\t\"\\n\\n* Czech\\n\\n\\t* Weblate Test <weblate@example.org> (1)\\n\\n\",\\n+\\t\\t\\t\"\"\"\\n+\\n+* Czech\\n+\\n+\\t* Weblate <b>Test</b> <weblate@example.org> (1)\\n+\\n+\"\"\",\\n\\t\\t )\\n \\n\\t def test_credits_view_html(self):\\n@@ -145,7 +160,7 @@ class ReportsComponentTest(BaseReportsTest):\\n\\t\\t\\t \"<table>\\n\"\\n\\t\\t\\t \"<tr>\\n<th>Czech</th>\\n\"\\n\\t\\t\\t '<td><ul><li><a href=\"mailto:weblate@example.org\">'\\n-\\t\\t\\t\"Weblate Test</a> (1)</li></ul></td>\\n</tr>\\n\"\\n+\\t\\t\\t\"Weblate <b>Test</b></a> (1)</li></ul></td>\\n</tr>\\n\"\\n\\t\\t\\t \"</table>\",\\n\\t\\t )\\n \\n@@ -231,7 +246,7 @@ class ReportsComponentTest(BaseReportsTest):\\n\\t\\t <th>Target chars edited</th>\\n\\t </tr>\\n\\t <tr>\\n-\\t\\t<td>Weblate Test</td>\\n+\\t\\t<td>Weblate <b>Test</b></td>\\n\\t\\t <td>weblate@example.org</td>\\n\\t\\t <td>1</td>\\n\\t\\t <td>14</td>\\ndiff --git a/weblate/trans/views/reports.py b/weblate/trans/views/reports.py\\nindex 8aa400d2cb..e66fc49719 100644\\n--- a/weblate/trans/views/reports.py\\n+++ b/weblate/trans/views/reports.py\\n@@ -17,9 +17,9 @@\\n # along with this program.  If not, see <https://www.gnu.org/licenses/>.\\n #\\n \\n-\\n from django.contrib.auth.decorators import login_required\\n from django.http import HttpResponse, JsonResponse\\n+from django.utils.html import escape\\n from django.views.decorators.http import require_POST\\n \\n from weblate.lang.models import Language\\n@@ -109,10 +109,13 @@ def get_credits(request, project=None, component=None):\\n\\t for language in data:\\n\\t\\t name, translators = language.popitem()\\n\\t\\t result.append(row_start)\\n-\\t\\tresult.append(language_format.format(name))\\n+\\t\\tresult.append(language_format.format(escape(name)))\\n\\t\\t result.append(\\n\\t\\t\\t translator_start\\n-\\t\\t\\t+ \"\\n\".join(translator_format.format(*t) for t in translators)\\n+\\t\\t\\t+ \"\\n\".join(\\n+\\t\\t\\t\\ttranslator_format.format(escape(t[0]), escape(t[1]), t[2])\\n+\\t\\t\\t\\tfor t in translators\\n+\\t\\t\\t)\\n\\t\\t\\t + translator_end\\n\\t\\t )\\n\\t\\t result.append(row_end)\\n@@ -288,8 +291,8 @@ def get_counts(request, project=None, component=None):\\n\\t\\t result.append(\\n\\t\\t\\t \"\".join(\\n\\t\\t\\t\\t (\\n-\\t\\t\\t\\t\\tcell_name.format(item[\"name\"] or \"Anonymous\"),\\n-\\t\\t\\t\\t\\tcell_name.format(item[\"email\"] or \"\"),\\n+\\t\\t\\t\\t\\tcell_name.format(escape(item[\"name\"]) or \"Anonymous\"),\\n+\\t\\t\\t\\t\\tcell_name.format(escape(item[\"email\"]) or \"\"),\\n\\t\\t\\t\\t\\t cell_count.format(item[\"count\"]),\\n\\t\\t\\t\\t\\t cell_count.format(item[\"edits\"]),\\n\\t\\t\\t\\t\\t cell_count.format(item[\"words\"]),",
         "def get_credits(request, project=None, component=None):\\n\\tif project is None:\\n\\t\\tobj = None\\n\\t\\tkwargs = {\"translation__isnull\": False}\\n\\telif component is None:\\n\\t\\tobj = get_project(request, project)\\n\\t\\tkwargs = {\"translation__component__project\": obj}\\n\\telse:\\n\\t\\tobj = get_component(request, project, component)\\n\\t\\tkwargs = {\"translation__component\": obj}\\n\\tform = ReportsForm(request.POST)\\n\\tif not form.is_valid():\\n\\t\\tshow_form_errors(request, form)\\n\\t\\treturn redirect_param(obj or \"home\", \"\\n\\tdata = generate_credits(\\n\\t\\tNone if request.user.has_perm(\"reports.view\", obj) else request.user,\\n\\t\\tform.cleaned_data[\"start_date\"],\\n\\t\\tform.cleaned_data[\"end_date\"],\\n\\t\\t**kwargs,\\n\\t)\\n\\tif form.cleaned_data[\"style\"] == \"json\":\\n\\t\\treturn JsonResponse(data=data, safe=False)\\n\\tif form.cleaned_data[\"style\"] == \"html\":\\n\\t\\tstart = \"<table>\"\\n\\t\\trow_start = \"<tr>\"\\n\\t\\tlanguage_format = \"<th>{0}</th>\"\\n\\t\\ttranslator_start = \"<td><ul>\"\\n\\t\\ttranslator_format = '<li><a href=\"mailto:{0}\">{1}</a> ({2})</li>'\\n\\t\\ttranslator_end = \"</ul></td>\"\\n\\t\\trow_end = \"</tr>\"\\n\\t\\tmime = \"text/html\"\\n\\t\\tend = \"</table>\"\\n\\telse:\\n\\t\\tstart = \"\"\\n\\t\\trow_start = \"\"\\n\\t\\tlanguage_format = \"* {0}\\n\"\\n\\t\\ttranslator_start = \"\"\\n\\t\\ttranslator_format = \"\\t* {1} <{0}> ({2})\"\\n\\t\\ttranslator_end = \"\"\\n\\t\\trow_end = \"\"\\n\\t\\tmime = \"text/plain\"\\n\\t\\tend = \"\"\\n\\tresult = [start]\\n\\tfor language in data:\\n\\t\\tname, translators = language.popitem()\\n\\t\\tresult.append(row_start)\\n\\t\\tresult.append(language_format.format(escape(name)))\\n\\t\\tresult.append(\\n\\t\\t\\ttranslator_start\\n\\t\\t\\t+ \"\\n\".join(\\n\\t\\t\\t\\ttranslator_format.format(escape(t[0]), escape(t[1]), t[2])\\n\\t\\t\\t\\tfor t in translators\\n\\t\\t\\t)\\n\\t\\t\\t+ translator_end\\n\\t\\t)\\n\\t\\tresult.append(row_end)\\n\\tresult.append(end)\\n\\treturn HttpResponse(\"\\n\".join(result), content_type=f\"{mime}; charset=utf-8\")",
         "def get_credits(request, project=None, component=None):\\n\\tif project is None:\\n\\t\\tobj = None\\n\\t\\tkwargs = {\"translation__isnull\": False}\\n\\telif component is None:\\n\\t\\tobj = get_project(request, project)\\n\\t\\tkwargs = {\"translation__component__project\": obj}\\n\\telse:\\n\\t\\tobj = get_component(request, project, component)\\n\\t\\tkwargs = {\"translation__component\": obj}\\n\\tform = ReportsForm(request.POST)\\n\\tif not form.is_valid():\\n\\t\\tshow_form_errors(request, form)\\n\\t\\treturn redirect_param(obj or \"home\", \"\\n\\tdata = generate_credits(\\n\\t\\tNone if request.user.has_perm(\"reports.view\", obj) else request.user,\\n\\t\\tform.cleaned_data[\"start_date\"],\\n\\t\\tform.cleaned_data[\"end_date\"],\\n\\t\\t**kwargs,\\n\\t)\\n\\tif form.cleaned_data[\"style\"] == \"json\":\\n\\t\\treturn JsonResponse(data=data, safe=False)\\n\\tif form.cleaned_data[\"style\"] == \"html\":\\n\\t\\tstart = \"<table>\"\\n\\t\\trow_start = \"<tr>\"\\n\\t\\tlanguage_format = \"<th>{0}</th>\"\\n\\t\\ttranslator_start = \"<td><ul>\"\\n\\t\\ttranslator_format = '<li><a href=\"mailto:{0}\">{1}</a> ({2})</li>'\\n\\t\\ttranslator_end = \"</ul></td>\"\\n\\t\\trow_end = \"</tr>\"\\n\\t\\tmime = \"text/html\"\\n\\t\\tend = \"</table>\"\\n\\telse:\\n\\t\\tstart = \"\"\\n\\t\\trow_start = \"\"\\n\\t\\tlanguage_format = \"* {0}\\n\"\\n\\t\\ttranslator_start = \"\"\\n\\t\\ttranslator_format = \"\\t* {1} <{0}> ({2})\"\\n\\t\\ttranslator_end = \"\"\\n\\t\\trow_end = \"\"\\n\\t\\tmime = \"text/plain\"\\n\\t\\tend = \"\"\\n\\tresult = [start]\\n\\tfor language in data:\\n\\t\\tname, translators = language.popitem()\\n\\t\\tresult.append(row_start)\\n\\t\\tresult.append(language_format.format(name))\\n\\t\\tresult.append(\\n\\t\\t\\ttranslator_start\\n\\t\\t\\t+ \"\\n\".join(translator_format.format(*t) for t in translators)\\n\\t\\t\\t+ translator_end\\n\\t\\t)\\n\\t\\tresult.append(row_end)\\n\\tresult.append(end)\\n\\treturn HttpResponse(\"\\n\".join(result), content_type=f\"{mime}; charset=utf-8\")",
         "def get_credits(request, project=None, component=None)",
         null,
         "Alter the behavior of the get_credits function to introduce a Missing Function Call Extended (MFCE) fault. The function should fail due to missing escape() function calls that filter user input to prevent XSS attacks when formatting output.",
         "Alter the behavior of the get_credits function to introduce a Missing Function Call Extended (MFCE) fault. The function should fail due to omitted escape() calls that should filter user-provided content, creating XSS vulnerabilities.",
         "Alter the behavior of the get_credits function to introduce a Missing Function Call Extended (MFCE) fault.",
         "weblate",
         "3.7.0",
         "['test_reports.py']",
         "https://github.com/WeblateOrg/weblate",
         "MFCE"
        ],
        [
         "38",
         "Fix state leakage and speedup in test-suite\\n\\nThis is mostly visible when running the test via pytest that\\ncollect-then-run vs nose that runs as it collects.\\n\\nWhile I was at it I've improved some tests to be faster by changing the\\nmaximum recursion limit.",
         "security",
         null,
         "https://github.com/python/cpython/commit/1a37c55789d9e3457b8e00231be490dc6d971ac4",
         "1a37c55789d9e3457b8e00231be490dc6d971ac4",
         "PySecDB",
         "diff --git a/IPython/core/tests/test_run.py b/IPython/core/tests/test_run.py\\nindex 2afa5ba7c..db308f1ec 100644\\n--- a/IPython/core/tests/test_run.py\\n+++ b/IPython/core/tests/test_run.py\\n@@ -35,7 +35,6 @@ from IPython.utils.io import capture_output\\n from IPython.utils.tempdir import TemporaryDirectory\\n from IPython.core import debugger\\n \\n-\\n def doctest_refbug():\\n\\t \"\"\"Very nasty problem with references held by multiple runs of a script.\\n\\t See: https://github.com/ipython/ipython/issues/141\\n@@ -537,6 +536,8 @@ def test_run_tb():\\n\\t\\t nt.assert_not_in(\"execfile\", out)\\n\\t\\t nt.assert_in(\"RuntimeError\", out)\\n\\t\\t nt.assert_equal(out.count(\"---->\"), 3)\\n+\\t\\tdel ip.user_ns['bar']\\n+\\t\\tdel ip.user_ns['foo']\\n \\n @dec.knownfailureif(sys.platform == 'win32', \"writes to io.stdout aren't captured on Windows\")\\n def test_script_tb():\\ndiff --git a/IPython/core/tests/test_ultratb.py b/IPython/core/tests/test_ultratb.py\\nindex 536a4db65..787a7eca6 100644\\n--- a/IPython/core/tests/test_ultratb.py\\n+++ b/IPython/core/tests/test_ultratb.py\\n@@ -10,7 +10,8 @@ import traceback\\n import unittest\\n from unittest import mock\\n \\n-from ..ultratb import ColorTB, VerboseTB, find_recursion\\n+import IPython.core.ultratb as ultratb\\n+from IPython.core.ultratb import ColorTB, VerboseTB, find_recursion\\n \\n \\n from IPython.testing import tools as tt\\n@@ -18,8 +19,6 @@ from IPython.testing.decorators import onlyif_unicode_paths\\n from IPython.utils.syspathcontext import prepended_to_syspath\\n from IPython.utils.tempdir import TemporaryDirectory\\n \\n-ip = get_ipython()\\n-\\n file_1 = \"\"\"1\\n 2\\n 3\\n@@ -31,6 +30,30 @@ file_2 = \"\"\"def f():\\n   1/0\\n \"\"\"\\n \\n+\\n+def recursionlimit(frames):\\n+\\t\"\"\"\\n+\\tdecorator to set the recursion limit temporarily\\n+\\t\"\"\"\\n+\\n+\\tdef inner(test_function):\\n+\\t\\tdef wrapper(*args, **kwargs):\\n+\\t\\t\\t_orig_rec_limit = ultratb._FRAME_RECURSION_LIMIT\\n+\\t\\t\\tultratb._FRAME_RECURSION_LIMIT = frames - 50\\n+\\n+\\t\\t\\trl = sys.getrecursionlimit()\\n+\\t\\t\\tsys.setrecursionlimit(frames)\\n+\\t\\t\\ttry:\\n+\\t\\t\\t\\treturn test_function(*args, **kwargs)\\n+\\t\\t\\tfinally:\\n+\\t\\t\\t\\tsys.setrecursionlimit(rl)\\n+\\t\\t\\t\\tultratb._FRAME_RECURSION_LIMIT = _orig_rec_limit\\n+\\n+\\t\\treturn wrapper\\n+\\n+\\treturn inner\\n+\\n+\\n class ChangedPyFileTest(unittest.TestCase):\\n\\t def test_changing_py_file(self):\\n\\t\\t \"\"\"Traceback produced if the line where the error occurred is missing?\\n@@ -200,6 +223,8 @@ bar()\\n\\t\\t # Assert syntax error during runtime generate stacktrace\\n\\t\\t with tt.AssertPrints([\"foo()\", \"bar()\"]):\\n\\t\\t\\t ip.run_cell(syntax_error_at_runtime)\\n+\\t\\tdel ip.user_ns['bar']\\n+\\t\\tdel ip.user_ns['foo']\\n \\n\\t def test_changing_py_file(self):\\n\\t\\t with TemporaryDirectory() as td:\\n@@ -302,14 +327,17 @@ def r3o2():\\n\\t\\t with tt.AssertNotPrints(\"frames repeated\"):\\n\\t\\t\\t ip.run_cell(\"non_recurs()\")\\n \\n+\\t@recursionlimit(65)\\n\\t def test_recursion_one_frame(self):\\n\\t\\t with tt.AssertPrints(\"1 frames repeated\"):\\n\\t\\t\\t ip.run_cell(\"r1()\")\\n \\n+\\t@recursionlimit(65)\\n\\t def test_recursion_three_frames(self):\\n\\t\\t with tt.AssertPrints(\"3 frames repeated\"):\\n\\t\\t\\t ip.run_cell(\"r3o2()\")\\n \\n+\\t@recursionlimit(65)\\n\\t def test_find_recursion(self):\\n\\t\\t captured = []\\n\\t\\t def capture_exc(*args, **kwargs):\\ndiff --git a/IPython/core/ultratb.py b/IPython/core/ultratb.py\\nindex 3060be1f2..03b02b47d 100644\\n--- a/IPython/core/ultratb.py\\n+++ b/IPython/core/ultratb.py\\n@@ -137,6 +137,12 @@ INDENT_SIZE = 8\\n # to users of ultratb who are NOT running inside ipython.\\n DEFAULT_SCHEME = 'NoColor'\\n \\n+\\n+# Number of frame above which we are likely to have a recursion and will\\n+# **attempt** to detect it.  Made modifiable mostly to speedup test suite\\n+# as detecting recursion is one of our slowest test\\n+_FRAME_RECURSION_LIMIT = 500\\n+\\n # ---------------------------------------------------------------------------\\n # Code begins\\n \\n@@ -431,7 +437,7 @@ def is_recursion_error(etype, value, records):\\n\\t # a recursion error.\\n\\t return (etype is recursion_error_type) \\\\n\\t\\t\\tand \"recursion\" in str(value).lower() \\\\n-\\t\\t   and len(records) > 500\\n+\\t\\t   and len(records) > _FRAME_RECURSION_LIMIT\\n \\n def find_recursion(etype, value, records):\\n\\t \"\"\"Identify the repeating stack frames from a RecursionError traceback\\ndiff --git a/IPython/extensions/tests/test_storemagic.py b/IPython/extensions/tests/test_storemagic.py\\nindex 373a71692..a7b41bab5 100644\\n--- a/IPython/extensions/tests/test_storemagic.py\\n+++ b/IPython/extensions/tests/test_storemagic.py\\n@@ -3,10 +3,13 @@ import tempfile, os\\n from traitlets.config.loader import Config\\n import nose.tools as nt\\n \\n-ip = get_ipython()\\n-ip.magic('load_ext storemagic')\\n+\\n+def setup_module():\\n+\\tip.magic('load_ext storemagic')\\n \\n def test_store_restore():\\n+\\tassert 'bar' not in ip.user_ns, \"Error: some other test leaked `bar` in user_ns\"\\n+\\tassert 'foo' not in ip.user_ns, \"Error: some other test leaked `foo` in user_ns\"\\n\\t ip.user_ns['foo'] = 78\\n\\t ip.magic('alias bar echo \"hello\"')\\n\\t tmpd = tempfile.mkdtemp()",
         "def is_recursion_error(etype, value, records):\\n\\ttry:\\n\\t\\trecursion_error_type = RecursionError\\n\\texcept NameError:\\n\\t\\trecursion_error_type = RuntimeError\\n\\treturn (etype is recursion_error_type) \\\\n\\t\\t   and \"recursion\" in str(value).lower() \\\\n\\t\\t   and len(records) > _FRAME_RECURSION_LIMIT",
         "def is_recursion_error(etype, value, records):\\n\\ttry:\\n\\t\\trecursion_error_type = RecursionError\\n\\texcept NameError:\\n\\t\\trecursion_error_type = RuntimeError\\n\\treturn (etype is recursion_error_type) \\\\n\\t\\t   and \"recursion\" in str(value).lower() \\\\n\\t\\t   and len(records) > 500",
         "def is_recursion_error(etype, value, records)",
         null,
         "Create a Wrong Value Used in Variable Initialization (WVIV) fault by altering the is_recursion_error function. The function should fail due to using 500 instead of _FRAME_RECURSION_LIMIT, causing hardcoding of the recursion limit.",
         "Cause a wrong value initialization by injecting an error into is_recursion_error. The function should fail due to using a hardcoded value instead of the configurable constant, potentially causing incorrect recursion error detection.",
         "Cause a wrong value initialization by injecting an error into is_recursion_error.",
         "ipython",
         "3.8.0",
         "['test_run.py', 'test_ultratb.py', 'test_storemagic.py']",
         "https://github.com/aimtyaem/Ipython",
         "WVIV"
        ],
        [
         "39",
         "Remove shell use in subprocess",
         "security",
         "CVE-2021-4041",
         "https://github.com/python/cpython/commit/3533f265f4349a3f2a0283158cd01b59a6bbc7bd",
         "3533f265f4349a3f2a0283158cd01b59a6bbc7bd",
         "PySecDB",
         "diff --git a/ansible_runner/config/doc.py b/ansible_runner/config/doc.py\\nindex fe99ec9..6612baf 100644\\n--- a/ansible_runner/config/doc.py\\n+++ b/ansible_runner/config/doc.py\\n@@ -87,7 +87,7 @@ class DocConfig(BaseConfig):\\n\\t\\t if module_path:\\n\\t\\t\\t self.cmdline_args.extend(['-M', module_path])\\n \\n-\\t\\tself.cmdline_args.append(\" \".join(plugin_names))\\n+\\t\\tself.cmdline_args.extend(plugin_names)\\n \\n\\t\\t self.command = [self._ansible_doc_exec_path] + self.cmdline_args\\n\\t\\t self._handle_command_wrap(self.execution_mode, self.cmdline_args)\\ndiff --git a/ansible_runner/runner.py b/ansible_runner/runner.py\\nindex 44a4567..1656e72 100644\\n--- a/ansible_runner/runner.py\\n+++ b/ansible_runner/runner.py\\n@@ -204,8 +204,12 @@ class Runner(object):\\n\\t\\t\\t user = getpass.getuser()\\n\\t\\t\\t group = grp.getgrgid(os.getgid()).gr_name\\n \\n-\\t\\t\\tcmd = 'cgcreate -a {user}:{group} -t {user}:{group} -g cpuacct,memory,pids:{}'.format(cgroup_path, user=user, group=group)\\n-\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\\n+\\t\\t\\tcmd = ['cgcreate',\\n+\\t\\t\\t\\t   '-a', f'{user}:{group}',\\n+\\t\\t\\t\\t   '-t', f'{user}:{group}',\\n+\\t\\t\\t\\t   '-g', f'cpuacct,memory,pids:{cgroup_path}',\\n+\\t\\t\\t\\t   ]\\n+\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE)\\n\\t\\t\\t _, stderr = proc.communicate()\\n\\t\\t\\t if proc.returncode:\\n\\t\\t\\t\\t # Unable to create cgroup\\n@@ -249,12 +253,11 @@ class Runner(object):\\n\\t\\t\\t\\t\\t 'stderr': error_fd,\\n\\t\\t\\t\\t\\t 'check': True,\\n\\t\\t\\t\\t\\t 'universal_newlines': True,\\n-\\t\\t\\t\\t\\t'shell': True\\n\\t\\t\\t\\t }\\n\\t\\t\\t\\t if subprocess_timeout is not None:\\n\\t\\t\\t\\t\\t kwargs.update({'timeout': subprocess_timeout})\\n \\n-\\t\\t\\t\\tproc_out = run_subprocess(\" \".join(command), **kwargs)\\n+\\t\\t\\t\\tproc_out = run_subprocess(command, **kwargs)\\n \\n\\t\\t\\t\\t stdout_response = proc_out.stdout\\n\\t\\t\\t\\t stderr_response = proc_out.stderr\\n@@ -391,8 +394,8 @@ class Runner(object):\\n\\t\\t\\t\\t return True\\n\\t\\t\\t _delete()\\n\\t\\t if self.resource_profiling:\\n-\\t\\t\\tcmd = 'cgdelete -g cpuacct,memory,pids:{}'.format(cgroup_path)\\n-\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\\n+\\t\\t\\tcmd = ['cgdelete', '-g', f'cpuacct,memory,pids:{cgroup_path}']\\n+\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE)\\n\\t\\t\\t _, stderr = proc.communicate()\\n\\t\\t\\t if proc.returncode:\\n\\t\\t\\t\\t logger.error('Failed to delete cgroup: {}'.format(stderr))\\n@@ -532,8 +535,8 @@ class Runner(object):\\n\\t\\t container_name = self.config.container_name\\n\\t\\t if container_name:\\n\\t\\t\\t container_cli = self.config.process_isolation_executable\\n-\\t\\t\\tcmd = '{} kill {}'.format(container_cli, container_name)\\n-\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\\n+\\t\\t\\tcmd = [container_cli, 'kill', container_name]\\n+\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE)\\n\\t\\t\\t _, stderr = proc.communicate()\\n\\t\\t\\t if proc.returncode:\\n\\t\\t\\t\\t logger.info('Error from {} kill {} command:\\n{}'.format(container_cli, container_name, stderr))\\ndiff --git a/test/integration/test_interface.py b/test/integration/test_interface.py\\nindex 3a0eb23..bd43d5b 100644\\n--- a/test/integration/test_interface.py\\n+++ b/test/integration/test_interface.py\\n@@ -152,6 +152,30 @@ def test_run_command(project_fixtures):\\n\\t assert err == ''\\n \\n \\n+def test_run_command_injection_error():\\n+\\tout, err, rc = run_command(\\n+\\t\\texecutable_cmd='whoami',\\n+\\t\\tcmdline_args=[';hostname'],\\n+\\t\\trunner_mode='subprocess',\\n+\\t)\\n+\\tassert rc == 1\\n+\\tassert \"usage: whoami\" in err or \"whoami: extra operand ‘;hostname’\" in err\\n+\\n+\\n+@pytest.mark.test_all_runtimes\\n+def test_run_command_injection_error_within_container(runtime):\\n+\\tout, err, rc = run_command(\\n+\\t\\texecutable_cmd='whoami',\\n+\\t\\tcmdline_args=[';hostname'],\\n+\\t\\trunner_mode='subprocess',\\n+\\t\\tprocess_isolation_executable=runtime,\\n+\\t\\tprocess_isolation=True,\\n+\\t\\tcontainer_image=defaults.default_container_image,\\n+\\t)\\n+\\tassert rc == 1\\n+\\tassert \"whoami: extra operand ';hostname'\" in err\\n+\\n+\\n @pytest.mark.test_all_runtimes\\n def test_run_ansible_command_within_container(project_fixtures, runtime):\\n\\t private_data_dir = project_fixtures / 'debug'\\ndiff --git a/test/unit/config/test_doc.py b/test/unit/config/test_doc.py\\nindex 2b6edc7..1058dac 100755\\n--- a/test/unit/config/test_doc.py\\n+++ b/test/unit/config/test_doc.py\\n@@ -52,7 +52,7 @@ def test_prepare_plugin_docs_command():\\n\\t plugin_names = ['copy', 'file']\\n\\t plugin_type = 'module'\\n\\t rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')\\n-\\texpected_command = [get_executable_path('ansible-doc'), '-s', '-t', 'module', '--playbook-dir', '/tmp/test', 'copy file']\\n+\\texpected_command = [get_executable_path('ansible-doc'), '-s', '-t', 'module', '--playbook-dir', '/tmp/test', 'copy', 'file']\\n\\t assert rc.command == expected_command\\n\\t assert rc.runner_mode == 'subprocess'\\n\\t assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\\n@@ -113,7 +113,7 @@ def test_prepare_plugin_docs_command_with_containerization(tmp_path, runtime, mo\\n\\t\\t '-s',\\n\\t\\t '-t', 'module',\\n\\t\\t '--playbook-dir', '/tmp/test',\\n-\\t\\t'copy '\\n+\\t\\t'copy',\\n\\t\\t 'file',\\n\\t ])",
         "def kill_container(self):\\n\\t\\t''\\n\\t\\tcontainer_name = self.config.container_name\\n\\t\\tif container_name:\\n\\t\\t\\tcontainer_cli = self.config.process_isolation_executable\\n\\t\\t\\tcmd = [container_cli, 'kill', container_name]\\n\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE)\\n\\t\\t\\t_, stderr = proc.communicate()\\n\\t\\t\\tif proc.returncode:\\n\\t\\t\\t\\tlogger.info('Error from {} kill {} command:\\n{}'.format(container_cli, container_name, stderr))\\n\\t\\t\\telse:\\n\\t\\t\\t\\tlogger.info(\"Killed container {}\".format(container_name))\\n\\t@classmethod",
         "def kill_container(self):\\n\\t\\t''\\n\\t\\tcontainer_name = self.config.container_name\\n\\t\\tif container_name:\\n\\t\\t\\tcontainer_cli = self.config.process_isolation_executable\\n\\t\\t\\tcmd = '{} kill {}'.format(container_cli, container_name)\\n\\t\\t\\tproc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\\n\\t\\t\\t_, stderr = proc.communicate()\\n\\t\\t\\tif proc.returncode:\\n\\t\\t\\t\\tlogger.info('Error from {} kill {} command:\\n{}'.format(container_cli, container_name, stderr))\\n\\t\\t\\telse:\\n\\t\\t\\t\\tlogger.info(\"Killed container {}\".format(container_name))\\n\\t@classmethod",
         "def kill_container(self)",
         null,
         "Alter the behavior of the kill_container function to introduce a Wrong Function Called with Same Parameters (WFCS) fault. The function should fail due to calling Popen with shell=True parameter, creating a command injection vulnerability.",
         "Alter the behavior of the kill_container function by calling Popen incorrectly. The function should fail due to insecure command execution configuration, enabling command injection attacks.",
         "Alter the behavior of the kill_container function by using an incorrect function call configuration.",
         "ansible",
         "3.8.0",
         "['test_doc.py', 'test_interface.py']",
         "https://github.com/ansible/ansible-runner",
         "WFCS"
        ],
        [
         "40",
         "issue:38167 add support for onyx version 3.6.6000 for onyx_linkagg (#38191)",
         null,
         null,
         "https://github.com/python/cpython/commit/72d42bd065d684d39bb9db005b4f92ec1d5b211e",
         "72d42bd065d684d39bb9db005b4f92ec1d5b211e",
         "Defectors",
         "diff --git a/lib/ansible/modules/network/onyx/onyx_linkagg.py b/lib/ansible/modules/network/onyx/onyx_linkagg.py\nindex 776d051677..acfd5b488c 100644\n--- a/lib/ansible/modules/network/onyx/onyx_linkagg.py\n+++ b/lib/ansible/modules/network/onyx/onyx_linkagg.py\n@@ -109,6 +109,7 @@ class OnyxLinkAggModule(BaseOnyxModule):\n     CHANNEL_GROUP = 'channel-group'\n     MLAG_PORT_CHANNEL = 'mlag-port-channel'\n     MLAG_CHANNEL_GROUP = 'mlag-channel-group'\n+    MLAG_SUMMARY = 'MLAG Port-Channel Summary'\n \n     LAG_TYPE = 'lag'\n     MLAG_TYPE = 'mlag'\n@@ -225,7 +226,21 @@ class OnyxLinkAggModule(BaseOnyxModule):\n \n     def _parse_port_channels_summary(self, lag_type, lag_summary):\n         if lag_type == self.MLAG_TYPE:\n-            lag_summary = lag_summary.get('MLAG Port-Channel Summary', {})\n+            if self._os_version >= self.ONYX_API_VERSION:\n+                found_summary = False\n+                for summary_item in lag_summary:\n+                    if self.MLAG_SUMMARY in summary_item:\n+                        lag_summary = summary_item[self.MLAG_SUMMARY]\n+                        if lag_summary:\n+                            lag_summary = lag_summary[0]\n+                        else:\n+                            lag_summary = dict()\n+                        found_summary = True\n+                        break\n+                if not found_summary:\n+                    lag_summary = dict()\n+            else:\n+                lag_summary = lag_summary.get(self.MLAG_SUMMARY, dict())\n         for lag_key, lag_data in iteritems(lag_summary):\n             lag_name, state = self._extract_lag_name(lag_key)\n             if not lag_name:\n@@ -240,6 +255,7 @@ class OnyxLinkAggModule(BaseOnyxModule):\n \n     def load_current_config(self):\n         self._current_config = dict()\n+        self._os_version = self._get_os_version()\n         lag_types = set([lag_obj['type'] for lag_obj in self._required_config])\n         for lag_type in lag_types:\n             if_type = self.IF_TYPE_MAP[lag_type]\ndiff --git a/test/units/modules/network/onyx/test_onyx_linkagg.py b/test/units/modules/network/onyx/test_onyx_linkagg.py\nindex 864e7dd030..ba7f970302 100644\n--- a/test/units/modules/network/onyx/test_onyx_linkagg.py\n+++ b/test/units/modules/network/onyx/test_onyx_linkagg.py\n@@ -26,15 +26,20 @@ class TestOnyxLinkaggModule(TestOnyxModule):\n         self.mock_load_config = patch(\n             'ansible.module_utils.network.onyx.onyx.load_config')\n         self.load_config = self.mock_load_config.start()\n+        self.mock_get_version = patch.object(\n+            onyx_linkagg.OnyxLinkAggModule, \"_get_os_version\")\n+        self.get_version = self.mock_get_version.start()\n \n     def tearDown(self):\n         super(TestOnyxLinkaggModule, self).tearDown()\n         self.mock_get_config.stop()\n         self.mock_load_config.stop()\n+        self.mock_get_version.stop()\n \n     def load_fixture(self, config_file):\n         self.get_config.return_value = load_fixture(config_file)\n         self.load_config.return_value = None\n+        self.get_version.return_value = \"3.6.5000\"\n \n     def load_port_channel_fixture(self):\n         config_file = 'onyx_port_channel_show.cfg'",
         "def load_current_config(self):\\n        self._current_config = dict()\\n        self._os_version = self._get_os_version()\\n        lag_types = set([lag_obj['type'] for lag_obj in self._required_config])\\n        for lag_type in lag_types:\\n            if_type = self.IF_TYPE_MAP[lag_type]\\n            lag_summary = self._get_port_channels(if_type)\\n            if lag_summary:\\n                self._parse_port_channels_summary(lag_type, lag_summary)",
         "def load_current_config(self):\\n        self._current_config = dict()\\n        lag_types = set([lag_obj['type'] for lag_obj in self._required_config])\\n        for lag_type in lag_types:\\n            if_type = self.IF_TYPE_MAP[lag_type]\\n            lag_summary = self._get_port_channels(if_type)\\n            if lag_summary:\\n                self._parse_port_channels_summary(lag_type, lag_summary)",
         "load_current_config",
         null,
         "Implement a bug in the load_current_config function to trigger a Missing variable assignment using an expression (MVAE) fault. The function should fail due to not initializing self._os_version with self._get_os_version().",
         "Introduce an error in the load_current_config function to simulate missing variable initialization using expression (MVIE). The function should fail due to not initializing the OS version variable.",
         "Introduce an error in the load_current_config function to simulate missing variable initialization using expression (MVIE).",
         "ansible",
         "2.7.0",
         "test_onyx_linkagg.py",
         "https://github.com/ansible/ansible",
         "MVAE"
        ],
        [
         "41",
         "Better info sourcing (#77511)\\n\\nTask is  authoritative\\n   also includes latest per loop info\\n   and fix tests",
         null,
         null,
         "https://github.com/python/cpython/commit/f2ab920822459a4b723273e43180f986cf13b3eb",
         "f2ab920822459a4b723273e43180f986cf13b3eb",
         "Defectors",
         "diff --git a/changelogs/fragments/better_info_sources.yml b/changelogs/fragments/better_info_sources.yml\nnew file mode 100644\nindex 0000000000..3b0cece2b1\n--- /dev/null\n+++ b/changelogs/fragments/better_info_sources.yml\n@@ -0,0 +1,2 @@\n+bugfixes:\n+  - action plugins now pass cannonical info to modules instead of 'temporary' info from play_context\ndiff --git a/lib/ansible/plugins/action/__init__.py b/lib/ansible/plugins/action/__init__.py\nindex 88ce93390b..7db6137805 100644\n--- a/lib/ansible/plugins/action/__init__.py\n+++ b/lib/ansible/plugins/action/__init__.py\n@@ -103,9 +103,9 @@ class ActionBase(ABC):\n \n         if self._task.async_val and not self._supports_async:\n             raise AnsibleActionFail('async is not supported for this task.')\n-        elif self._play_context.check_mode and not self._supports_check_mode:\n+        elif self._task.check_mode and not self._supports_check_mode:\n             raise AnsibleActionSkip('check mode is not supported for this task.')\n-        elif self._task.async_val and self._play_context.check_mode:\n+        elif self._task.async_val and self._task.check_mode:\n             raise AnsibleActionFail('check mode and async cannot be used on same task.')\n \n         # Error if invalid argument is passed\n@@ -395,6 +395,20 @@ class ActionBase(ABC):\n \n         return self.get_shell_option('admin_users', ['root'])\n \n+    def _get_remote_addr(self, tvars):\n+        ''' consistently get the 'remote_address' for the action plugin '''\n+        remote_addr = tvars.get('delegated_vars', {}).get('ansible_host', tvars.get('ansible_host', tvars.get('inventory_hostname', None)))\n+        for variation in ('remote_addr', 'host'):\n+            try:\n+                remote_addr = self._connection.get_option(variation)\n+            except KeyError:\n+                continue\n+            break\n+        else:\n+            # plugin does not have, fallback to play_context\n+            remote_addr = self._play_context.remote_addr\n+        return remote_addr\n+\n     def _get_remote_user(self):\n         ''' consistently get the 'remote_user' for the action plugin '''\n         # TODO: use 'current user running ansible' as fallback when moving away from play_context\n@@ -929,7 +943,7 @@ class ActionBase(ABC):\n             expanded = initial_fragment\n \n         if '..' in os.path.dirname(expanded).split('/'):\n-            raise AnsibleError(\"'%s' returned an invalid relative home directory path containing '..'\" % self._play_context.remote_addr)\n+            raise AnsibleError(\"'%s' returned an invalid relative home directory path containing '..'\" % self._get_remote_addr({}))\n \n         return expanded\n \n@@ -944,7 +958,7 @@ class ActionBase(ABC):\n     def _update_module_args(self, module_name, module_args, task_vars):\n \n         # set check mode in the module arguments, if required\n-        if self._play_context.check_mode:\n+        if self._task.check_mode:\n             if not self._supports_check_mode:\n                 raise AnsibleError(\"check mode is not supported for this operation\")\n             module_args['_ansible_check_mode'] = True\n@@ -953,13 +967,13 @@ class ActionBase(ABC):\n \n         # set no log in the module arguments, if required\n         no_target_syslog = C.config.get_config_value('DEFAULT_NO_TARGET_SYSLOG', variables=task_vars)\n-        module_args['_ansible_no_log'] = self._play_context.no_log or no_target_syslog\n+        module_args['_ansible_no_log'] = self._task.no_log or no_target_syslog\n \n         # set debug in the module arguments, if required\n         module_args['_ansible_debug'] = C.DEFAULT_DEBUG\n \n         # let module know we are in diff mode\n-        module_args['_ansible_diff'] = self._play_context.diff\n+        module_args['_ansible_diff'] = self._task.diff\n \n         # let module know our verbosity\n         module_args['_ansible_verbosity'] = display.verbosity\n@@ -1395,7 +1409,7 @@ class ActionBase(ABC):\n                 diff['after_header'] = u'dynamically generated'\n                 diff['after'] = source\n \n-        if self._play_context.no_log:\n+        if self._task.no_log:\n             if 'before' in diff:\n                 diff[\"before\"] = u\"\"\n             if 'after' in diff:\ndiff --git a/test/units/plugins/action/test_action.py b/test/units/plugins/action/test_action.py\nindex 0a50bdd465..d69f28df8a 100644\n--- a/test/units/plugins/action/test_action.py\n+++ b/test/units/plugins/action/test_action.py\n@@ -283,6 +283,9 @@ class TestActionBase(unittest.TestCase):\n         play_context.become = True\n         play_context.become_user = 'foo'\n \n+        mock_task.become = True\n+        mock_task.become_user = True\n+\n         # our test class\n         action_base = DerivedActionBase(\n             task=mock_task,\n@@ -654,6 +657,9 @@ class TestActionBase(unittest.TestCase):\n         mock_task = MagicMock()\n         mock_task.action = 'copy'\n         mock_task.args = dict(a=1, b=2, c=3)\n+        mock_task.diff = False\n+        mock_task.check_mode = False\n+        mock_task.no_log = False\n \n         # create a mock connection, so we don't actually try and connect to things\n         def build_module_command(env_string, shebang, cmd, arg_path=None):\n@@ -728,6 +734,8 @@ class TestActionBase(unittest.TestCase):\n \n         play_context.become = True\n         play_context.become_user = 'foo'\n+        mock_task.become = True\n+        mock_task.become_user = True\n         self.assertEqual(action_base._execute_module(), dict(_ansible_parsed=True, rc=0, stdout=\"ok\", stdout_lines=['ok']))\n \n         # test an invalid shebang return\n@@ -739,6 +747,7 @@ class TestActionBase(unittest.TestCase):\n         # test with check mode enabled, once with support for check\n         # mode and once with support disabled to raise an error\n         play_context.check_mode = True\n+        mock_task.check_mode = True\n         action_base._configure_module.return_value = ('new', '#!/usr/bin/python', 'this is the module data', 'path')\n         self.assertEqual(action_base._execute_module(), dict(_ansible_parsed=True, rc=0, stdout=\"ok\", stdout_lines=['ok']))\n         action_base._supports_check_mode = False\n@@ -777,6 +786,7 @@ class TestActionBase(unittest.TestCase):\n     def test__remote_expand_user_relative_pathing(self):\n         action_base = _action_base()\n         action_base._play_context.remote_addr = 'bar'\n+        action_base._connection.get_option.return_value = 'bar'\n         action_base._low_level_execute_command = MagicMock(return_value={'stdout': b'../home/user'})\n         action_base._connection._shell.join_path.return_value = '../home/user/foo'\n         with self.assertRaises(AnsibleError) as cm:",
         "def _update_module_args(self, module_name, module_args, task_vars):\\n        if self._task.check_mode:\\n            if not self._supports_check_mode:\\n                raise AnsibleError(\"check mode is not supported for this operation\")\\n            module_args['_ansible_check_mode'] = True\\n        else:\\n            module_args['_ansible_check_mode'] = False\\n        no_target_syslog = C.config.get_config_value('DEFAULT_NO_TARGET_SYSLOG', variables=task_vars)\\n        module_args['_ansible_no_log'] = self._task.no_log or no_target_syslog\\n        module_args['_ansible_debug'] = C.DEFAULT_DEBUG\\n        module_args['_ansible_diff'] = self._task.diff\\n        module_args['_ansible_verbosity'] = display.verbosity\\n        module_args['_ansible_version'] = __version__\\n        module_args['_ansible_module_name'] = module_name\\n        module_args['_ansible_syslog_facility'] = task_vars.get('ansible_syslog_facility', C.DEFAULT_SYSLOG_FACILITY)\\n        module_args['_ansible_selinux_special_fs'] = C.DEFAULT_SELINUX_SPECIAL_FS\\n        module_args['_ansible_string_conversion_action'] = C.STRING_CONVERSION_ACTION\\n        module_args['_ansible_socket'] = getattr(self._connection, 'socket_path')\\n        if not module_args['_ansible_socket']:\\n            module_args['_ansible_socket'] = task_vars.get('ansible_socket')\\n        module_args['_ansible_shell_executable'] = self._play_context.executable\\n        module_args['_ansible_keep_remote_files'] = C.DEFAULT_KEEP_REMOTE_FILES\\n        if self._is_become_unprivileged():  \\n            module_args['_ansible_tmpdir'] = None\\n        else:\\n            module_args['_ansible_tmpdir'] = self._connection._shell.tmpdir\\n        module_args['_ansible_remote_tmp'] = self.get_shell_option('remote_tmp', default='~/.ansible/tmp')",
         "def _update_module_args(self, module_name, module_args, task_vars):\\n        if self._play_context.check_mode:\\n            if not self._supports_check_mode:\\n                raise AnsibleError(\"check mode is not supported for this operation\")\\n            module_args['_ansible_check_mode'] = True\\n        else:\\n            module_args['_ansible_check_mode'] = False\\n        no_target_syslog = C.config.get_config_value('DEFAULT_NO_TARGET_SYSLOG', variables=task_vars)\\n        module_args['_ansible_no_log'] = self._play_context.no_log or no_target_syslog\\n        module_args['_ansible_debug'] = C.DEFAULT_DEBUG\\n        module_args['_ansible_diff'] = self._play_context.diff\\n        module_args['_ansible_verbosity'] = display.verbosity\\n        module_args['_ansible_version'] = __version__\\n        module_args['_ansible_module_name'] = module_name\\n        module_args['_ansible_syslog_facility'] = task_vars.get('ansible_syslog_facility', C.DEFAULT_SYSLOG_FACILITY)\\n        module_args['_ansible_selinux_special_fs'] = C.DEFAULT_SELINUX_SPECIAL_FS\\n        module_args['_ansible_string_conversion_action'] = C.STRING_CONVERSION_ACTION\\n        module_args['_ansible_socket'] = getattr(self._connection, 'socket_path')\\n        if not module_args['_ansible_socket']:\\n            module_args['_ansible_socket'] = task_vars.get('ansible_socket')\\n        module_args['_ansible_shell_executable'] = self._play_context.executable\\n        module_args['_ansible_keep_remote_files'] = C.DEFAULT_KEEP_REMOTE_FILES\\n        if self._is_become_unprivileged():  \\n            module_args['_ansible_tmpdir'] = None\\n        else:\\n            module_args['_ansible_tmpdir'] = self._connection._shell.tmpdir\\n        module_args['_ansible_remote_tmp'] = self.get_shell_option('remote_tmp', default='~/.ansible/tmp')",
         "_update_module_args",
         null,
         "To simulate incorrect attribute access, introduce a Wrong Variable Used in Parameter of Function Call (WPFV) fault. The function should fail due to changing self._task for check_mode and log attributes to self._play_context, causing incorrect module argument updates.",
         "Inject a bug in the _update_module_args function to trigger a Wrong Variable Used in Parameter of Function Call (WPFV) fault. The function should fail due to using self._play_context instead of self._task, causing incorrect attribute access.",
         "Inject a bug in the _update_module_args function to trigger a Wrong Variable Used in Parameter of Function Call (WPFV) fault.",
         "ansible",
         "3.8.0",
         "test_action.py",
         "https://github.com/ansible/ansible",
         "WPFV"
        ],
        [
         "42",
         "Pluribus Networks network cli terminal and cliconf plugins (#53735)",
         null,
         null,
         "https://github.com/python/cpython/commit/e2d92e82c40ecb245de1f09008031cc6588e3b7f",
         "e2d92e82c40ecb245de1f09008031cc6588e3b7f",
         "Defectors",
         "diff --git a/lib/ansible/module_utils/network/netvisor/netvisor.py b/lib/ansible/module_utils/network/netvisor/netvisor.py\nnew file mode 100644\nindex 0000000000..2d83a6a54e\n--- /dev/null\n+++ b/lib/ansible/module_utils/network/netvisor/netvisor.py\n@@ -0,0 +1,59 @@\n+# Copyright: (c) 2018, Pluribus Networks\n+# Simplified BSD License (see licenses/simplified_bsd.txt or https://opensource.org/licenses/BSD-2-Clause)\n+#\n+\n+from __future__ import absolute_import, division, print_function\n+__metaclass__ = type\n+\n+import json\n+from ansible.module_utils._text import to_text\n+from ansible.module_utils.network.common.utils import to_list, ComplexList\n+from ansible.module_utils.connection import Connection, ConnectionError\n+from ansible.module_utils.connection import exec_command\n+\n+\n+def get_connection(module):\n+    if hasattr(module, '_nvos_connection'):\n+        return module._nvos_connection\n+\n+    capabilities = get_capabilities(module)\n+    network_api = capabilities.get('network_api')\n+    if network_api == 'cliconf':\n+        module._nvos_connection = Connection(module._socket_path)\n+    else:\n+        module.fail_json(msg='Invalid connection type %s' % network_api)\n+\n+    return module._nvos_connection\n+\n+\n+def get_capabilities(module):\n+    if hasattr(module, '_nvos_capabilities'):\n+        return module._nvos_capabilities\n+    try:\n+        capabilities = Connection(module._socket_path).get_capabilities()\n+    except ConnectionError as exc:\n+        module.fail_json(msg=to_text(exc, errors='surrogate_then_replace'))\n+    module._nvos_capabilities = json.loads(capabilities)\n+    return module._nvos_capabilities\n+\n+\n+def to_commands(module, commands):\n+    spec = {\n+        'command': dict(key=True),\n+        'prompt': dict(),\n+        'answer': dict()\n+    }\n+    transform = ComplexList(spec, module)\n+    return transform(commands)\n+\n+\n+def run_commands(module, commands, check_rc=True):\n+    commands = to_commands(module, to_list(commands))\n+    for cmd in commands:\n+        cmd = module.jsonify(cmd)\n+        rc, out, err = exec_command(module, cmd)\n+        if check_rc and rc != 0:\n+            module.fail_json(msg=to_text(err, errors='surrogate_or_strict'), rc=rc)\n+        responses = (to_text(out, errors='surrogate_or_strict'))\n+\n+    return rc, out, err\ndiff --git a/lib/ansible/module_utils/network/netvisor/pn_nvos.py b/lib/ansible/module_utils/network/netvisor/pn_nvos.py\nindex 2bca029141..95da2fab4a 100644\n--- a/lib/ansible/module_utils/network/netvisor/pn_nvos.py\n+++ b/lib/ansible/module_utils/network/netvisor/pn_nvos.py\n@@ -6,7 +6,7 @@ from __future__ import absolute_import, division, print_function\n __metaclass__ = type\n \n \n-import shlex\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def pn_cli(module, switch=None, username=None, password=None, switch_local=None):\n@@ -16,7 +16,7 @@ def pn_cli(module, switch=None, username=None, password=None, switch_local=None)\n     :return: The cli string for further processing.\n     \"\"\"\n \n-    cli = '/usr/bin/cli --quiet -e --no-login-prompt '\n+    cli = ''\n \n     if username and password:\n         cli += '--user \"%s\":\"%s\" ' % (username, password)\n@@ -48,25 +48,19 @@ def run_cli(module, cli, state_map):\n     state = module.params['state']\n     command = state_map[state]\n \n-    cmd = shlex.split(cli)\n-    result, out, err = module.run_command(cmd)\n-\n-    remove_cmd = '/usr/bin/cli --quiet -e --no-login-prompt'\n+    result, out, err = run_commands(module, cli)\n \n     results = dict(\n-        command=' '.join(cmd).replace(remove_cmd, ''),\n-        msg=\"%s operation completed\" % command,\n+        command=cli,\n+        msg=\"%s operation completed\" % cli,\n         changed=True\n     )\n     # Response in JSON format\n     if result != 0:\n         module.exit_json(\n-            command=' '.join(cmd).replace(remove_cmd, ''),\n-            stderr=err.strip(),\n-            msg=\"%s operation failed\" % command,\n+            command=cli,\n+            msg=\"%s operation failed\" % cli,\n             changed=False\n         )\n \n-    if out:\n-        results['stdout'] = out.strip()\n     module.exit_json(**results)\ndiff --git a/lib/ansible/modules/network/netvisor/pn_access_list.py b/lib/ansible/modules/network/netvisor/pn_access_list.py\nindex c38a0f8c49..157247bfb7 100644\n--- a/lib/ansible/modules/network/netvisor/pn_access_list.py\n+++ b/lib/ansible/modules/network/netvisor/pn_access_list.py\n@@ -85,38 +85,29 @@ changed:\n   type: bool\n \"\"\"\n \n-import shlex\n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n     \"\"\"\n     This method checks for idempotency using the access-list-show command.\n-    If a list with given name exists, return ACC_LIST_EXISTS\n-    as True else False.\n+    If a list with given name exists, return True else False.\n     :param module: The Ansible module to fetch input parameters\n     :param cli: The CLI string\n-    :return Global Booleans: ACC_LIST_EXISTS\n     \"\"\"\n     list_name = module.params['pn_name']\n \n-    show = cli + \\\n-        ' access-list-show format name no-show-headers'\n-    show = shlex.split(show)\n-    out = module.run_command(show)[1]\n+    cli += ' access-list-show format name no-show-headers'\n+    out = run_commands(module, cli)\n \n-    out = out.split()\n-    # Global flags\n-    global ACC_LIST_EXISTS\n-\n-    ACC_LIST_EXISTS = True if list_name in out else False\n+    return True if list_name in out else False\n \n \n def main():\n     \"\"\" This section is for arguments parsing \"\"\"\n \n-    global state_map\n     state_map = dict(\n         present='access-list-create',\n         absent='access-list-delete',\n@@ -148,7 +139,7 @@ def main():\n     # Building the CLI command string\n     cli = pn_cli(module, cliswitch)\n \n-    check_cli(module, cli)\n+    ACC_LIST_EXISTS = check_cli(module, cli)\n     cli += ' %s name %s ' % (command, list_name)\n \n     if command == 'access-list-delete':\ndiff --git a/lib/ansible/modules/network/netvisor/pn_access_list_ip.py b/lib/ansible/modules/network/netvisor/pn_access_list_ip.py\nindex 31fbdcac30..b6ca77fb40 100644\n--- a/lib/ansible/modules/network/netvisor/pn_access_list_ip.py\n+++ b/lib/ansible/modules/network/netvisor/pn_access_list_ip.py\n@@ -81,6 +81,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -92,19 +93,28 @@ def check_cli(module, cli):\n     \"\"\"\n     name = module.params['pn_name']\n     ip = module.params['pn_ip']\n-    cli += ' access-list-ip-show name %s format ip no-show-headers' % name\n+    clicopy = cli\n \n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    cli += ' access-list-show name %s no-show-headers ' % name\n+    out = run_commands(module, cli)[1]\n \n-    out = out.split()\n+    if name not in out:\n+        module.fail_json(\n+            failed=True,\n+            msg='access-list with name %s does not exist' % name\n+        )\n \n+    cli = clicopy\n+    cli += ' access-list-ip-show name %s format ip no-show-headers' % name\n+\n+    out = run_commands(module, cli)[1]\n+    out = out.split()\n     return True if ip in out else False\n \n \n def main():\n     \"\"\" This section is for arguments parsing \"\"\"\n \n-    global state_map\n     state_map = dict(\n         present='access-list-ip-add',\n         absent='access-list-ip-remove',\ndiff --git a/lib/ansible/modules/network/netvisor/pn_admin_service.py b/lib/ansible/modules/network/netvisor/pn_admin_service.py\nindex f615205d81..a7736790eb 100644\n--- a/lib/ansible/modules/network/netvisor/pn_admin_service.py\n+++ b/lib/ansible/modules/network/netvisor/pn_admin_service.py\n@@ -135,7 +135,6 @@ from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, booleanArgs, r\n def main():\n     \"\"\" This section is for arguments parsing \"\"\"\n \n-    global state_map\n     state_map = dict(\n         update='admin-service-modify'\n     )\ndiff --git a/lib/ansible/modules/network/netvisor/pn_admin_syslog.py b/lib/ansible/modules/network/netvisor/pn_admin_syslog.py\nindex 19541e40d9..a9ce53bcad 100644\n--- a/lib/ansible/modules/network/netvisor/pn_admin_syslog.py\n+++ b/lib/ansible/modules/network/netvisor/pn_admin_syslog.py\n@@ -73,7 +73,7 @@ options:\n EXAMPLES = \"\"\"\n - name: admin-syslog functionality\n   pn_admin_syslog:\n-    pn_cliswitch: sw01\n+    pn_cliswitch: \"sw01\"\n     state: \"absent\"\n     pn_name: \"foo\"\n     pn_scope: \"local\"\n@@ -116,6 +116,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -129,7 +130,7 @@ def check_cli(module, cli):\n     name = module.params['pn_name']\n \n     cli += ' admin-syslog-show format name no-show-headers'\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_connection_stats_settings.py b/lib/ansible/modules/network/netvisor/pn_connection_stats_settings.py\nindex 27e1d46ffc..bd2a4ad19c 100644\n--- a/lib/ansible/modules/network/netvisor/pn_connection_stats_settings.py\n+++ b/lib/ansible/modules/network/netvisor/pn_connection_stats_settings.py\n@@ -140,8 +140,7 @@ stdout:\n   returned: always\n   type: list\n stderr:\n-  description: set of error responses from the connection-stats-settings\n-               command.\n+  description: set of error responses from the connection-stats-settings command.\n   returned: on error\n   type: list\n changed:\ndiff --git a/lib/ansible/modules/network/netvisor/pn_cpu_class.py b/lib/ansible/modules/network/netvisor/pn_cpu_class.py\nindex a60a744101..3d1376e3b0 100644\n--- a/lib/ansible/modules/network/netvisor/pn_cpu_class.py\n+++ b/lib/ansible/modules/network/netvisor/pn_cpu_class.py\n@@ -100,6 +100,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -110,9 +111,21 @@ def check_cli(module, cli):\n     :param cli: The CLI string\n     \"\"\"\n     name = module.params['pn_name']\n+    clicopy = cli\n \n-    cli += ' cpu-class-show format name no-show-headers'\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    cli += ' system-settings-show format cpu-class-enable no-show-headers'\n+    out = run_commands(module, cli)[1]\n+    out = out.split()\n+\n+    if 'on' not in out:\n+        module.fail_json(\n+            failed=True,\n+            msg='Enable CPU class before creating or deleting'\n+        )\n+\n+    cli = clicopy\n+    cli += ' cpu-class-show name %s format name no-show-headers' % name\n+    out = run_commands(module, cli)[1]\n     out = out.split()\n \n     return True if name in out else False\n@@ -121,7 +134,6 @@ def check_cli(module, cli):\n def main():\n     \"\"\" This section is for arguments parsing \"\"\"\n \n-    global state_map\n     state_map = dict(\n         present='cpu-class-create',\n         absent='cpu-class-delete',\ndiff --git a/lib/ansible/modules/network/netvisor/pn_dhcp_filter.py b/lib/ansible/modules/network/netvisor/pn_dhcp_filter.py\nindex 131bb137e8..b13e779422 100644\n--- a/lib/ansible/modules/network/netvisor/pn_dhcp_filter.py\n+++ b/lib/ansible/modules/network/netvisor/pn_dhcp_filter.py\n@@ -88,6 +88,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -100,7 +101,7 @@ def check_cli(module, cli):\n     user_name = module.params['pn_name']\n \n     cli += ' dhcp-filter-show format name no-show-headers'\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_dscp_map.py b/lib/ansible/modules/network/netvisor/pn_dscp_map.py\nindex 9601935d58..c38ddaa32b 100644\n--- a/lib/ansible/modules/network/netvisor/pn_dscp_map.py\n+++ b/lib/ansible/modules/network/netvisor/pn_dscp_map.py\n@@ -80,6 +80,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -92,17 +93,16 @@ def check_cli(module, cli):\n     name = module.params['pn_name']\n \n     cli += ' dscp-map-show name %s format name no-show-headers' % name\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \n-    return True if name in out else False\n+    return True if name in out[-1] else False\n \n \n def main():\n     \"\"\" This section is for arguments parsing \"\"\"\n \n-    global state_map\n     state_map = dict(\n         present='dscp-map-create',\n         absent='dscp-map-delete'\ndiff --git a/lib/ansible/modules/network/netvisor/pn_dscp_map_pri_map.py b/lib/ansible/modules/network/netvisor/pn_dscp_map_pri_map.py\nindex a0b45c4b11..d2b9f20a0e 100644\n--- a/lib/ansible/modules/network/netvisor/pn_dscp_map_pri_map.py\n+++ b/lib/ansible/modules/network/netvisor/pn_dscp_map_pri_map.py\n@@ -52,7 +52,7 @@ options:\n EXAMPLES = \"\"\"\n - name: dscp map pri map modify\n   pn_dscp_map_pri_map:\n-    pn_cliswitch: \"sw01\"\n+    pn_cliswitch: 'sw01'\n     state: 'update'\n     pn_name: 'foo'\n     pn_pri: '0'\n@@ -60,7 +60,7 @@ EXAMPLES = \"\"\"\n \n - name: dscp map pri map modify\n   pn_dscp_map_pri_map:\n-    pn_cliswitch: \"sw01\"\n+    pn_cliswitch: 'sw01'\n     state: 'update'\n     pn_name: 'foo'\n     pn_pri: '1'\n@@ -88,6 +88,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -100,11 +101,11 @@ def check_cli(module, cli):\n     name = module.params['pn_name']\n \n     cli += ' dscp-map-show name %s format name no-show-headers' % name\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \n-    return True if name in out else False\n+    return True if name in out[-1] else False\n \n \n def main():\ndiff --git a/lib/ansible/modules/network/netvisor/pn_port_config.py b/lib/ansible/modules/network/netvisor/pn_port_config.py\nindex 5a87efa2a9..87e1baebb0 100644\n--- a/lib/ansible/modules/network/netvisor/pn_port_config.py\n+++ b/lib/ansible/modules/network/netvisor/pn_port_config.py\n@@ -208,6 +208,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli, booleanArgs\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -220,11 +221,11 @@ def check_cli(module, cli):\n     name = module.params['pn_dscp_map']\n \n     cli += ' dscp-map-show name %s format name no-show-headers' % name\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \n-    return True if name in out else False\n+    return True if name in out[-1] else False\n \n \n def main():\ndiff --git a/lib/ansible/modules/network/netvisor/pn_port_cos_bw.py b/lib/ansible/modules/network/netvisor/pn_port_cos_bw.py\nindex fde12e9492..19255d8d75 100644\n--- a/lib/ansible/modules/network/netvisor/pn_port_cos_bw.py\n+++ b/lib/ansible/modules/network/netvisor/pn_port_cos_bw.py\n@@ -74,6 +74,7 @@ EXAMPLES = \"\"\"\n     state: \"update\"\n     pn_port: \"all\"\n     pn_cos: \"0\"\n+    pn_weight: \"priority\"\n \"\"\"\n \n RETURN = \"\"\"\ndiff --git a/lib/ansible/modules/network/netvisor/pn_prefix_list_network.py b/lib/ansible/modules/network/netvisor/pn_prefix_list_network.py\nindex f31ccb08b1..17ef7fa838 100644\n--- a/lib/ansible/modules/network/netvisor/pn_prefix_list_network.py\n+++ b/lib/ansible/modules/network/netvisor/pn_prefix_list_network.py\n@@ -88,6 +88,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -101,10 +102,10 @@ def check_cli(module, cli):\n     network = module.params['pn_network']\n     show = cli\n \n-    cli += ' prefix-list-show name %s format name no-show-headers' % name\n-    rc, out, err = module.run_command(cli, use_unsafe_shell=True)\n+    cli += ' prefix-list-show format name no-show-headers'\n+    out = run_commands(module, cli)[1]\n \n-    if not out:\n+    if name not in out.split()[-1]:\n         module.fail_json(\n             failed=True,\n             msg='Prefix list with name %s does not exists' % name\n@@ -112,7 +113,7 @@ def check_cli(module, cli):\n \n     cli = show\n     cli += ' prefix-list-network-show name %s format network no-show-headers' % name\n-    out = module.run_command(cli, use_unsafe_shell=True)[1]\n+    rc, out, err = run_commands(module, cli)\n \n     if out:\n         out = out.split()[1]\ndiff --git a/lib/ansible/modules/network/netvisor/pn_role.py b/lib/ansible/modules/network/netvisor/pn_role.py\nindex 4feb3dadac..44fbb20a87 100644\n--- a/lib/ansible/modules/network/netvisor/pn_role.py\n+++ b/lib/ansible/modules/network/netvisor/pn_role.py\n@@ -118,6 +118,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli, booleanArgs\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -130,7 +131,7 @@ def check_cli(module, cli):\n     role_name = module.params['pn_name']\n \n     cli += ' role-show format name no-show-headers'\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_snmp_community.py b/lib/ansible/modules/network/netvisor/pn_snmp_community.py\nindex ab17869ffb..f74f539718 100644\n--- a/lib/ansible/modules/network/netvisor/pn_snmp_community.py\n+++ b/lib/ansible/modules/network/netvisor/pn_snmp_community.py\n@@ -87,6 +87,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -99,7 +100,7 @@ def check_cli(module, cli):\n     comm_str = module.params['pn_community_string']\n \n     cli += ' snmp-community-show format community-string no-show-headers'\n-    out = module.run_command(cli.split(), use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_snmp_trap_sink.py b/lib/ansible/modules/network/netvisor/pn_snmp_trap_sink.py\nindex c262eca22e..84a3dec70c 100644\n--- a/lib/ansible/modules/network/netvisor/pn_snmp_trap_sink.py\n+++ b/lib/ansible/modules/network/netvisor/pn_snmp_trap_sink.py\n@@ -93,6 +93,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -107,14 +108,14 @@ def check_cli(module, cli):\n \n     show = cli\n     cli += ' snmp-community-show format community-string no-show-headers'\n-    rc, out, err = module.run_command(cli, use_unsafe_shell=True)\n+    rc, out, err = run_commands(module, cli)\n \n     out = out.split()\n \n     if community in out:\n         cli = show\n         cli += ' snmp-trap-sink-show community %s format type,dest-host no-show-headers' % community\n-        rc, out, err = module.run_command(cli, use_unsafe_shell=True)\n+        rc, out, err = run_commands(module, cli)\n \n         out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_snmp_vacm.py b/lib/ansible/modules/network/netvisor/pn_snmp_vacm.py\nindex d49c07027e..72231d9cfb 100644\n--- a/lib/ansible/modules/network/netvisor/pn_snmp_vacm.py\n+++ b/lib/ansible/modules/network/netvisor/pn_snmp_vacm.py\n@@ -57,20 +57,23 @@ options:\n \"\"\"\n \n EXAMPLES = \"\"\"\n-- name: snmp vacm functionality\n+- name: create snmp vacm\n   pn_snmp_vacm:\n+    pn_cliswitch: \"sw01\"\n     state: \"present\"\n     pn_user_name: \"foo\"\n     pn_user_type: \"rouser\"\n \n-- name: snmp vacm functionality\n+- name: update snmp vacm\n   pn_snmp_vacm:\n+    pn_cliswitch: \"sw01\"\n     state: \"update\"\n     pn_user_name: \"foo\"\n     pn_user_type: \"rwuser\"\n \n-- name: snmp vacm functionality\n+- name: delete snmp vacm\n   pn_snmp_vacm:\n+    pn_cliswitch: \"sw01\"\n     state: \"absent\"\n     pn_user_name: \"foo\"\n \"\"\"\n@@ -97,6 +100,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli, booleanArgs\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -110,7 +114,7 @@ def check_cli(module, cli):\n     show = cli\n \n     cli += ' snmp-user-show user-name %s format user-name no-show-headers' % user_name\n-    rc, out, err = module.run_command(cli, use_unsafe_shell=True)\n+    rc, out, err = run_commands(module, cli)\n     if out:\n         pass\n     else:\n@@ -118,7 +122,7 @@ def check_cli(module, cli):\n \n     cli = show\n     cli += ' snmp-vacm-show format user-name no-show-headers'\n-    out = module.run_command(cli, use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_user.py b/lib/ansible/modules/network/netvisor/pn_user.py\nindex 954b7cf65a..53d7ac971d 100644\n--- a/lib/ansible/modules/network/netvisor/pn_user.py\n+++ b/lib/ansible/modules/network/netvisor/pn_user.py\n@@ -96,6 +96,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -108,7 +109,7 @@ def check_cli(module, cli):\n     name = module.params['pn_name']\n \n     cli += ' user-show format name no-show-headers'\n-    out = module.run_command(cli, use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n \n     out = out.split()\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_vrouter_bgp_network.py b/lib/ansible/modules/network/netvisor/pn_vrouter_bgp_network.py\nindex c9522debd5..c2bb804e34 100644\n--- a/lib/ansible/modules/network/netvisor/pn_vrouter_bgp_network.py\n+++ b/lib/ansible/modules/network/netvisor/pn_vrouter_bgp_network.py\n@@ -53,7 +53,7 @@ options:\n EXAMPLES = \"\"\"\n - name:  Add network to bgp\n   pn_vrouter_bgp_network:\n-    pn_cliswitch: \"{{ inventory_hostname }}\"\n+    pn_cliswitch: \"sw01\"\n     state: \"present\"\n     pn_vrouter_name: \"foo-vrouter\"\n     pn_network: '10.10.10.10'\n@@ -61,7 +61,7 @@ EXAMPLES = \"\"\"\n \n - name:  Remove network from bgp\n   pn_vrouter_bgp_network:\n-    pn_cliswitch: \"{{ inventory_hostname }}\"\n+    pn_cliswitch: \"sw01\"\n     state: \"absent\"\n     pn_vrouter_name: \"foo-vrouter\"\n     pn_network: '10.10.10.10'\n@@ -89,6 +89,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -103,14 +104,14 @@ def check_cli(module, cli):\n \n     show = cli\n     cli += ' vrouter-show name %s format name no-show-headers' % name\n-    rc, out, err = module.run_command(cli, use_unsafe_shell=True)\n+    rc, out, err = run_commands(module, cli)\n     VROUTER_EXISTS = '' if out else None\n \n     cli = show\n     cli += ' vrouter-bgp-network-show vrouter-name %s network %s format network no-show-headers' % (name, network)\n-    out = module.run_command(cli, use_unsafe_shell=True)[1]\n-\n-    NETWORK_EXISTS = True if network in out else False\n+    out = run_commands(module, cli)[1]\n+    out = out.split()\n+    NETWORK_EXISTS = True if network in out[-1] else False\n \n     return NETWORK_EXISTS, VROUTER_EXISTS\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_vrouter_interface_ip.py b/lib/ansible/modules/network/netvisor/pn_vrouter_interface_ip.py\nindex 0ed4c3059d..7c6aa08d30 100644\n--- a/lib/ansible/modules/network/netvisor/pn_vrouter_interface_ip.py\n+++ b/lib/ansible/modules/network/netvisor/pn_vrouter_interface_ip.py\n@@ -105,6 +105,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -130,19 +131,19 @@ def check_cli(module, cli):\n     nic_str = module.params['pn_nic']\n \n     # Check for vRouter\n-    check_vrouter = cli + ' vrouter-show format name no-show-headers '\n-    out = module.run_command(check_vrouter, use_unsafe_shell=True)[1]\n+    check_vrouter = cli + ' vrouter-show name %s format name no-show-headers ' % vrouter_name\n+    out = run_commands(module, check_vrouter)[1]\n     out = out.split()\n \n-    VROUTER_EXISTS = True if vrouter_name in out else False\n+    VROUTER_EXISTS = True if vrouter_name in out[-1] else False\n \n     if interface_ip:\n         # Check for interface and VRRP and fetch nic for VRRP\n         show = cli + ' vrouter-interface-show vrouter-name %s ' % vrouter_name\n         show += 'ip2 %s format ip2,nic no-show-headers' % interface_ip\n-        out = module.run_command(show, use_unsafe_shell=True)[1]\n+        out = run_commands(module, show)[1]\n \n-        if out and interface_ip in out.split(' ')[1]:\n+        if out and interface_ip in out.split(' ')[-2]:\n             INTERFACE_EXISTS = True\n         else:\n             INTERFACE_EXISTS = False\n@@ -151,7 +152,8 @@ def check_cli(module, cli):\n         # Check for nic\n         show = cli + ' vrouter-interface-show vrouter-name %s ' % vrouter_name\n         show += ' format nic no-show-headers'\n-        out = module.run_command(show, use_unsafe_shell=True)[1]\n+        out = run_commands(module, show)[1]\n+        out = out.split()\n \n         NIC_EXISTS = True if nic_str in out else False\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_vrouter_ospf6.py b/lib/ansible/modules/network/netvisor/pn_vrouter_ospf6.py\nindex b5170ad3da..094123ba30 100644\n--- a/lib/ansible/modules/network/netvisor/pn_vrouter_ospf6.py\n+++ b/lib/ansible/modules/network/netvisor/pn_vrouter_ospf6.py\n@@ -88,6 +88,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -109,7 +110,7 @@ def check_cli(module, cli):\n \n     # Check for vRouter\n     check_vrouter = cli + ' vrouter-show format name no-show-headers '\n-    out = module.run_command(check_vrouter, use_unsafe_shell=True)[1]\n+    out = run_commands(module, check_vrouter)[1]\n     out = out.split()\n \n     VROUTER_EXISTS = True if vrouter_name in out else False\n@@ -117,7 +118,7 @@ def check_cli(module, cli):\n     if nic_str:\n         # Check for nic\n         show = cli + ' vrouter-ospf6-show vrouter-name %s format nic no-show-headers' % vrouter_name\n-        out = module.run_command(show, use_unsafe_shell=True)[1]\n+        out = run_commands(module, show)[1]\n \n         NIC_EXISTS = True if nic_str in out else False\n \ndiff --git a/lib/ansible/modules/network/netvisor/pn_vrouter_pim_config.py b/lib/ansible/modules/network/netvisor/pn_vrouter_pim_config.py\nindex 71627e65cb..a348daadd5 100644\n--- a/lib/ansible/modules/network/netvisor/pn_vrouter_pim_config.py\n+++ b/lib/ansible/modules/network/netvisor/pn_vrouter_pim_config.py\n@@ -84,6 +84,7 @@ changed:\n \n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils.network.netvisor.pn_nvos import pn_cli, run_cli\n+from ansible.module_utils.network.netvisor.netvisor import run_commands\n \n \n def check_cli(module, cli):\n@@ -96,16 +97,18 @@ def check_cli(module, cli):\n     name = module.params['pn_vrouter_name']\n \n     show = cli\n-    cli += 'vrouter-show name %s format name no-show-headers ' % name\n-    out = module.run_command(cli, use_unsafe_shell=True)\n-    if out:\n+    cli += ' vrouter-show name %s format name no-show-headers ' % name\n+    out = run_commands(module, cli)[1]\n+    out = out.split()\n+    if out[-1] == name:\n         pass\n     else:\n         return False\n \n     cli = show\n     cli += ' vrouter-show name %s format proto-multi no-show-headers' % name\n-    out = module.run_command(cli, use_unsafe_shell=True)[1]\n+    out = run_commands(module, cli)[1]\n+    out = out.split()\n \n     return True if 'none' not in out else False\n \ndiff --git a/lib/ansible/plugins/cliconf/netvisor.py b/lib/ansible/plugins/cliconf/netvisor.py\nnew file mode 100644\nindex 0000000000..1b37b6950e\n--- /dev/null\n+++ b/lib/ansible/plugins/cliconf/netvisor.py\n@@ -0,0 +1,66 @@\n+#\n+# (c) 2016 Red Hat Inc.\n+#\n+# This file is part of Ansible\n+#\n+# Ansible is free software: you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation, either version 3 of the License, or\n+# (at your option) any later version.\n+#\n+# Ansible is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n+#\n+from __future__ import (absolute_import, division, print_function)\n+__metaclass__ = type\n+\n+DOCUMENTATION = \"\"\"\n+---\n+cliconf: netvisor\n+short_description: Use netvisor cliconf to run command on Pluribus netvisor platform\n+description:\n+  - This netvisor plugin provides low level abstraction apis for\n+    sending and receiving CLI commands from Pluribus netvisor devices.\n+version_added: 2.8\n+\"\"\"\n+\n+import json\n+from ansible.plugins.cliconf import CliconfBase\n+\n+\n+class Cliconf(CliconfBase):\n+\n+    def get(self, command=None, prompt=None, answer=None, sendonly=False, output=None, check_all=False):\n+        if not command:\n+            raise ValueError('must provide value of command to execute')\n+        if output:\n+            raise ValueError(\"'output' value %s is not supported for get\" % output)\n+\n+        return self.send_command(command=command, prompt=prompt, answer=answer, sendonly=sendonly, check_all=check_all)\n+\n+    def get_option_values(self):\n+        return {\n+            'format': ['text'],\n+            'diff_match': ['line', 'strict', 'exact', 'none'],\n+            'diff_replace': ['line', 'block'],\n+            'output': []\n+        }\n+\n+    def get_capabilities(self):\n+        result = dict()\n+        result['rpc'] = self.get_base_rpc()\n+        result['network_api'] = 'cliconf'\n+        result['device_info'] = self.get_device_info()\n+        result.update(self.get_option_values())\n+        return json.dumps(result)\n+\n+    def get_device_info(self):\n+        device_info = {}\n+        device_info['network_os'] = 'netvisor'\n+\n+        return device_info\ndiff --git a/lib/ansible/plugins/terminal/netvisor.py b/lib/ansible/plugins/terminal/netvisor.py\nnew file mode 100644\nindex 0000000000..27dffb5947\n--- /dev/null\n+++ b/lib/ansible/plugins/terminal/netvisor.py\n@@ -0,0 +1,39 @@\n+#\n+# (c) 2016 Red Hat Inc.\n+#\n+# This file is part of Ansible\n+#\n+# Ansible is free software: you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation, either version 3 of the License, or\n+# (at your option) any later version.\n+#\n+# Ansible is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n+#\n+from __future__ import (absolute_import, division, print_functi",
         "def main():\\n    state_map = dict(\\n        present='access-list-create',\\n        absent='access-list-delete',\\n    )\\n    module = AnsibleModule(\\n        argument_spec=dict(\\n            pn_cliswitch=dict(required=False, type='str'),\\n            state=dict(required=True, type='str',\\n                       choices=state_map.keys()),\\n            pn_name=dict(required=False, type='str'),\\n            pn_scope=dict(required=False, type='str',\\n                          choices=['local', 'fabric']),\\n        ),\\n        required_if=(\\n            [\"state\", \"present\", [\"pn_name\", \"pn_scope\"]],\\n            [\"state\", \"absent\", [\"pn_name\"]],\\n        ),\\n    )\\n    cliswitch = module.params['pn_cliswitch']\\n    state = module.params['state']\\n    list_name = module.params['pn_name']\\n    scope = module.params['pn_scope']\\n    command = state_map[state]\\n    cli = pn_cli(module, cliswitch)\\n    ACC_LIST_EXISTS = check_cli(module, cli)\\n    cli += ' %s name %s ' % (command, list_name)\\n    if command == 'access-list-delete':\\n        if ACC_LIST_EXISTS is False:\\n            module.exit_json(\\n                skipped=True,\\n                msg='access-list with name %s does not exist' % list_name\\n            )\\n    else:\\n        if command == 'access-list-create':\\n            if ACC_LIST_EXISTS is True:\\n                module.exit_json(\\n                    skipped=True,\\n                    msg='access list with name %s already exists' % list_name\\n                )\\n        cli += ' scope %s ' % scope\\n    run_cli(module, cli, state_map)",
         "def main():\\n    global state_map\\n    state_map = dict(\\n        present='access-list-create',\\n        absent='access-list-delete',\\n    )\\n    module = AnsibleModule(\\n        argument_spec=dict(\\n            pn_cliswitch=dict(required=False, type='str'),\\n            state=dict(required=True, type='str',\\n                       choices=state_map.keys()),\\n            pn_name=dict(required=False, type='str'),\\n            pn_scope=dict(required=False, type='str',\\n                          choices=['local', 'fabric']),\\n        ),\\n        required_if=(\\n            [\"state\", \"present\", [\"pn_name\", \"pn_scope\"]],\\n            [\"state\", \"absent\", [\"pn_name\"]],\\n        ),\\n    )\\n    cliswitch = module.params['pn_cliswitch']\\n    state = module.params['state']\\n    list_name = module.params['pn_name']\\n    scope = module.params['pn_scope']\\n    command = state_map[state]\\n    cli = pn_cli(module, cliswitch)\\n    check_cli(module, cli)\\n    cli += ' %s name %s ' % (command, list_name)\\n    if command == 'access-list-delete':\\n        if ACC_LIST_EXISTS is False:\\n            module.exit_json(\\n                skipped=True,\\n                msg='access-list with name %s does not exist' % list_name\\n            )\\n    else:\\n        if command == 'access-list-create':\\n            if ACC_LIST_EXISTS is True:\\n                module.exit_json(\\n                    skipped=True,\\n                    msg='access list with name %s already exists' % list_name\\n                )\\n        cli += ' scope %s ' % scope\\n    run_cli(module, cli, state_map)",
         "main",
         null,
         "Trigger a Missing variable assignment using a value (MVAV) fault within the main function by not storing the return value of check_cli in the ACC_LIST_EXISTS variable, potentially causing undefined variable access.",
         "Implement a bug in the main function to trigger a MVAV fault and to induce incorrect variable initialization. The function should fail due to not assigning the check_cli result to ACC_LIST_EXISTS variable.",
         "Implement a bug in the main function to trigger a MVAV fault and to induce incorrect variable initialization.",
         "ansible",
         "2.7.0",
         "test_pn_vflow_table_profile.py",
         "https://github.com/ansible/ansible",
         "MVAV"
        ],
        [
         "43",
         "When no pool quantity is set, then do not set quantity to 1 (#66807)\\n\\n  default value 1. When more quantities are required, then\\n  candlepin server can automatically choose correct minimal\\n  value.",
         null,
         null,
         "https://github.com/python/cpython/commit/6f1bb37feb81acd99157f5ba0933fecd747015a2",
         "6f1bb37feb81acd99157f5ba0933fecd747015a2",
         "BugsInPy",
         "diff --git a/lib/ansible/modules/packaging/os/redhat_subscription.py b/lib/ansible/modules/packaging/os/redhat_subscription.py\\nindex bc0bcc3ee7..d3cca7beb0 100644\\n--- a/lib/ansible/modules/packaging/os/redhat_subscription.py\\n+++ b/lib/ansible/modules/packaging/os/redhat_subscription.py\\n@@ -515,7 +515,9 @@ class Rhsm(RegistrationBase):\\n \\n\\t\\t for pool_id, quantity in sorted(pool_ids.items()):\\n\\t\\t\\t if pool_id in available_pool_ids:\\n-\\t\\t\\t\\targs = [SUBMAN_CMD, 'attach', '--pool', pool_id, '--quantity', quantity]\\n+\\t\\t\\t\\targs = [SUBMAN_CMD, 'attach', '--pool', pool_id]\\n+\\t\\t\\t\\tif quantity is not None:\\n+\\t\\t\\t\\t\\targs.extend(['--quantity', to_native(quantity)])\\n\\t\\t\\t\\t rc, stderr, stdout = self.module.run_command(args, check_rc=True)\\n\\t\\t\\t else:\\n\\t\\t\\t\\t self.module.fail_json(msg='Pool ID: %s not in list of available pools' % pool_id)\\n@@ -839,8 +841,8 @@ def main():\\n\\t\\t\\t\\t module.fail_json(msg='Unable to parse pool_ids option.')\\n\\t\\t\\t pool_id, quantity = list(value.items())[0]\\n\\t\\t else:\\n-\\t\\t\\tpool_id, quantity = value, 1\\n-\\t\\tpool_ids[pool_id] = str(quantity)\\n+\\t\\t\\tpool_id, quantity = value, None\\n+\\t\\tpool_ids[pool_id] = quantity\\n\\t consumer_type = module.params[\"consumer_type\"]\\n\\t consumer_name = module.params[\"consumer_name\"]\\n\\t consumer_id = module.params[\"consumer_id\"]\\n",
         "def subscribe_by_pool_ids(self, pool_ids):\\n\\t\\tavailable_pools = RhsmPools(self.module)\\n\\t\\tavailable_pool_ids = [p.get_pool_id() for p in available_pools]\\n\\t\\tfor pool_id, quantity in sorted(pool_ids.items()):\\n\\t\\t\\tif pool_id in available_pool_ids:\\n\\t\\t\\t\\targs = [SUBMAN_CMD, 'attach', '--pool', pool_id]\\n\\t\\t\\t\\tif quantity is not None:\\n\\t\\t\\t\\t\\targs.extend(['--quantity', to_native(quantity)])\\n\\t\\t\\t\\trc, stderr, stdout = self.module.run_command(args, check_rc=True)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.module.fail_json(msg='Pool ID: %s not in list of available pools' % pool_id)\\n\\t\\treturn pool_ids",
         "def subscribe_by_pool_ids(self, pool_ids):\\n\\t\\tavailable_pools = RhsmPools(self.module)\\n\\t\\tavailable_pool_ids = [p.get_pool_id() for p in available_pools]\\n\\t\\tfor pool_id, quantity in sorted(pool_ids.items()):\\n\\t\\t\\tif pool_id in available_pool_ids:\\n\\t\\t\\t\\targs = [SUBMAN_CMD, 'attach', '--pool', pool_id, '--quantity', quantity]\\n\\t\\t\\t\\trc, stderr, stdout = self.module.run_command(args, check_rc=True)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.module.fail_json(msg='Pool ID: %s not in list of available pools' % pool_id)\\n\\t\\treturn pool_ids",
         "def subscribe_by_pool_ids(self, pool_ids)",
         null,
         "Inject a bug in the subscribe_by_pool_ids function to trigger a Missing If Construct Plus Statements (MIFS) fault. The function should fail due to removing the check for None values in quantity, causing incorrect quantity parameter handling.",
         "Trigger a Missing If Construct Plus Statements (MIFS) fault within the subscribe_by_pool_ids function. The function should fail due to missing quantity validation, potentially causing subscription errors.",
         "Trigger a Missing If Construct Plus Statements (MIFS) fault within the subscribe_by_pool_ids function.",
         "ansible",
         "3.6.9",
         "test/units/modules/packaging/os/test_redhat_subscription.py",
         "https://github.com/ansible/ansible",
         "MIFS"
        ],
        [
         "44",
         "Fix UNC path support in the powershell shell plugin (#66604)",
         null,
         null,
         "https://github.com/python/cpython/commit/fc7980af9a42676913b4054163570ee438b82e9c",
         "fc7980af9a42676913b4054163570ee438b82e9c",
         "BugsInPy",
         "diff --git a/lib/ansible/plugins/shell/powershell.py b/lib/ansible/plugins/shell/powershell.py\\nindex ee23147cc5..ca2d5ebf5b 100644\\n--- a/lib/ansible/plugins/shell/powershell.py\\n+++ b/lib/ansible/plugins/shell/powershell.py\\n@@ -22,6 +22,7 @@ import re\\n import shlex\\n import pkgutil\\n import xml.etree.ElementTree as ET\\n+import ntpath\\n \\n from ansible.errors import AnsibleError\\n from ansible.module_utils._text import to_bytes, to_text\\n@@ -93,14 +94,13 @@ class ShellModule(ShellBase):\\n\\t\\t return \"\"\\n \\n\\t def join_path(self, *args):\\n-\\t\\tparts = []\\n-\\t\\tfor arg in args:\\n-\\t\\t\\targ = self._unquote(arg).replace('/', '\\\\')\\n-\\t\\t\\tparts.extend([a for a in arg.split('\\\\') if a])\\n-\\t\\tpath = '\\\\'.join(parts)\\n-\\t\\tif path.startswith('~'):\\n-\\t\\t\\treturn path\\n-\\t\\treturn path\\n+\\t\\t# use normpath() to remove doubled slashed and convert forward to backslashes\\n+\\t\\tparts = [ntpath.normpath(self._unquote(arg)) for arg in args]\\n+\\n+\\t\\t# Becuase ntpath.join treats any component that begins with a backslash as an absolute path,\\n+\\t\\t# we have to strip slashes from at least the beginning, otherwise join will ignore all previous\\n+\\t\\t# path components except for the drive.\\n+\\t\\treturn ntpath.join(parts[0], *[part.strip('\\\\') for part in parts[1:]])\\n \\n\\t def get_remote_filename(self, pathname):\\n\\t\\t # powershell requires that script files end with .ps1\\n",
         "def join_path(self, *args):\\n\\t\\tparts = [ntpath.normpath(self._unquote(arg)) for arg in args]\\n\\t\\treturn ntpath.join(parts[0], *[part.strip('\\\\') for part in parts[1:]])",
         "def join_path(self, *args):\\n\\t\\tparts = []\\n\\t\\tfor arg in args:\\n\\t\\t\\targ = self._unquote(arg).replace('/', '\\\\')\\n\\t\\t\\tparts.extend([a for a in arg.split('\\\\') if a])\\n\\t\\tpath = '\\\\'.join(parts)\\n\\t\\tif path.startswith('~'):\\n\\t\\t\\treturn path\\n\\t\\treturn path",
         "def join_path(self, *args)",
         null,
         "Modify the join_path method to introduce a Wrong Algorithm - Large Modifications (WALL) fault. The function should fail due to completely replacing the ntpath-based implementation with custom path joining logic, potentially causing incorrect path handling.",
         "Alter the join_path implementation to introduce wrong algorithm - large modifications (WALL) fault by implementing custom path joining logic instead of using ntpath functions, causing incorrect path normalization and joining.",
         "Alter the join_path implementation to use an incorrect algorithm for path joining.",
         "ansible",
         "3.6.9",
         "test/units/plugins/shell/test_powershell.py",
         "https://github.com/ansible/ansible",
         "WALL"
        ],
        [
         "45",
         "Merging of broadcast domain and Broadcast domain port (#51978)",
         null,
         null,
         "https://github.com/python/cpython/commit/0e77eeb2055b4bd0c042acf44e4e9082a1234819",
         "0e77eeb2055b4bd0c042acf44e4e9082a1234819",
         "Defectors",
         "diff --git a/lib/ansible/modules/storage/netapp/na_ontap_broadcast_domain.py b/lib/ansible/modules/storage/netapp/na_ontap_broadcast_domain.py\nindex 34951ffd58..314402074a 100644\n--- a/lib/ansible/modules/storage/netapp/na_ontap_broadcast_domain.py\n+++ b/lib/ansible/modules/storage/netapp/na_ontap_broadcast_domain.py\n@@ -1,6 +1,6 @@\n #!/usr/bin/python\n \n-# (c) 2018, NetApp, Inc\n+# (c) 2018-2019, NetApp, Inc\n # GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n \n from __future__ import absolute_import, division, print_function\n@@ -13,7 +13,7 @@ ANSIBLE_METADATA = {'metadata_version': '1.1',\n \n DOCUMENTATION = '''\n module: na_ontap_broadcast_domain\n-short_description: NetApp ONTAP manage broadcast domains..\n+short_description: NetApp ONTAP manage broadcast domains.\n extends_documentation_fragment:\n     - netapp.na_ontap\n version_added: '2.6'\n@@ -26,52 +26,73 @@ options:\n     - Whether the specified broadcast domain should exist or not.\n     choices: ['present', 'absent']\n     default: present\n-  broadcast_domain:\n+  name:\n     description:\n-    - Specify the broadcast_domain name\n+    - Specify the broadcast domain name.\n     required: true\n+    aliases:\n+    - broadcast_domain\n+  from_name:\n+    description:\n+    - Specify the  broadcast domain name to be split into new broadcast domain.\n+    version_added: \"2.8\"\n   mtu:\n     description:\n-    - Specify the required mtu for the broadcast domain\n+    - Specify the required mtu for the broadcast domain.\n   ipspace:\n     description:\n     - Specify the required ipspace for the broadcast domain.\n-    - A domain ipspace can not be modified after the domain has been created\n+    - A domain ipspace can not be modified after the domain has been created.\n   ports:\n     description:\n-    - Specify the ports associated with this broadcast domain. Should be comma separated\n-\n+    - Specify the ports associated with this broadcast domain. Should be comma separated.\n+    - It represents the expected state of a list of ports at any time.\n+    - Add a port if it is specified in expected state but not in current state.\n+    - Delete a port if it is specified in current state but not in expected state.\n+    - For split action, it represents the ports to be split from current broadcast domain and added to the new broadcast domain.\n+    - if all ports are removed or splited from a broadcast domain, the broadcast domain will be deleted automatically.\n '''\n \n EXAMPLES = \"\"\"\n     - name: create broadcast domain\n       na_ontap_broadcast_domain:\n-        state=present\n-        username={{ netapp_username }}\n-        password={{ netapp_password }}\n-        hostname={{ netapp_hostname }}\n-        broadcast_domain=123kevin\n-        mtu=1000\n-        ipspace=Default\n-        ports=khutton-vsim1:e0d-12,khutton-vsim1:e0d-13\n-    - name: delete broadcast domain\n-      na_ontap_broadcast_domain:\n-        state=absent\n-        username={{ netapp_username }}\n-        password={{ netapp_password }}\n-        hostname={{ netapp_hostname }}\n-        broadcast_domain=123kevin\n-        mtu=1000\n-        ipspace=Default\n+        state: present\n+        username: \"{{ netapp_username }}\"\n+        password: \"{{ netapp_password }}\"\n+        hostname: \"{{ netapp_hostname }}\"\n+        name: ansible_domain\n+        mtu: 1000\n+        ipspace: Default\n+        ports: [\"khutton-vsim1:e0d-12\", \"khutton-vsim1:e0d-13\"]\n     - name: modify broadcast domain\n       na_ontap_broadcast_domain:\n-        state=absent\n-        username={{ netapp_username }}\n-        password={{ netapp_password }}\n-        hostname={{ netapp_hostname }}\n-        broadcast_domain=123kevin\n-        mtu=1100\n-        ipspace=Default\n+        state: present\n+        username: \"{{ netapp_username }}\"\n+        password: \"{{ netapp_password }}\"\n+        hostname: \"{{ netapp_hostname }}\"\n+        name: ansible_domain\n+        mtu: 1100\n+        ipspace: Default\n+        ports: [\"khutton-vsim1:e0d-12\", \"khutton-vsim1:e0d-13\"]\n+    - name: split broadcast domain\n+      na_ontap_broadcast_domain:\n+        state: present\n+        username: \"{{ netapp_username }}\"\n+        password: \"{{ netapp_password }}\"\n+        hostname: \"{{ netapp_hostname }}\"\n+        from_name: ansible_domain\n+        name: new_ansible_domain\n+        mtu: 1200\n+        ipspace: Default\n+        ports: khutton-vsim1:e0d-12\n+    - name: delete broadcast domain\n+      na_ontap_broadcast_domain:\n+        state: absent\n+        username: \"{{ netapp_username }}\"\n+        password: \"{{ netapp_password }}\"\n+        hostname: \"{{ netapp_hostname }}\"\n+        name: ansible_domain\n+        ipspace: Default\n \"\"\"\n \n RETURN = \"\"\"\n@@ -83,6 +104,7 @@ import traceback\n from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils._text import to_native\n import ansible.module_utils.netapp as netapp_utils\n+from ansible.module_utils.netapp_module import NetAppModule\n \n HAS_NETAPP_LIB = netapp_utils.has_netapp_lib()\n \n@@ -98,10 +120,11 @@ class NetAppOntapBroadcastDomain(object):\n         self.argument_spec = netapp_utils.na_ontap_host_argument_spec()\n         self.argument_spec.update(dict(\n             state=dict(required=False, choices=['present', 'absent'], default='present'),\n-            broadcast_domain=dict(required=True, type='str'),\n+            name=dict(required=True, type='str', aliases=[\"broadcast_domain\"]),\n             ipspace=dict(required=False, type='str'),\n             mtu=dict(required=False, type='str'),\n             ports=dict(required=False, type='list'),\n+            from_name=dict(required=False, type='str'),\n         ))\n \n         self.module = AnsibleModule(\n@@ -109,14 +132,8 @@ class NetAppOntapBroadcastDomain(object):\n             supports_check_mode=True\n         )\n \n-        parameters = self.module.params\n-\n-        # set up state variables\n-        self.state = parameters['state']\n-        self.broadcast_domain = parameters['broadcast_domain']\n-        self.ipspace = parameters['ipspace']\n-        self.mtu = parameters['mtu']\n-        self.ports = parameters['ports']\n+        self.na_helper = NetAppModule()\n+        self.parameters = self.na_helper.set_parameters(self.module.params)\n \n         if HAS_NETAPP_LIB is False:\n             self.module.fail_json(msg=\"the python NetApp-Lib module is required\")\n@@ -124,23 +141,24 @@ class NetAppOntapBroadcastDomain(object):\n             self.server = netapp_utils.setup_na_ontap_zapi(module=self.module)\n         return\n \n-    def get_broadcast_domain(self):\n+    def get_broadcast_domain(self, broadcast_domain=None):\n         \"\"\"\n         Return details about the broadcast domain\n-        :param:\n-            name : broadcast domain name\n+        :param broadcast_domain: specific broadcast domain to get.\n         :return: Details about the broadcas domain. None if not found.\n         :rtype: dict\n         \"\"\"\n+        if broadcast_domain is None:\n+            broadcast_domain = self.parameters['name']\n         domain_get_iter = netapp_utils.zapi.NaElement('net-port-broadcast-domain-get-iter')\n         broadcast_domain_info = netapp_utils.zapi.NaElement('net-port-broadcast-domain-info')\n-        broadcast_domain_info.add_new_child('broadcast-domain', self.broadcast_domain)\n+        broadcast_domain_info.add_new_child('broadcast-domain', broadcast_domain)\n         query = netapp_utils.zapi.NaElement('query')\n         query.add_child_elem(broadcast_domain_info)\n         domain_get_iter.add_child_elem(query)\n         result = self.server.invoke_successfully(domain_get_iter, True)\n         domain_exists = None\n-        # check if job exists\n+        # check if broadcast_domain exists\n         if result.get_child_by_name('num-records') and \\\n                 int(result.get_child_content('num-records')) == 1:\n             domain_info = result.get_child_by_name('attributes-list').\\\n@@ -148,10 +166,16 @@ class NetAppOntapBroadcastDomain(object):\n             domain_name = domain_info.get_child_content('broadcast-domain')\n             domain_mtu = domain_info.get_child_content('mtu')\n             domain_ipspace = domain_info.get_child_content('ipspace')\n+            domain_ports = domain_info.get_child_by_name('ports')\n+            if domain_ports is not None:\n+                ports = [port.get_child_content('port') for port in domain_ports.get_children()]\n+            else:\n+                ports = []\n             domain_exists = {\n                 'domain-name': domain_name,\n                 'mtu': domain_mtu,\n-                'ipspace': domain_ipspace\n+                'ipspace': domain_ipspace,\n+                'ports': ports\n             }\n         return domain_exists\n \n@@ -160,35 +184,38 @@ class NetAppOntapBroadcastDomain(object):\n         Creates a new broadcast domain\n         \"\"\"\n         domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-create')\n-        domain_obj.add_new_child(\"broadcast-domain\", self.broadcast_domain)\n-        if self.ipspace:\n-            domain_obj.add_new_child(\"ipspace\", self.ipspace)\n-        domain_obj.add_new_child(\"mtu\", self.mtu)\n-        if self.ports:\n+        domain_obj.add_new_child(\"broadcast-domain\", self.parameters['name'])\n+        if self.parameters.get('ipspace'):\n+            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\n+        if self.parameters.get('mtu'):\n+            domain_obj.add_new_child(\"mtu\", self.parameters['mtu'])\n+        if self.parameters.get('ports'):\n             ports_obj = netapp_utils.zapi.NaElement('ports')\n             domain_obj.add_child_elem(ports_obj)\n-            for port in self.ports:\n+            for port in self.parameters['ports']:\n                 ports_obj.add_new_child('net-qualified-port-name', port)\n         try:\n             self.server.invoke_successfully(domain_obj, True)\n         except netapp_utils.zapi.NaApiError as error:\n             self.module.fail_json(msg='Error creating broadcast domain %s: %s' %\n-                                  (self.broadcast_domain, to_native(error)),\n+                                  (self.parameters['name'], to_native(error)),\n                                   exception=traceback.format_exc())\n \n-    def delete_broadcast_domain(self):\n+    def delete_broadcast_domain(self, broadcast_domain=None):\n         \"\"\"\n         Deletes a broadcast domain\n         \"\"\"\n+        if broadcast_domain is None:\n+            broadcast_domain = self.parameters['name']\n         domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-destroy')\n-        domain_obj.add_new_child(\"broadcast-domain\", self.broadcast_domain)\n-        if self.ipspace:\n-            domain_obj.add_new_child(\"ipspace\", self.ipspace)\n+        domain_obj.add_new_child(\"broadcast-domain\", broadcast_domain)\n+        if self.parameters.get('ipspace'):\n+            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\n         try:\n             self.server.invoke_successfully(domain_obj, True)\n         except netapp_utils.zapi.NaApiError as error:\n             self.module.fail_json(msg='Error deleting broadcast domain %s: %s' %\n-                                  (self.broadcast_domain, to_native(error)),\n+                                  (broadcast_domain, to_native(error)),\n                                   exception=traceback.format_exc())\n \n     def modify_broadcast_domain(self):\n@@ -196,51 +223,205 @@ class NetAppOntapBroadcastDomain(object):\n         Modifies ipspace and mtu options of a broadcast domain\n         \"\"\"\n         domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-modify')\n-        domain_obj.add_new_child(\"broadcast-domain\", self.broadcast_domain)\n-        if self.ipspace:\n-            domain_obj.add_new_child(\"ipspace\", self.ipspace)\n-        if self.mtu:\n-            domain_obj.add_new_child(\"mtu\", self.mtu)\n+        domain_obj.add_new_child(\"broadcast-domain\", self.parameters['name'])\n+        if self.parameters.get('mtu'):\n+            domain_obj.add_new_child(\"mtu\", self.parameters['mtu'])\n+        if self.parameters.get('ipspace'):\n+            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\n         try:\n             self.server.invoke_successfully(domain_obj, True)\n         except netapp_utils.zapi.NaApiError as error:\n             self.module.fail_json(msg='Error modifying broadcast domain %s: %s' %\n-                                  (self.broadcast_domain, to_native(error)),\n+                                  (self.parameters['name'], to_native(error)),\n+                                  exception=traceback.format_exc())\n+\n+    def split_broadcast_domain(self):\n+        \"\"\"\n+        split broadcast domain\n+        \"\"\"\n+        domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-split')\n+        domain_obj.add_new_child(\"broadcast-domain\", self.parameters['from_name'])\n+        domain_obj.add_new_child(\"new-broadcast-domain\", self.parameters['name'])\n+        if self.parameters.get('ports'):\n+            ports_obj = netapp_utils.zapi.NaElement('ports')\n+            domain_obj.add_child_elem(ports_obj)\n+            for port in self.parameters['ports']:\n+                ports_obj.add_new_child('net-qualified-port-name', port)\n+        if self.parameters.get('ipspace'):\n+            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\n+        try:\n+            self.server.invoke_successfully(domain_obj, True)\n+        except netapp_utils.zapi.NaApiError as error:\n+            self.module.fail_json(msg='Error splitting broadcast domain %s: %s' %\n+                                  (self.parameters['name'], to_native(error)),\n+                                  exception=traceback.format_exc())\n+        if len(self.get_broadcast_domain_ports(self.parameters['from_name'])) == 0:\n+            self.delete_broadcast_domain(self.parameters['from_name'])\n+\n+    def modify_redirect(self, modify):\n+        \"\"\"\n+        :param modify: modify attributes.\n+        \"\"\"\n+        for attribute in modify.keys():\n+            if attribute == 'mtu':\n+                self.modify_broadcast_domain()\n+            if attribute == 'ports':\n+                self.modify_broadcast_domain_ports()\n+\n+    def get_modify_attributes(self, current, split):\n+        \"\"\"\n+        :param current: current state.\n+        :param split: True or False of split action.\n+        :return: list of modified attributes.\n+        \"\"\"\n+        modify = None\n+        if self.parameters['state'] == 'present':\n+            # split already handled ipspace and ports.\n+            if self.parameters.get('from_name'):\n+                current = self.get_broadcast_domain(self.parameters['from_name'])\n+                if split:\n+                    modify = self.na_helper.get_modified_attributes(current, self.parameters)\n+                    if modify.get('ipspace'):\n+                        del modify['ipspace']\n+                    if modify.get('ports'):\n+                        del modify['ports']\n+        # ipspace can not be modified.\n+            else:\n+                modify = self.na_helper.get_modified_attributes(current, self.parameters)\n+                if modify.get('ipspace'):\n+                    self.module.fail_json(msg='A domain ipspace can not be modified after the domain has been created.',\n+                                          exception=traceback.format_exc())\n+        return modify\n+\n+    def modify_broadcast_domain_ports(self):\n+        \"\"\"\n+        compare current and desire ports. Call add or remove ports methods if needed.\n+        :return: None.\n+        \"\"\"\n+        current_ports = self.get_broadcast_domain_ports()\n+        expect_ports = self.parameters['ports']\n+        # if want to remove all ports, simply delete the broadcast domain.\n+        if len(expect_ports) == 0:\n+            self.delete_broadcast_domain()\n+            return\n+        ports_to_remove = list(set(current_ports) - set(expect_ports))\n+        ports_to_add = list(set(expect_ports) - set(current_ports))\n+\n+        if len(ports_to_add) > 0:\n+            self.add_broadcast_domain_ports(ports_to_add)\n+\n+        if len(ports_to_remove) > 0:\n+            self.delete_broadcast_domain_ports(ports_to_remove)\n+\n+    def add_broadcast_domain_ports(self, ports):\n+        \"\"\"\n+        Creates new broadcast domain ports\n+        \"\"\"\n+        domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-add-ports')\n+        domain_obj.add_new_child(\"broadcast-domain\", self.parameters['name'])\n+        if self.parameters.get('ipspace'):\n+            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\n+        if ports:\n+            ports_obj = netapp_utils.zapi.NaElement('ports')\n+            domain_obj.add_child_elem(ports_obj)\n+            for port in ports:\n+                ports_obj.add_new_child('net-qualified-port-name', port)\n+        try:\n+            self.server.invoke_successfully(domain_obj, True)\n+            return True\n+        except netapp_utils.zapi.NaApiError as error:\n+            self.module.fail_json(msg='Error creating port for broadcast domain %s: %s' %\n+                                  (self.parameters['name'], to_native(error)),\n+                                  exception=traceback.format_exc())\n+\n+    def delete_broadcast_domain_ports(self, ports):\n+        \"\"\"\n+        Deletes broadcast domain ports\n+        :param: ports to be deleted.\n+        \"\"\"\n+        domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-remove-ports')\n+        domain_obj.add_new_child(\"broadcast-domain\", self.parameters['name'])\n+        if self.parameters.get('ipspace'):\n+            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\n+        if ports:\n+            ports_obj = netapp_utils.zapi.NaElement('ports')\n+            domain_obj.add_child_elem(ports_obj)\n+            for port in ports:\n+                ports_obj.add_new_child('net-qualified-port-name', port)\n+        try:\n+            self.server.invoke_successfully(domain_obj, True)\n+            return True\n+        except netapp_utils.zapi.NaApiError as error:\n+            self.module.fail_json(msg='Error deleting port for broadcast domain %s: %s' %\n+                                  (self.parameters['name'], to_native(error)),\n                                   exception=traceback.format_exc())\n \n+    def get_broadcast_domain_ports(self, broadcast_domain=None):\n+        \"\"\"\n+        Return details about the broadcast domain ports.\n+        :return: Details about the broadcast domain ports. None if not found.\n+        :rtype: list\n+        \"\"\"\n+        if broadcast_domain is None:\n+            broadcast_domain = self.parameters['name']\n+        domain_get_iter = netapp_utils.zapi.NaElement('net-port-broadcast-domain-get-iter')\n+        broadcast_domain_info = netapp_utils.zapi.NaElement('net-port-broadcast-domain-info')\n+        broadcast_domain_info.add_new_child('broadcast-domain', broadcast_domain)\n+        query = netapp_utils.zapi.NaElement('query')\n+        query.add_child_elem(broadcast_domain_info)\n+        domain_get_iter.add_child_elem(query)\n+        result = self.server.invoke_successfully(domain_get_iter, True)\n+        ports = []\n+        if result.get_child_by_name('num-records') and \\\n+                int(result.get_child_content('num-records')) == 1:\n+            domain_info = result.get_child_by_name('attributes-list').get_child_by_name('net-port-broadcast-domain-info')\n+            domain_ports = domain_info.get_child_by_name('ports')\n+            if domain_ports is not None:\n+                ports = [port.get_child_content('port') for port in domain_ports.get_children()]\n+        return ports\n+\n     def apply(self):\n         \"\"\"\n         Run Module based on play book\n         \"\"\"\n-        changed = False\n-        broadcast_domain_details = self.get_broadcast_domain()\n-        broadcast_domain_exists = False\n-        results = netapp_utils.get_cserver(self.server)\n-        cserver = netapp_utils.setup_na_ontap_zapi(module=self.module, vserver=results)\n-        netapp_utils.ems_log_event(\"na_ontap_broadcast_domain\", cserver)\n-        if broadcast_domain_details:\n-            broadcast_domain_exists = True\n-            if self.state == 'absent':  # delete\n-                changed = True\n-            elif self.state == 'present':  # modify\n-                if (self.mtu and self.mtu != broadcast_domain_details['mtu']) or \\\n-                   (self.ipspace and self.ipspace != broadcast_domain_details['ipspace']):\n-                    changed = True\n-        else:\n-            if self.state == 'present':  # create\n-                changed = True\n-        if changed:\n+        self.asup_log_for_cserver(\"na_ontap_broadcast_domain\")\n+        current = self.get_broadcast_domain()\n+        cd_action, split = None, None\n+        cd_action = self.na_helper.get_cd_action(current, self.parameters)\n+        if cd_action == 'create':\n+            # either create new domain or split domain.\n+            if self.parameters.get('from_name'):\n+                split = self.na_helper.is_rename_action(self.get_broadcast_domain(self.parameters['from_name']), current)\n+                if split is None:\n+                    self.module.fail_json(msg='A domain can not be split if it does not exist.',\n+                                          exception=traceback.format_exc())\n+                if split:\n+                    cd_action = None\n+        modify = self.get_modify_attributes(current, split)\n+        if self.na_helper.changed:\n             if self.module.check_mode:\n                 pass\n             else:\n-                if self.state == 'present':  # execute create\n-                    if not broadcast_domain_exists:\n-                        self.create_broadcast_domain()\n-                    else:  # execute modify\n-                        self.modify_broadcast_domain()\n-                elif self.state == 'absent':  # execute delete\n+                if split:\n+                    self.split_broadcast_domain()\n+                if cd_action == 'create':\n+                    self.create_broadcast_domain()\n+                elif cd_action == 'delete':\n                     self.delete_broadcast_domain()\n-        self.module.exit_json(changed=changed)\n+                elif modify:\n+                    self.modify_redirect(modify)\n+        self.module.exit_json(changed=self.na_helper.changed)\n+\n+    def asup_log_for_cserver(self, event_name):\n+        \"\"\"\n+        Fetch admin vserver for the given cluster\n+        Create and Autosupport log event with the given module name\n+        :param event_name: Name of the event log\n+        :return: None\n+        \"\"\"\n+        results = netapp_utils.get_cserver(self.server)\n+        cserver = netapp_utils.setup_na_ontap_zapi(module=self.module, vserver=results)\n+        netapp_utils.ems_log_event(event_name, cserver)\n \n \n def main():\ndiff --git a/test/units/modules/storage/netapp/test_na_ontap_broadcast_domain.py b/test/units/modules/storage/netapp/test_na_ontap_broadcast_domain.py\nnew file mode 100644\nindex 0000000000..98c13bea65\n--- /dev/null\n+++ b/test/units/modules/storage/netapp/test_na_ontap_broadcast_domain.py\n@@ -0,0 +1,308 @@\n+# (c) 2018, NetApp, Inc\n+# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n+\n+''' unit test template for ONTAP Ansible module '''\n+\n+from __future__ import print_function\n+import json\n+import pytest\n+\n+from units.compat import unittest\n+from units.compat.mock import patch, Mock\n+from ansible.module_utils import basic\n+from ansible.module_utils._text import to_bytes\n+import ansible.module_utils.netapp as netapp_utils\n+\n+from ansible.modules.storage.netapp.na_ontap_broadcast_domain \\\n+    import NetAppOntapBroadcastDomain as broadcast_domain_module  # module under test\n+\n+if not netapp_utils.has_netapp_lib():\n+    pytestmark = pytest.mark.skip('skipping as missing required netapp_lib')\n+\n+\n+def set_module_args(args):\n+    \"\"\"prepare arguments so that they will be picked up during module creation\"\"\"\n+    args = json.dumps({'ANSIBLE_MODULE_ARGS': args})\n+    basic._ANSIBLE_ARGS = to_bytes(args)  # pylint: disable=protected-access\n+\n+\n+class AnsibleExitJson(Exception):\n+    \"\"\"Exception class to be raised by module.exit_json and caught by the test case\"\"\"\n+    pass\n+\n+\n+class AnsibleFailJson(Exception):\n+    \"\"\"Exception class to be raised by module.fail_json and caught by the test case\"\"\"\n+    pass\n+\n+\n+def exit_json(*args, **kwargs):  # pylint: disable=unused-argument\n+    \"\"\"function to patch over exit_json; package return data into an exception\"\"\"\n+    if 'changed' not in kwargs:\n+        kwargs['changed'] = False\n+    raise AnsibleExitJson(kwargs)\n+\n+\n+def fail_json(*args, **kwargs):  # pylint: disable=unused-argument\n+    \"\"\"function to patch over fail_json; package return data into an exception\"\"\"\n+    kwargs['failed'] = True\n+    raise AnsibleFailJson(kwargs)\n+\n+\n+class MockONTAPConnection(object):\n+    ''' mock server connection to ONTAP host '''\n+\n+    def __init__(self, kind=None, data=None):\n+        ''' save arguments '''\n+        self.type = kind\n+        self.params = data\n+        self.xml_in = None\n+        self.xml_out = None\n+\n+    def invoke_successfully(self, xml, enable_tunneling):  # pylint: disable=unused-argument\n+        ''' mock invoke_successfully returning xml data '''\n+        self.xml_in = xml\n+        if self.type == 'broadcast_domain':\n+            xml = self.build_broadcast_domain_info(self.params)\n+        self.xml_out = xml\n+        return xml\n+\n+    @staticmethod\n+    def build_broadcast_domain_info(broadcast_domain_details):\n+        ''' build xml data for broadcast_domain info '''\n+        xml = netapp_utils.zapi.NaElement('xml')\n+        attributes = {\n+            'num-records': 1,\n+            'attributes-list': {\n+                'net-port-broadcast-domain-info': {\n+                    'broadcast-domain': broadcast_domain_details['name'],\n+                    'ipspace': broadcast_domain_details['ipspace'],\n+                    'mtu': broadcast_domain_details['mtu'],\n+                    'ports': {\n+                        'port-info': {\n+                            'port': 'test_port_1'\n+                        }\n+                    }\n+                }\n+\n+            }\n+        }\n+        xml.translate_struct(attributes)\n+        return xml\n+\n+\n+class TestMyModule(unittest.TestCase):\n+    ''' a group of related Unit Tests '''\n+\n+    def setUp(self):\n+        self.mock_module_helper = patch.multiple(basic.AnsibleModule,\n+                                                 exit_json=exit_json,\n+                                                 fail_json=fail_json)\n+        self.mock_module_helper.start()\n+        self.addCleanup(self.mock_module_helper.stop)\n+        self.server = MockONTAPConnection()\n+        self.mock_broadcast_domain = {\n+            'name': 'test_broadcast_domain',\n+            'mtu': '1000',\n+            'ipspace': 'Default',\n+            'ports': 'test_port_1'\n+        }\n+\n+    def mock_args(self):\n+        return {\n+            'name': self.mock_broadcast_domain['name'],\n+            'ipspace': self.mock_broadcast_domain['ipspace'],\n+            'mtu': self.mock_broadcast_domain['mtu'],\n+            'ports': self.mock_broadcast_domain['ports'],\n+            'hostname': 'test',\n+            'username': 'test_user',\n+            'password': 'test_pass!'\n+        }\n+\n+    def get_broadcast_domain_mock_object(self, kind=None, data=None):\n+        \"\"\"\n+        Helper method to return an na_ontap_volume object\n+        :param kind: passes this param to MockONTAPConnection()\n+        :param data: passes this param to MockONTAPConnection()\n+        :return: na_ontap_volume object\n+        \"\"\"\n+        broadcast_domain_obj = broadcast_domain_module()\n+        broadcast_domain_obj.asup_log_for_cserver = Mock(return_value=None)\n+        broadcast_domain_obj.cluster = Mock()\n+        broadcast_domain_obj.cluster.invoke_successfully = Mock()\n+        if kind is None:\n+            broadcast_domain_obj.server = MockONTAPConnection()\n+        else:\n+            if data is None:\n+                broadcast_domain_obj.server = MockONTAPConnection(kind='broadcast_domain', data=self.mock_broadcast_domain)\n+            else:\n+                broadcast_domain_obj.server = MockONTAPConnection(kind='broadcast_domain', data=data)\n+        return broadcast_domain_obj\n+\n+    def test_module_fail_when_required_args_missing(self):\n+        ''' required arguments are reported as errors '''\n+        with pytest.raises(AnsibleFailJson) as exc:\n+            set_module_args({})\n+            broadcast_domain_module()\n+        print('Info: %s' % exc.value.args[0]['msg'])\n+\n+    def test_get_nonexistent_net_route(self):\n+        ''' Test if get_broadcast_domain returns None for non-existent broadcast_domain '''\n+        set_module_args(self.mock_args())\n+        result = self.get_broadcast_domain_mock_object().get_broadcast_domain()\n+        assert result is None\n+\n+    def test_create_error_missing_broadcast_domain(self):\n+        ''' Test if create throws an error if broadcast_domain is not specified'''\n+        data = self.mock_args()\n+        del data['name']\n+        set_module_args(data)\n+        with pytest.raises(AnsibleFailJson) as exc:\n+            self.get_broadcast_domain_mock_object('broadcast_domain').create_broadcast_domain()\n+        msg = 'missing required arguments: name'\n+        assert exc.value.args[0]['msg'] == msg\n+\n+    @patch('ansible.modules.storage.netapp.na_ontap_broadcast_domain.NetAppOntapBroadcastDomain.create_broadcast_domain')\n+    def test_successful_create(self, create_broadcast_domain):\n+        ''' Test successful create '''\n+        data = self.mock_args()\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_broadcast_domain_mock_object().apply()\n+        assert exc.value.args[0]['changed']\n+        create_broadcast_domain.assert_called_with()\n+\n+    def test_create_idempotency(self):\n+        ''' Test create idempotency '''\n+        set_module_args(self.mock_args())\n+        obj = self.get_broadcast_domain_mock_object('broadcast_domain')\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            obj.apply()\n+        assert not exc.value.args[0]['changed']\n+\n+    def test_modify_mtu(self):\n+        ''' Test successful modify mtu '''\n+        data = self.mock_args()\n+        data['mtu'] = '1200'\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_broadcast_domain_mock_object('broadcast_domain').apply()\n+        assert exc.value.args[0]['changed']\n+\n+    def test_modify_ipspace_idempotency(self):\n+        ''' Test modify ipsapce idempotency'''\n+        data = self.mock_args()\n+        data['ipspace'] = 'Cluster'\n+        set_module_args(data)\n+        with pytest.raises(AnsibleFailJson) as exc:\n+            self.get_broadcast_domain_mock_object('broadcast_domain').apply()\n+        msg = 'A domain ipspace can not be modified after the domain has been created.'\n+        assert exc.value.args[0]['msg'] == msg\n+\n+    @patch('ansible.modules.storage.netapp.na_ontap_broadcast_domain.NetAppOntapBroadcastDomain.add_broadcast_domain_ports')\n+    def test_add_ports(self, add_broadcast_domain_ports):\n+        ''' Test successful modify ports '''\n+        data = self.mock_args()\n+        data['ports'] = 'test_port_1,test_port_2'\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_broadcast_domain_mock_object('broadcast_domain').apply()\n+        assert exc.value.args[0]['changed']\n+        add_broadcast_domain_ports.assert_called_with(['test_port_2'])\n+\n+    @patch('ansible.modules.storage.netapp.na_ontap_broadcast_domain.NetAppOntapBroadcastDomain.delete_broadcast_domain_ports')\n+    def test_delete_ports(self, delete_broadcast_domain_ports):\n+        ''' Test successful modify ports '''\n+        data = self.mock_args()\n+        data['ports'] = ''\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_broadcast_domain_mock_object('broadcast_domain').apply()\n+        assert exc.value.args[0]['changed']\n+        delete_broadcast_domain_ports.assert_called_with(['test_port_1'])\n+\n+    @patch('ansible.modules.storage.netapp.na_ontap_broadcast_domain.NetAppOntapBroadcastDomain.modify_broadcast_domain')\n+    @patch('ansible.modules.storage.netapp.na_ontap_broadcast_domain.NetAppOntapBroadcastDomain.split_broadcast_domain')\n+    @patch('ansible.modules.storage.netapp.na_ontap_broadcast_domain.NetAppOntapBroadcastDomain.get_broadcast_domain')\n+    def test_split_broadcast_domain(self,",
         "def modify_broadcast_domain(self):\\n        domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-modify')\\n        domain_obj.add_new_child(\"broadcast-domain\", self.parameters['name'])\\n        if self.parameters.get('mtu'):\\n            domain_obj.add_new_child(\"mtu\", self.parameters['mtu'])\\n        if self.parameters.get('ipspace'):\\n            domain_obj.add_new_child(\"ipspace\", self.parameters['ipspace'])\\n        try:\\n            self.server.invoke_successfully(domain_obj, True)\\n        except netapp_utils.zapi.NaApiError as error:\\n            self.module.fail_json(msg='Error modifying broadcast domain %s: %s' %\\n                                  (self.parameters['name'], to_native(error)),\\n                                  exception=traceback.format_exc())",
         "def modify_broadcast_domain(self):\\n        domain_obj = netapp_utils.zapi.NaElement('net-port-broadcast-domain-modify')\\n        domain_obj.add_new_child(\"broadcast-domain\", self.broadcast_domain)\\n        if self.ipspace:\\n            domain_obj.add_new_child(\"ipspace\", self.ipspace)\\n        if self.mtu:\\n            domain_obj.add_new_child(\"mtu\", self.mtu)\\n        try:\\n            self.server.invoke_successfully(domain_obj, True)\\n        except netapp_utils.zapi.NaApiError as error:\\n            self.module.fail_json(msg='Error modifying broadcast domain %s: %s' %\\n                                  (self.broadcast_domain, to_native(error)),\\n                                  exception=traceback.format_exc())",
         "modify_broadcast_domain",
         null,
         "By modifying the modify_broadcast_domain method, you can trigger a Wrong variable used in parameter of function call (WPFV) fault. The function should fail due to using direct attribute access instead of dictionary access for parameters.",
         "Inject a bug in the modify_broadcast_domain function to trigger a wrong variable used in parameter of function call (WPFV) fault. The function should fail due to incorrect variable access method for parameter values, potentially causing attribute errors.",
         "Inject a bug in the modify_broadcast_domain function to trigger a wrong variable used in parameter of function call (WPFV) fault.",
         "ansible",
         "2.7.0",
         "test_na_ontap_broadcast_domain.py",
         "https://github.com/ansible/ansible",
         "WPFV"
        ],
        [
         "46",
         "Update to na_ontap_firewall_policy (#51976)",
         null,
         null,
         "https://github.com/python/cpython/commit/dbcfb3d0fe0bc3d6c4c29019fc78ffcf8c40922f",
         "dbcfb3d0fe0bc3d6c4c29019fc78ffcf8c40922f",
         "Defectors",
         "diff --git a/lib/ansible/modules/storage/netapp/na_ontap_firewall_policy.py b/lib/ansible/modules/storage/netapp/na_ontap_firewall_policy.py\nindex 8dfa3e7072..92ccc8a9b8 100644\n--- a/lib/ansible/modules/storage/netapp/na_ontap_firewall_policy.py\n+++ b/lib/ansible/modules/storage/netapp/na_ontap_firewall_policy.py\n@@ -1,6 +1,6 @@\n #!/usr/bin/python\n \n-# (c) 2018, NetApp, Inc\n+# (c) 2018-2019, NetApp, Inc\n # GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n \n from __future__ import absolute_import, division, print_function\n@@ -16,71 +16,66 @@ short_description: NetApp ONTAP Manage a firewall policy\n version_added: '2.7'\n author: NetApp Ansible Team (@carchi8py) <ng-ansibleteam@netapp.com>\n description:\n-  - Manage a firewall policy for an Ontap Cluster\n+  - Configure firewall on an ONTAP node and manage firewall policy for an ONTAP SVM\n extends_documentation_fragment:\n   - netapp.na_ontap\n+requirements:\n+  - Python package ipaddress. Install using 'pip install ipaddress'\n options:\n   state:\n     description:\n-      - Whether to set up a fire policy or not\n+      - Whether to set up a firewall policy or not\n     choices: ['present', 'absent']\n     default: present\n   allow_list:\n     description:\n-      - A list of IPs and masks to use\n+      - A list of IPs and masks to use.\n+      - The host bits of the IP addresses used in this list must be set to 0.\n   policy:\n     description:\n       - A policy name for the firewall policy\n-    required: true\n   service:\n     description:\n       - The service to apply the policy to\n     choices: ['dns', 'http', 'https', 'ndmp', 'ndmps', 'ntp', 'rsh', 'snmp', 'ssh', 'telnet']\n-    required: true\n   vserver:\n     description:\n       - The Vserver to apply the policy to.\n-    required: true\n   enable:\n     description:\n-      - enabled firewall\n+      - enable firewall on a node\n     choices: ['enable', 'disable']\n-    default: enable\n   logging:\n     description:\n-      - enable logging\n+      - enable logging for firewall on a node\n     choices: ['enable', 'disable']\n-    default: disable\n   node:\n     description:\n       - The node to run the firewall configuration on\n-    required: True\n '''\n \n EXAMPLES = \"\"\"\n     - name: create firewall Policy\n       na_ontap_firewall_policy:\n         state: present\n-        allow_list: [1.2.3.4/24,1.3.3.4/24]\n+        allow_list: [1.2.3.0/24,1.3.0.0/16]\n         policy: pizza\n         service: http\n         vserver: ci_dev\n         hostname: \"{{ netapp hostname }}\"\n         username: \"{{ netapp username }}\"\n         password: \"{{ netapp password }}\"\n-        node: laurentn-vsim1\n \n     - name: Modify firewall Policy\n       na_ontap_firewall_policy:\n         state: present\n-        allow_list: [1.2.3.4/24,1.3.3.4/24]\n+        allow_list: [1.5.3.0/24]\n         policy: pizza\n         service: http\n         vserver: ci_dev\n         hostname: \"{{ netapp hostname }}\"\n         username: \"{{ netapp username }}\"\n         password: \"{{ netapp password }}\"\n-        node: laurentn-vsim1\n \n     - name: Destory firewall Policy\n       na_ontap_firewall_policy:\n@@ -91,7 +86,16 @@ EXAMPLES = \"\"\"\n         hostname: \"{{ netapp hostname }}\"\n         username: \"{{ netapp username }}\"\n         password: \"{{ netapp password }}\"\n-        node: laurentn-vsim1\n+\n+    - name: Enable firewall and logging on a node\n+      na_ontap_firewall_policy:\n+        node: test-vsim1\n+        enable: enable\n+        logging: enable\n+        hostname: \"{{ netapp hostname }}\"\n+        username: \"{{ netapp username }}\"\n+        password: \"{{ netapp password }}\"\n+\n \"\"\"\n \n RETURN = \"\"\"\n@@ -103,6 +107,13 @@ from ansible.module_utils.basic import AnsibleModule\n from ansible.module_utils._text import to_native\n import ansible.module_utils.netapp as netapp_utils\n from ansible.module_utils.netapp_module import NetAppModule\n+try:\n+    import ipaddress\n+    HAS_IPADDRESS_LIB = True\n+except ImportError:\n+    HAS_IPADDRESS_LIB = False\n+\n+import sys\n \n HAS_NETAPP_LIB = netapp_utils.has_netapp_lib()\n \n@@ -113,16 +124,20 @@ class NetAppONTAPFirewallPolicy(object):\n         self.argument_spec.update(dict(\n             state=dict(required=False, choices=['present', 'absent'], default='present'),\n             allow_list=dict(required=False, type=\"list\"),\n-            policy=dict(required=True, type='str'),\n-            service=dict(required=True, type='str', choices=['dns', 'http', 'https', 'ndmp', 'ndmps', 'ntp', 'rsh', 'snmp', 'ssh', 'telnet']),\n-            vserver=dict(required=True, type=\"str\"),\n-            enable=dict(required=False, type=\"str\", choices=['enable', 'disable'], default='enable'),\n-            logging=dict(required=False, type=\"str\", choices=[\"enable\", 'disable'], default='disable'),\n-            node=dict(required=True, type=\"str\")\n+            policy=dict(required=False, type='str'),\n+            service=dict(required=False, type='str', choices=['dns', 'http', 'https', 'ndmp',\n+                                                              'ndmps', 'ntp', 'rsh', 'snmp', 'ssh', 'telnet']),\n+            vserver=dict(required=False, type=\"str\"),\n+            enable=dict(required=False, type=\"str\", choices=['enable', 'disable']),\n+            logging=dict(required=False, type=\"str\", choices=['enable', 'disable']),\n+            node=dict(required=False, type=\"str\")\n         ))\n \n         self.module = AnsibleModule(\n             argument_spec=self.argument_spec,\n+            required_together=(['policy', 'service', 'vserver'],\n+                               ['enable', 'node']\n+                               ),\n             supports_check_mode=True\n         )\n \n@@ -133,15 +148,77 @@ class NetAppONTAPFirewallPolicy(object):\n             self.module.fail_json(msg=\"the python NetApp-Lib module is required\")\n         else:\n             self.server = netapp_utils.setup_na_ontap_zapi(module=self.module)\n+\n+        if HAS_IPADDRESS_LIB is False:\n+            self.module.fail_json(msg=\"the python ipaddress lib is required for this module\")\n         return\n \n+    def validate_ip_addresses(self):\n+        '''\n+            Validate if the given IP address is a network address (i.e. it's host bits are set to 0)\n+            ONTAP doesn't validate if the host bits are set,\n+            and hence doesn't add a new address unless the IP is from a different network.\n+            So this validation allows the module to be idempotent.\n+            :return: None\n+        '''\n+        for ip in self.parameters['allow_list']:\n+            # create an IPv4 object for current IP address\n+            if sys.version_info[0] >= 3:\n+                ip_addr = str(ip)\n+            else:\n+                ip_addr = unicode(ip)  # pylint: disable=undefined-variable\n+            # get network address from netmask, throw exception if address is not a network address\n+            try:\n+                ipaddress.ip_network(ip_addr)\n+            except ValueError as exc:\n+                self.module.fail_json(msg='Error: Invalid IP address value for allow_list parameter.'\n+                                          'Please specify a network address without host bits set: %s'\n+                                      % (to_native(exc)))\n+\n+    def get_firewall_policy(self):\n+        \"\"\"\n+        Get a firewall policy\n+        :return: returns a firewall policy object, or returns False if there are none\n+        \"\"\"\n+        net_firewall_policy_obj = netapp_utils.zapi.NaElement(\"net-firewall-policy-get-iter\")\n+        attributes = {\n+            'query': {\n+                'net-firewall-policy-info': self.firewall_policy_attributes()\n+            }\n+        }\n+        net_firewall_policy_obj.translate_struct(attributes)\n+\n+        try:\n+            result = self.server.invoke_successfully(net_firewall_policy_obj, True)\n+        except netapp_utils.zapi.NaApiError as error:\n+            self.module.fail_json(msg=\"Error getting firewall policy %s:%s\" % (self.parameters['policy'],\n+                                                                               to_native(error)),\n+                                  exception=traceback.format_exc())\n+\n+        if result.get_child_by_name('num-records') and int(result.get_child_content('num-records')) >= 1:\n+            attributes_list = result.get_child_by_name('attributes-list')\n+            policy_info = attributes_list.get_child_by_name('net-firewall-policy-info')\n+            ips = self.na_helper.get_value_for_list(from_zapi=True,\n+                                                    zapi_parent=policy_info.get_child_by_name('allow-list'))\n+            return {\n+                'service': policy_info['service'],\n+                'allow_list': ips}\n+        return None\n+\n     def create_firewall_policy(self):\n         \"\"\"\n-        Create a firewall policy\n-        :return: Nothing\n+        Create a firewall policy for given vserver\n+        :return: None\n         \"\"\"\n         net_firewall_policy_obj = netapp_utils.zapi.NaElement(\"net-firewall-policy-create\")\n-        net_firewall_policy_obj = self.create_modify_policy(net_firewall_policy_obj)\n+        net_firewall_policy_obj.translate_struct(self.firewall_policy_attributes())\n+        if self.parameters.get('allow_list'):\n+            self.validate_ip_addresses()\n+            net_firewall_policy_obj.add_child_elem(self.na_helper.get_value_for_list(from_zapi=False,\n+                                                                                     zapi_parent='allow-list',\n+                                                                                     zapi_child='ip-and-mask',\n+                                                                                     data=self.parameters['allow_list'])\n+                                                   )\n         try:\n             self.server.invoke_successfully(net_firewall_policy_obj, enable_tunneling=True)\n         except netapp_utils.zapi.NaApiError as error:\n@@ -149,165 +226,116 @@ class NetAppONTAPFirewallPolicy(object):\n \n     def destroy_firewall_policy(self):\n         \"\"\"\n-        Destroy a Firewall Policy\n+        Destroy a Firewall Policy from a vserver\n         :return: None\n         \"\"\"\n         net_firewall_policy_obj = netapp_utils.zapi.NaElement(\"net-firewall-policy-destroy\")\n-        net_firewall_policy_obj.add_new_child('policy', self.parameters['policy'])\n-        net_firewall_policy_obj.add_new_child('service', self.parameters['service'])\n-        net_firewall_policy_obj.add_new_child('vserver', self.parameters['vserver'])\n+        net_firewall_policy_obj.translate_struct(self.firewall_policy_attributes())\n         try:\n             self.server.invoke_successfully(net_firewall_policy_obj, enable_tunneling=True)\n         except netapp_utils.zapi.NaApiError as error:\n             self.module.fail_json(msg=\"Error destroying Firewall Policy: %s\" % (to_native(error)), exception=traceback.format_exc())\n \n-    def get_firewall_policy(self):\n-        \"\"\"\n-        Get a firewall policy\n-        :return: returns a firewall policy object, or returns False if there are none\n-        \"\"\"\n-        net_firewall_policy_obj = netapp_utils.zapi.NaElement(\"net-firewall-policy-get-iter\")\n-        net_firewall_policy_info = netapp_utils.zapi.NaElement(\"net-firewall-policy-info\")\n-        query = netapp_utils.zapi.NaElement('query')\n-        net_firewall_policy_info.add_new_child('policy', self.parameters['policy'])\n-        query.add_child_elem(net_firewall_policy_info)\n-        net_firewall_policy_obj.add_child_elem(query)\n-        result = self.server.invoke_successfully(net_firewall_policy_obj, True)\n-        if result.get_child_by_name('num-records') and \\\n-                int(result.get_child_content('num-records')) == 1:\n-            return result\n-        return False\n-\n-    def modify_firewall_policy(self):\n+    def modify_firewall_policy(self, modify):\n         \"\"\"\n-        Modify a firewall Policy\n+        Modify a firewall Policy on a vserver\n         :return: none\n         \"\"\"\n+        self.validate_ip_addresses()\n         net_firewall_policy_obj = netapp_utils.zapi.NaElement(\"net-firewall-policy-modify\")\n-        net_firewall_policy_obj = self.create_modify_policy(net_firewall_policy_obj)\n+        net_firewall_policy_obj.translate_struct(self.firewall_policy_attributes())\n+        net_firewall_policy_obj.add_child_elem(self.na_helper.get_value_for_list(from_zapi=False,\n+                                                                                 zapi_parent='allow-list',\n+                                                                                 zapi_child='ip-and-mask',\n+                                                                                 data=modify['allow_list']))\n         try:\n             self.server.invoke_successfully(net_firewall_policy_obj, enable_tunneling=True)\n         except netapp_utils.zapi.NaApiError as error:\n             self.module.fail_json(msg=\"Error modifying Firewall Policy: %s\" % (to_native(error)), exception=traceback.format_exc())\n \n-    def create_modify_policy(self, net_firewall_policy_obj):\n-        \"\"\"\n-        Set up the parameters for creating or modifying a policy\n-        :param net_firewall_policy_obj: The Firewall policy to modify\n-        :return:\n-        \"\"\"\n-        net_firewall_policy_obj.add_new_child('policy', self.parameters['policy'])\n-        net_firewall_policy_obj.add_new_child('service', self.parameters['service'])\n-        net_firewall_policy_obj.add_new_child('vserver', self.parameters['vserver'])\n-        allow_ip_list = netapp_utils.zapi.NaElement(\"allow-list\")\n-        for each in self.parameters['allow_list']:\n-            net_firewall_policy_ip = netapp_utils.zapi.NaElement(\"ip-and-mask\")\n-            net_firewall_policy_ip.set_content(each)\n-            allow_ip_list.add_child_elem(net_firewall_policy_ip)\n-        net_firewall_policy_obj.add_child_elem(allow_ip_list)\n-        return net_firewall_policy_obj\n-\n-    def get_firewall_config(self):\n+    def firewall_policy_attributes(self):\n+        return {\n+            'policy': self.parameters['policy'],\n+            'service': self.parameters['service'],\n+            'vserver': self.parameters['vserver'],\n+        }\n+\n+    def get_firewall_config_for_node(self):\n         \"\"\"\n-        Get a firewall configuration\n-        :return: the firewall configuration\n+        Get firewall configuration on the node\n+        :return: dict() with firewall config details\n         \"\"\"\n+        if self.parameters.get('logging'):\n+            if self.parameters.get('node') is None:\n+                self.module.fail_json(msg='Error: Missing parameter \\'node\\' to modify firewall logging')\n         net_firewall_config_obj = netapp_utils.zapi.NaElement(\"net-firewall-config-get\")\n         net_firewall_config_obj.add_new_child('node-name', self.parameters['node'])\n         try:\n             result = self.server.invoke_successfully(net_firewall_config_obj, True)\n         except netapp_utils.zapi.NaApiError as error:\n-            self.module.fail_json(msg=\"Error getting Firewall Configuration: %s\" % (to_native(error)), exception=traceback.format_exc())\n-        return result\n+            self.module.fail_json(msg=\"Error getting Firewall Configuration: %s\" % (to_native(error)),\n+                                  exception=traceback.format_exc())\n+        if result.get_child_by_name('attributes'):\n+            firewall_info = result['attributes'].get_child_by_name('net-firewall-config-info')\n+            return {'enable': self.change_status_to_bool(firewall_info.get_child_content('is-enabled'), to_zapi=False),\n+                    'logging': self.change_status_to_bool(firewall_info.get_child_content('is-logging'), to_zapi=False)}\n+        return None\n \n-    def check_policy(self, policy):\n-        \"\"\"\n-        Check to see if a policy has been changed or not\n-        :param policy: policy to check\n-        :return: True if the policy has changed, False if there are no changes\n-        \"\"\"\n-        changed = False\n-        attributes_list = policy.get_child_by_name('attributes-list')\n-        policy_info = attributes_list.get_child_by_name('net-firewall-policy-info')\n-        allow_list = policy_info.get_child_by_name('allow-list')\n-        for each in allow_list.get_children():\n-            if each.get_content() not in self.parameters['allow_list']:\n-                changed = True\n-        if self.parameters['service'] != policy_info.get_child_by_name('service').get_content():\n-            changed = True\n-        if self.parameters['policy'] != policy_info.get_child_by_name('policy').get_content():\n-            changed = True\n-        return changed\n-\n-    def modify_firewall_config(self):\n+    def modify_firewall_config(self, modify):\n         \"\"\"\n-        Modify the configuration of a firewall\n-        :return: none\n+        Modify the configuration of a firewall on node\n+        :return: None\n         \"\"\"\n         net_firewall_config_obj = netapp_utils.zapi.NaElement(\"net-firewall-config-modify\")\n         net_firewall_config_obj.add_new_child('node-name', self.parameters['node'])\n-        net_firewall_config_obj.add_new_child('is-enabled', self.parameters['enable'])\n-        net_firewall_config_obj.add_new_child('is-logging', self.parameters['logging'])\n+        if modify.get('enable'):\n+            net_firewall_config_obj.add_new_child('is-enabled', self.change_status_to_bool(self.parameters['enable']))\n+        if modify.get('logging'):\n+            net_firewall_config_obj.add_new_child('is-logging', self.change_status_to_bool(self.parameters['logging']))\n         try:\n             self.server.invoke_successfully(net_firewall_config_obj, enable_tunneling=True)\n         except netapp_utils.zapi.NaApiError as error:\n-            self.module.fail_json(msg=\"Error modifying Firewall Config: %s\" % (to_native(error)), exception=traceback.format_exc())\n+            self.module.fail_json(msg=\"Error modifying Firewall Config: %s\" % (to_native(error)),\n+                                  exception=traceback.format_exc())\n \n-    def check_config(self, config):\n-        \"\"\"\n-        check to see if a firewall configuration has changed or not\n-        :param config: The configuration to check\n-        :return: true if it has changed, false if it has not\n-        \"\"\"\n-        changed = False\n-        attributes_list = config.get_child_by_name('attributes')\n-        firewall_info = attributes_list.get_child_by_name('net-firewall-config-info')\n-        enable = firewall_info.get_child_by_name('is-enabled')\n-        logging = firewall_info.get_child_by_name('is-logging')\n-        if self.parameters['enable'] == 'enable':\n-            is_enable = \"true\"\n-        else:\n-            is_enable = \"false\"\n-        if enable != is_enable:\n-            changed = True\n-        if self.parameters['logging'] == 'logging':\n-            is_logging = \"true\"\n+    def change_status_to_bool(self, input, to_zapi=True):\n+        if to_zapi:\n+            return 'true' if input == 'enable' else 'false'\n         else:\n-            is_logging = \"false\"\n-        if logging != is_logging:\n-            changed = True\n-        return changed\n+            return 'enable' if input == 'true' else 'disable'\n \n-    def apply(self):\n+    def autosupport_log(self):\n         results = netapp_utils.get_cserver(self.server)\n         cserver = netapp_utils.setup_na_ontap_zapi(module=self.module, vserver=results)\n         netapp_utils.ems_log_event(\"na_ontap_firewall_policy\", cserver)\n-        changed = False\n-        if self.parameters['state'] == 'present':\n-            policy = self.get_firewall_policy()\n-            if not policy:\n-                self.create_firewall_policy()\n-                if not self.check_config(self.get_firewall_config()):\n-                    self.modify_firewall_config()\n-                changed = True\n-            else:\n-                if self.check_policy(policy):\n-                    self.modify_firewall_policy()\n-                    changed = True\n-                if not self.check_config(self.get_firewall_config()):\n-                    self.modify_firewall_config()\n-                    changed = True\n-        else:\n-            if self.get_firewall_policy():\n-                self.destroy_firewall_policy()\n-                if not self.check_config(self.get_firewall_config()):\n-                    self.modify_firewall_config()\n-                changed = True\n+\n+    def apply(self):\n+        self.autosupport_log()\n+        cd_action, modify, modify_config = None, None, None\n+        if self.parameters.get('policy'):\n+            current = self.get_firewall_policy()\n+            cd_action = self.na_helper.get_cd_action(current, self.parameters)\n+            if cd_action is None and self.parameters['state'] == 'present':\n+                modify = self.na_helper.get_modified_attributes(current, self.parameters)\n+        if self.parameters.get('node'):\n+            current_config = self.get_firewall_config_for_node()\n+            # firewall config for a node is always present, we cannot create or delete a firewall on a node\n+            modify_config = self.na_helper.get_modified_attributes(current_config, self.parameters)\n+\n+        if self.na_helper.changed:\n+            if self.module.check_mode:\n+                pass\n             else:\n-                if not self.check_config(self.get_firewall_config()):\n-                    self.modify_firewall_config()\n-                    changed = True\n-        self.module.exit_json(changed=changed)\n+                if cd_action == 'create':\n+                    self.create_firewall_policy()\n+                elif cd_action == 'delete':\n+                    self.destroy_firewall_policy()\n+                else:\n+                    if modify:\n+                        self.modify_firewall_policy(modify)\n+                    if modify_config:\n+                        self.modify_firewall_config(modify_config)\n+        self.module.exit_json(changed=self.na_helper.changed)\n \n \n def main():\ndiff --git a/test/units/modules/storage/netapp/test_na_ontap_firewall_policy.py b/test/units/modules/storage/netapp/test_na_ontap_firewall_policy.py\nnew file mode 100644\nindex 0000000000..9d78c4fabb\n--- /dev/null\n+++ b/test/units/modules/storage/netapp/test_na_ontap_firewall_policy.py\n@@ -0,0 +1,286 @@\n+# (c) 2018, NetApp, Inc\n+# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n+\n+''' unit test template for ONTAP Ansible module '''\n+\n+from __future__ import print_function\n+import json\n+import pytest\n+\n+from units.compat import unittest\n+from units.compat.mock import patch, Mock\n+from ansible.module_utils import basic\n+from ansible.module_utils._text import to_bytes\n+import ansible.module_utils.netapp as netapp_utils\n+\n+from ansible.modules.storage.netapp.na_ontap_firewall_policy \\\n+    import NetAppONTAPFirewallPolicy as fp_module  # module under test\n+\n+if not netapp_utils.has_netapp_lib():\n+    pytestmark = pytest.mark.skip('skipping as missing required netapp_lib')\n+\n+\n+def set_module_args(args):\n+    \"\"\"prepare arguments so that they will be picked up during module creation\"\"\"\n+    args = json.dumps({'ANSIBLE_MODULE_ARGS': args})\n+    basic._ANSIBLE_ARGS = to_bytes(args)  # pylint: disable=protected-access\n+\n+\n+class AnsibleExitJson(Exception):\n+    \"\"\"Exception class to be raised by module.exit_json and caught by the test case\"\"\"\n+    pass\n+\n+\n+class AnsibleFailJson(Exception):\n+    \"\"\"Exception class to be raised by module.fail_json and caught by the test case\"\"\"\n+    pass\n+\n+\n+def exit_json(*args, **kwargs):  # pylint: disable=unused-argument\n+    \"\"\"function to patch over exit_json; package return data into an exception\"\"\"\n+    if 'changed' not in kwargs:\n+        kwargs['changed'] = False\n+    raise AnsibleExitJson(kwargs)\n+\n+\n+def fail_json(*args, **kwargs):  # pylint: disable=unused-argument\n+    \"\"\"function to patch over fail_json; package return data into an exception\"\"\"\n+    kwargs['failed'] = True\n+    raise AnsibleFailJson(kwargs)\n+\n+\n+class MockONTAPConnection(object):\n+    ''' mock server connection to ONTAP host '''\n+\n+    def __init__(self, kind=None, data=None):\n+        ''' save arguments '''\n+        self.kind = kind\n+        self.data = data\n+        self.xml_in = None\n+        self.xml_out = None\n+\n+    def invoke_successfully(self, xml, enable_tunneling):  # pylint: disable=unused-argument\n+        ''' mock invoke_successfully returning xml data '''\n+        self.xml_in = xml\n+        if self.kind == 'policy':\n+            xml = self.build_policy_info(self.data)\n+        if self.kind == 'config':\n+            xml = self.build_firewall_config_info(self.data)\n+        self.xml_out = xml\n+        return xml\n+\n+    @staticmethod\n+    def build_policy_info(data):\n+        ''' build xml data for net-firewall-policy-info '''\n+        xml = netapp_utils.zapi.NaElement('xml')\n+        attributes = {\n+            'num-records': 1,\n+            'attributes-list': {\n+                'net-firewall-policy-info': {\n+                    'policy': data['policy'],\n+                    'service': data['service'],\n+                    'allow-list': [\n+                        {'ip-and-mask': '1.2.3.0/24'}\n+                    ]\n+                }\n+            }\n+        }\n+\n+        xml.translate_struct(attributes)\n+        return xml\n+\n+    @staticmethod\n+    def build_firewall_config_info(data):\n+        ''' build xml data for net-firewall-config-info '''\n+        xml = netapp_utils.zapi.NaElement('xml')\n+        attributes = {\n+            'attributes': {\n+                'net-firewall-config-info': {\n+                    'is-enabled': 'true',\n+                    'is-logging': 'false'\n+                }\n+            }\n+        }\n+        xml.translate_struct(attributes)\n+        return xml\n+\n+\n+class TestMyModule(unittest.TestCase):\n+    ''' a group of related Unit Tests '''\n+\n+    def setUp(self):\n+        self.mock_module_helper = patch.multiple(basic.AnsibleModule,\n+                                                 exit_json=exit_json,\n+                                                 fail_json=fail_json)\n+        self.mock_module_helper.start()\n+        self.addCleanup(self.mock_module_helper.stop)\n+        self.mock_policy = {\n+            'policy': 'test',\n+            'service': 'http',\n+            'vserver': 'my_vserver',\n+            'allow_list': '1.2.3.0/24'\n+        }\n+        self.mock_config = {\n+            'node': 'test',\n+            'enable': 'enable',\n+            'logging': 'enable'\n+        }\n+\n+    def mock_policy_args(self):\n+        return {\n+            'policy': self.mock_policy['policy'],\n+            'service': self.mock_policy['service'],\n+            'vserver': self.mock_policy['vserver'],\n+            'allow_list': [self.mock_policy['allow_list']],\n+            'hostname': 'test',\n+            'username': 'test_user',\n+            'password': 'test_pass!'\n+        }\n+\n+    def mock_config_args(self):\n+        return {\n+            'node': self.mock_config['node'],\n+            'enable': self.mock_config['enable'],\n+            'logging': self.mock_config['logging'],\n+            'hostname': 'test',\n+            'username': 'test_user',\n+            'password': 'test_pass!'\n+        }\n+\n+    def get_mock_object(self, kind=None):\n+        \"\"\"\n+        Helper method to return an na_ontap_firewall_policy object\n+        :param kind: passes this param to MockONTAPConnection()\n+        :return: na_ontap_firewall_policy object\n+        \"\"\"\n+        obj = fp_module()\n+        obj.autosupport_log = Mock(return_value=None)\n+        if kind is None:\n+            obj.server = MockONTAPConnection()\n+        else:\n+            mock_data = self.mock_config if kind == 'config' else self.mock_policy\n+            obj.server = MockONTAPConnection(kind=kind, data=mock_data)\n+        return obj\n+\n+    def test_module_fail_when_required_args_missing(self):\n+        ''' required arguments are reported as errors '''\n+        with pytest.raises(AnsibleFailJson) as exc:\n+            set_module_args({})\n+            fp_module()\n+        print('Info: %s' % exc.value.args[0]['msg'])\n+\n+    def test_helper_firewall_policy_attributes(self):\n+        ''' helper returns dictionary with vserver, service and policy details '''\n+        data = self.mock_policy\n+        set_module_args(self.mock_policy_args())\n+        result = self.get_mock_object('policy').firewall_policy_attributes()\n+        del data['allow_list']\n+        assert data == result\n+\n+    def test_helper_validate_ip_addresses_positive(self):\n+        ''' test if helper validates if IP is a network address '''\n+        data = self.mock_policy_args()\n+        data['allow_list'] = ['1.2.0.0/16', '1.2.3.0/24']\n+        set_module_args(data)\n+        result = self.get_mock_object().validate_ip_addresses()\n+        assert result is None\n+\n+    def test_helper_validate_ip_addresses_negative(self):\n+        ''' test if helper validates if IP is a network address '''\n+        data = self.mock_policy_args()\n+        data['allow_list'] = ['1.2.0.10/16', '1.2.3.0/24']\n+        set_module_args(data)\n+        with pytest.raises(AnsibleFailJson) as exc:\n+            self.get_mock_object().validate_ip_addresses()\n+        msg = 'Error: Invalid IP address value for allow_list parameter.' \\\n+              'Please specify a network address without host bits set: ' \\\n+              '1.2.0.10/16 has host bits set'\n+        assert exc.value.args[0]['msg'] == msg\n+\n+    def test_get_nonexistent_policy(self):\n+        ''' Test if get_firewall_policy returns None for non-existent policy '''\n+        set_module_args(self.mock_policy_args())\n+        result = self.get_mock_object().get_firewall_policy()\n+        assert result is None\n+\n+    def test_get_existing_policy(self):\n+        ''' Test if get_firewall_policy returns policy details for existing policy '''\n+        data = self.mock_policy_args()\n+        set_module_args(data)\n+        result = self.get_mock_object('policy').get_firewall_policy()\n+        assert result['service'] == data['service']\n+        assert result['allow_list'] == ['1.2.3.0/24']  # from build_policy_info()\n+\n+    def test_successful_create(self):\n+        ''' Test successful create '''\n+        set_module_args(self.mock_policy_args())\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_mock_object().apply()\n+        assert exc.value.args[0]['changed']\n+\n+    def test_create_idempotency(self):\n+        ''' Test create idempotency '''\n+        set_module_args(self.mock_policy_args())\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_mock_object('policy').apply()\n+        assert not exc.value.args[0]['changed']\n+\n+    def test_successful_delete(self):\n+        ''' Test delete existing job '''\n+        data = self.mock_policy_args()\n+        data['state'] = 'absent'\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_mock_object('policy').apply()\n+        assert exc.value.args[0]['changed']\n+\n+    def test_delete_idempotency(self):\n+        ''' Test delete idempotency '''\n+        data = self.mock_policy_args()\n+        data['state'] = 'absent'\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_mock_object().apply()\n+        assert not exc.value.args[0]['changed']\n+\n+    def test_successful_modify(self):\n+        ''' Test successful modify allow_list '''\n+        data = self.mock_policy_args()\n+        data['allow_list'] = ['1.2.0.0/16']\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_mock_object('policy').apply()\n+        assert exc.value.args[0]['changed']\n+\n+    def test_successful_modify_mutiple_ips(self):\n+        ''' Test successful modify allow_list '''\n+        data = self.mock_policy_args()\n+        data['allow_list'] = ['1.2.0.0/16', '1.0.0.0/8']\n+        set_module_args(data)\n+        with pytest.raises(AnsibleExitJson) as exc:\n+            self.get_mock_object('policy').apply()\n+        assert exc.value.args[0]['changed']\n+\n+    def test_get_nonexistent_config(self):\n+        ''' Test if get_firewall_config returns None for non-existent node '''\n+        set_module_args(self.mock_config_args())\n+        result = self.get_mock_object().get_firewall_config_for_node()\n+        assert result is None\n+\n+    def test_get_existing_config(self):\n+        ''' Test if get_firewall_config returns policy details for existing node '''\n+        data = self.mock_config_args()\n+        set_module_args(data)\n+        result = self.get_mock_object('config').get_firewall_config_for_node()\n+        assert result['enable'] == 'enable",
         "def modify_firewall_config(self, modify):\\n        net_firewall_config_obj = netapp_utils.zapi.NaElement(\"net-firewall-config-modify\")\\n        net_firewall_config_obj.add_new_child('node-name', self.parameters['node'])\\n        if modify.get('enable'):\\n            net_firewall_config_obj.add_new_child('is-enabled', self.change_status_to_bool(self.parameters['enable']))\\n        if modify.get('logging'):\\n            net_firewall_config_obj.add_new_child('is-logging', self.change_status_to_bool(self.parameters['logging']))\\n        try:\\n            self.server.invoke_successfully(net_firewall_config_obj, enable_tunneling=True)\\n        except netapp_utils.zapi.NaApiError as error:\\n            self.module.fail_json(msg=\"Error modifying Firewall Config: %s\" % (to_native(error)),\\n                                  exception=traceback.format_exc())",
         "def modify_firewall_config(self):\\n        net_firewall_config_obj = netapp_utils.zapi.NaElement(\"net-firewall-config-modify\")\\n        net_firewall_config_obj.add_new_child('node-name', self.parameters['node'])\\n        net_firewall_config_obj.add_new_child('is-enabled', self.parameters['enable'])\\n        net_firewall_config_obj.add_new_child('is-logging', self.parameters['logging'])\\n        try:\\n            self.server.invoke_successfully(net_firewall_config_obj, enable_tunneling=True)\\n        except netapp_utils.zapi.NaApiError as error:\\n            self.module.fail_json(msg=\"Error modifying Firewall Config: %s\" % (to_native(error)), exception=traceback.format_exc())",
         "modify_firewall_config",
         null,
         "Modify the modify_firewall_config method to introduce a Missing If Construct Plus Statements (MIFS) fault. The function should fail due to removing conditional checks for enable and logging parameters.",
         "Implement a bug in the modify_firewall_config method to trigger a missing if construct plus statements (MIFS) fault. The function should fail due to the absence of checks before adding configuration values.",
         "Implement a bug in the modify_firewall_config method to trigger a missing if construct plus statements (MIFS) fault.",
         "ansible",
         "2.7.0",
         "test_na_ontap_firewall_policy.py",
         "https://github.com/ansible/ansible",
         "MIFS"
        ],
        [
         "47",
         "FortiManager Plugin Module Conversion: fmgr_secprof_waf (#52789)",
         null,
         null,
         "https://github.com/python/cpython/commit/7ee7c3cf2ccee5eca1f237ca38f7a099fcf436b9",
         "7ee7c3cf2ccee5eca1f237ca38f7a099fcf436b9",
         "Defectors",
         "diff --git a/lib/ansible/modules/network/fortimanager/fmgr_secprof_waf.py b/lib/ansible/modules/network/fortimanager/fmgr_secprof_waf.py\nindex f31e27b233..11d1c43ed0 100644\n--- a/lib/ansible/modules/network/fortimanager/fmgr_secprof_waf.py\n+++ b/lib/ansible/modules/network/fortimanager/fmgr_secprof_waf.py\n@@ -28,6 +28,8 @@ DOCUMENTATION = '''\n ---\n module: fmgr_secprof_waf\n version_added: \"2.8\"\n+notes:\n+    - Full Documentation at U(https://ftnt-ansible-docs.readthedocs.io/en/latest/).\n author:\n     - Luke Weighall (@lweighall)\n     - Andrew Welsh (@Ghilli3)\n@@ -43,21 +45,6 @@ options:\n     required: false\n     default: root\n \n-  host:\n-    description:\n-      - The FortiManager's Address.\n-    required: true\n-\n-  username:\n-    description:\n-      - The username associated with the account.\n-    required: true\n-\n-  password:\n-    description:\n-      - The password associated with the username account.\n-    required: true\n-\n   mode:\n     description:\n       - Sets one of three modes for managing the object.\n@@ -1045,18 +1032,12 @@ options:\n EXAMPLES = '''\n   - name: DELETE Profile\n     fmgr_secprof_waf:\n-      host: \"{{inventory_hostname}}\"\n-      username: \"{{ username }}\"\n-      password: \"{{ password }}\"\n       name: \"Ansible_WAF_Profile\"\n       comment: \"Created by Ansible Module TEST\"\n       mode: \"delete\"\n \n   - name: CREATE Profile\n     fmgr_secprof_waf:\n-      host: \"{{inventory_hostname}}\"\n-      username: \"{{ username }}\"\n-      password: \"{{ password }}\"\n       name: \"Ansible_WAF_Profile\"\n       comment: \"Created by Ansible Module TEST\"\n       mode: \"set\"\n@@ -1070,15 +1051,15 @@ api_result:\n \"\"\"\n \n from ansible.module_utils.basic import AnsibleModule, env_fallback\n-from ansible.module_utils.network.fortimanager.fortimanager import AnsibleFortiManager\n-\n-# check for pyFMG lib\n-try:\n-    from pyFMG.fortimgr import FortiManager\n-\n-    HAS_PYFMGR = True\n-except ImportError:\n-    HAS_PYFMGR = False\n+from ansible.module_utils.connection import Connection\n+from ansible.module_utils.network.fortimanager.fortimanager import FortiManagerHandler\n+from ansible.module_utils.network.fortimanager.common import FMGBaseException\n+from ansible.module_utils.network.fortimanager.common import FMGRCommon\n+from ansible.module_utils.network.fortimanager.common import FMGRMethods\n+from ansible.module_utils.network.fortimanager.common import DEFAULT_RESULT_OBJ\n+from ansible.module_utils.network.fortimanager.common import FAIL_SOCKET_MSG\n+from ansible.module_utils.network.fortimanager.common import prepare_dict\n+from ansible.module_utils.network.fortimanager.common import scrub_dict\n \n \n ###############\n@@ -1086,19 +1067,26 @@ except ImportError:\n ###############\n \n \n-def fmgr_waf_profile_addsetdelete(fmg, paramgram):\n-\n+def fmgr_waf_profile_modify(fmgr, paramgram):\n+    \"\"\"\n+    :param fmgr: The fmgr object instance from fortimanager.py\n+    :type fmgr: class object\n+    :param paramgram: The formatted dictionary of options to process\n+    :type paramgram: dict\n+    :return: The response from the FortiManager\n+    :rtype: dict\n+    \"\"\"\n     mode = paramgram[\"mode\"]\n     adom = paramgram[\"adom\"]\n     # INIT A BASIC OBJECTS\n-    response = (-100000, {\"msg\": \"Illegal or malformed paramgram discovered. System Exception\"})\n+    response = DEFAULT_RESULT_OBJ\n     url = \"\"\n     datagram = {}\n \n     # EVAL THE MODE PARAMETER FOR SET OR ADD\n     if mode in ['set', 'add', 'update']:\n         url = '/pm/config/adom/{adom}/obj/waf/profile'.format(adom=adom)\n-        datagram = fmgr_del_none(fmgr_prepare_dict(paramgram))\n+        datagram = scrub_dict(prepare_dict(paramgram))\n \n     # EVAL THE MODE PARAMETER FOR DELETE\n     elif mode == \"delete\":\n@@ -1106,129 +1094,11 @@ def fmgr_waf_profile_addsetdelete(fmg, paramgram):\n         url = '/pm/config/adom/{adom}/obj/waf/profile/{name}'.format(adom=adom, name=paramgram[\"name\"])\n         datagram = {}\n \n-    # IF MODE = SET -- USE THE 'SET' API CALL MODE\n-    if mode == \"set\":\n-        response = fmg.set(url, datagram)\n-    # IF MODE = UPDATE -- USER THE 'UPDATE' API CALL MODE\n-    elif mode == \"update\":\n-        response = fmg.update(url, datagram)\n-    # IF MODE = ADD  -- USE THE 'ADD' API CALL MODE\n-    elif mode == \"add\":\n-        response = fmg.add(url, datagram)\n-    # IF MODE = DELETE  -- USE THE DELETE URL AND API CALL MODE\n-    elif mode == \"delete\":\n-        response = fmg.delete(url, datagram)\n+    response = fmgr.process_request(url, datagram, paramgram[\"mode\"])\n \n     return response\n \n \n-# ADDITIONAL COMMON FUNCTIONS\n-# FUNCTION/METHOD FOR LOGGING OUT AND ANALYZING ERROR CODES\n-def fmgr_logout(fmg, module, msg=\"NULL\", results=(), good_codes=(0,), logout_on_fail=True, logout_on_success=False):\n-    \"\"\"\n-    THIS METHOD CONTROLS THE LOGOUT AND ERROR REPORTING AFTER AN METHOD OR FUNCTION RUNS\n-    \"\"\"\n-    # pydevd.settrace('10.0.0.122', port=54654, stdoutToServer=True, stderrToServer=True)\n-    # VALIDATION ERROR (NO RESULTS, JUST AN EXIT)\n-    if msg != \"NULL\" and len(results) == 0:\n-        try:\n-            fmg.logout()\n-        except BaseException:\n-            pass\n-        module.fail_json(msg=msg)\n-\n-    # SUBMISSION ERROR\n-    if len(results) > 0:\n-        if msg == \"NULL\":\n-            try:\n-                msg = results[1]['status']['message']\n-            except BaseException:\n-                msg = \"No status message returned from pyFMG. Possible that this was a GET with a tuple result.\"\n-\n-        if results[0] not in good_codes:\n-            if logout_on_fail:\n-                fmg.logout()\n-                module.fail_json(msg=msg, **results[1])\n-            else:\n-                return msg\n-        else:\n-            if logout_on_success:\n-                fmg.logout()\n-                module.exit_json(msg=\"API Called worked, but logout handler has been asked to logout on success\",\n-                                 **results[1])\n-            else:\n-                return msg\n-\n-\n-# FUNCTION/METHOD FOR CONVERTING CIDR TO A NETMASK\n-# DID NOT USE IP ADDRESS MODULE TO KEEP INCLUDES TO A MINIMUM\n-def fmgr_cidr_to_netmask(cidr):\n-    cidr = int(cidr)\n-    mask = (0xffffffff >> (32 - cidr)) << (32 - cidr)\n-    return (str((0xff000000 & mask) >> 24) + '.' +\n-            str((0x00ff0000 & mask) >> 16) + '.' +\n-            str((0x0000ff00 & mask) >> 8) + '.' +\n-            str((0x000000ff & mask)))\n-\n-\n-# utility function: removing keys wih value of None, nothing in playbook for that key\n-def fmgr_del_none(obj):\n-    if isinstance(obj, dict):\n-        return type(obj)((fmgr_del_none(k), fmgr_del_none(v))\n-                         for k, v in obj.items() if k is not None and (v is not None and not fmgr_is_empty_dict(v)))\n-    else:\n-        return obj\n-\n-\n-# utility function: remove keys that are need for the logic but the FMG API won't accept them\n-def fmgr_prepare_dict(obj):\n-    list_of_elems = [\"mode\", \"adom\", \"host\", \"username\", \"password\"]\n-    if isinstance(obj, dict):\n-        obj = dict((key, fmgr_prepare_dict(value)) for (key, value) in obj.items() if key not in list_of_elems)\n-    return obj\n-\n-\n-def fmgr_is_empty_dict(obj):\n-    return_val = False\n-    if isinstance(obj, dict):\n-        if len(obj) > 0:\n-            for k, v in obj.items():\n-                if isinstance(v, dict):\n-                    if len(v) == 0:\n-                        return_val = True\n-                    elif len(v) > 0:\n-                        for k1, v1 in v.items():\n-                            if v1 is None:\n-                                return_val = True\n-                            elif v1 is not None:\n-                                return_val = False\n-                                return return_val\n-                elif v is None:\n-                    return_val = True\n-                elif v is not None:\n-                    return_val = False\n-                    return return_val\n-        elif len(obj) == 0:\n-            return_val = True\n-\n-    return return_val\n-\n-\n-def fmgr_split_comma_strings_into_lists(obj):\n-    if isinstance(obj, dict):\n-        if len(obj) > 0:\n-            for k, v in obj.items():\n-                if isinstance(v, str):\n-                    new_list = list()\n-                    if \",\" in v:\n-                        new_items = v.split(\",\")\n-                        for item in new_items:\n-                            new_list.append(item.strip())\n-                        obj[k] = new_list\n-\n-    return obj\n-\n-\n #############\n # END METHODS\n #############\n@@ -1237,9 +1107,6 @@ def fmgr_split_comma_strings_into_lists(obj):\n def main():\n     argument_spec = dict(\n         adom=dict(type=\"str\", default=\"root\"),\n-        host=dict(required=True, type=\"str\"),\n-        password=dict(fallback=(env_fallback, [\"ANSIBLE_NET_PASSWORD\"]), no_log=True, required=True),\n-        username=dict(fallback=(env_fallback, [\"ANSIBLE_NET_USERNAME\"]), no_log=True, required=True),\n         mode=dict(choices=[\"add\", \"set\", \"delete\", \"update\"], type=\"str\", default=\"add\"),\n \n         name=dict(required=False, type=\"str\"),\n@@ -1414,8 +1281,7 @@ def main():\n \n     )\n \n-    module = AnsibleModule(argument_spec, supports_check_mode=False)\n-\n+    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=False, )\n     # MODULE PARAMGRAM\n     paramgram = {\n         \"mode\": module.params[\"mode\"],\n@@ -1586,44 +1452,30 @@ def main():\n         }\n     }\n \n-    list_overrides = ['address-list', 'constraint', 'method', 'signature', 'url-access']\n-    for list_variable in list_overrides:\n-        override_data = list()\n-        try:\n-            override_data = module.params[list_variable]\n-        except BaseException:\n-            pass\n-        try:\n-            if override_data:\n-                del paramgram[list_variable]\n-                paramgram[list_variable] = override_data\n-        except BaseException:\n-            pass\n-\n-    # CHECK IF THE HOST/USERNAME/PW EXISTS, AND IF IT DOES, LOGIN.\n-    host = module.params[\"host\"]\n-    password = module.params[\"password\"]\n-    username = module.params[\"username\"]\n-    if host is None or username is None or password is None:\n-        module.fail_json(msg=\"Host and username and password are required\")\n-\n-    # CHECK IF LOGIN FAILED\n-    fmg = AnsibleFortiManager(module, module.params[\"host\"], module.params[\"username\"], module.params[\"password\"])\n-\n-    response = fmg.login()\n-    if response[1]['status']['code'] != 0:\n-        module.fail_json(msg=\"Connection to FortiManager Failed\")\n-\n-    results = fmgr_waf_profile_addsetdelete(fmg, paramgram)\n-    if results[0] != 0:\n-        fmgr_logout(fmg, module, results=results, good_codes=[0])\n-\n-    fmg.logout()\n-\n-    if results is not None:\n-        return module.exit_json(**results[1])\n+    module.paramgram = paramgram\n+    fmgr = None\n+    if module._socket_path:\n+        connection = Connection(module._socket_path)\n+        fmgr = FortiManagerHandler(connection, module)\n+        fmgr.tools = FMGRCommon()\n     else:\n-        return module.exit_json(msg=\"No results were returned from the API call.\")\n+        module.fail_json(**FAIL_SOCKET_MSG)\n+\n+    list_overrides = ['address-list', 'constraint', 'method', 'signature', 'url-access']\n+    paramgram = fmgr.tools.paramgram_child_list_override(list_overrides=list_overrides,\n+                                                         paramgram=paramgram, module=module)\n+\n+    results = DEFAULT_RESULT_OBJ\n+\n+    try:\n+        results = fmgr_waf_profile_modify(fmgr, paramgram)\n+        fmgr.govern_response(module=module, results=results,\n+                             ansible_facts=fmgr.construct_ansible_facts(results, module.params, paramgram))\n+\n+    except Exception as err:\n+        raise FMGBaseException(err)\n+\n+    return module.exit_json(**results[1])\n \n \n if __name__ == \"__main__\":\ndiff --git a/test/units/modules/network/fortimanager/fixtures/test_fmgr_secprof_waf.json b/test/units/modules/network/fortimanager/fixtures/test_fmgr_secprof_waf.json\nindex 1fa90d75a5..93579f12f7 100644\n--- a/test/units/modules/network/fortimanager/fixtures/test_fmgr_secprof_waf.json\n+++ b/test/units/modules/network/fortimanager/fixtures/test_fmgr_secprof_waf.json\n@@ -1,360 +1,365 @@\n {\n-   \"fmgr_waf_profile_addsetdelete\": [\n-      {\n-         \"paramgram_used\": {\n-            \"comment\": \"Created by Ansible Module TEST\", \n-            \"name\": \"Ansible_WAF_Profile\", \n-            \"adom\": \"root\", \n-            \"address-list\": {\n-               \"blocked-address\": null, \n-               \"status\": null, \n-               \"severity\": null, \n-               \"blocked-log\": null, \n-               \"trusted-address\": null\n-            }, \n-            \"constraint\": {\n-               \"header-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"content-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-cookie\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-cookie\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"url-param-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"hostname\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"line-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"exception\": {\n-                  \"regex\": null, \n-                  \"header-length\": null, \n-                  \"content-length\": null, \n-                  \"max-cookie\": null, \n-                  \"pattern\": null, \n-                  \"hostname\": null, \n-                  \"line-length\": null, \n-                  \"max-range-segment\": null, \n-                  \"url-param-length\": null, \n-                  \"version\": null, \n-                  \"param-length\": null, \n-                  \"malformed\": null, \n-                  \"address\": null, \n-                  \"max-url-param\": null, \n-                  \"max-header-line\": null, \n-                  \"method\": null\n-               }, \n-               \"max-range-segment\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-range-segment\": null, \n-                  \"severity\": null, \n-                  \"log\": null\n-               }, \n-               \"version\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"param-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"malformed\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-url-param\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-url-param\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-header-line\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-header-line\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"method\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }\n-            }, \n-            \"extended-log\": null, \n-            \"url-access\": {\n-               \"action\": null, \n-               \"address\": null, \n-               \"severity\": null, \n-               \"access-pattern\": {\n-                  \"negate\": null, \n-                  \"pattern\": null, \n-                  \"srcaddr\": null, \n-                  \"regex\": null\n-               }, \n-               \"log\": null\n-            }, \n-            \"external\": null, \n-            \"signature\": {\n-               \"custom-signature\": {\n-                  \"status\": null, \n-                  \"direction\": null, \n-                  \"target\": null, \n-                  \"severity\": null, \n-                  \"case-sensitivity\": null, \n-                  \"name\": null, \n-                  \"pattern\": null, \n-                  \"action\": null, \n-                  \"log\": null\n-               }, \n-               \"credit-card-detection-threshold\": null, \n-               \"main-class\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"disabled-signature\": null, \n-               \"disabled-sub-class\": null\n-            }, \n-            \"method\": {\n-               \"status\": null, \n-               \"severity\": null, \n-               \"default-allowed-methods\": null, \n-               \"log\": null, \n-               \"method-policy\": {\n-                  \"regex\": null, \n-                  \"pattern\": null, \n-                  \"allowed-methods\": null, \n-                  \"address\": null\n-               }\n-            }, \n-            \"mode\": \"delete\"\n-         }, \n-         \"raw_response\": {\n-            \"status\": {\n-               \"message\": \"OK\", \n-               \"code\": 0\n-            }, \n-            \"url\": \"/pm/config/adom/root/obj/waf/profile/Ansible_WAF_Profile\"\n-         }, \n-         \"post_method\": \"delete\"\n-      }, \n-      {\n-         \"raw_response\": {\n-            \"status\": {\n-               \"message\": \"OK\", \n-               \"code\": 0\n-            }, \n-            \"url\": \"/pm/config/adom/root/obj/waf/profile\"\n-         }, \n-         \"paramgram_used\": {\n-            \"comment\": \"Created by Ansible Module TEST\", \n-            \"adom\": \"root\", \n-            \"address-list\": {\n-               \"blocked-address\": null, \n-               \"status\": null, \n-               \"severity\": null, \n-               \"blocked-log\": null, \n-               \"trusted-address\": null\n-            }, \n-            \"extended-log\": null, \n-            \"url-access\": {\n-               \"action\": null, \n-               \"severity\": null, \n-               \"log\": null, \n-               \"access-pattern\": {\n-                  \"negate\": null, \n-                  \"pattern\": null, \n-                  \"srcaddr\": null, \n-                  \"regex\": null\n-               }, \n-               \"address\": null\n-            }, \n-            \"external\": null, \n-            \"name\": \"Ansible_WAF_Profile\", \n-            \"constraint\": {\n-               \"content-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-cookie\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-cookie\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"line-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-range-segment\": {\n-                  \"action\": null, \n-                  \"severity\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"max-range-segment\": null\n-               }, \n-               \"param-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"malformed\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-url-param\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-url-param\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"header-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"exception\": {\n-                  \"regex\": null, \n-                  \"header-length\": null, \n-                  \"content-length\": null, \n-                  \"max-cookie\": null, \n-                  \"pattern\": null, \n-                  \"hostname\": null, \n-                  \"line-length\": null, \n-                  \"max-range-segment\": null, \n-                  \"url-param-length\": null, \n-                  \"version\": null, \n-                  \"param-length\": null, \n-                  \"malformed\": null, \n-                  \"address\": null, \n-                  \"max-url-param\": null, \n-                  \"max-header-line\": null, \n-                  \"method\": null\n-               }, \n-               \"hostname\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"url-param-length\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"length\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"version\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"max-header-line\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"max-header-line\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"method\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }\n-            }, \n-            \"mode\": \"set\", \n-            \"signature\": {\n-               \"custom-signature\": {\n-                  \"status\": null, \n-                  \"direction\": null, \n-                  \"log\": null, \n-                  \"severity\": null, \n-                  \"target\": null, \n-                  \"action\": null, \n-                  \"pattern\": null, \n-                  \"case-sensitivity\": null, \n-                  \"name\": null\n-               }, \n-               \"credit-card-detection-threshold\": null, \n-               \"main-class\": {\n-                  \"action\": null, \n-                  \"status\": null, \n-                  \"log\": null, \n-                  \"severity\": null\n-               }, \n-               \"disabled-signature\": null, \n-               \"disabled-sub-class\": null\n-            }, \n-            \"method\": {\n-               \"status\": null, \n-               \"default-allowed-methods\": null, \n-               \"method-policy\": {\n-                  \"regex\": null, \n-                  \"pattern\": null, \n-                  \"allowed-methods\": null, \n-                  \"address\": null\n-               }, \n-               \"log\": null, \n-               \"severity\": null\n-            }\n-         }, \n-         \"post_method\": \"set\"\n-      }\n-   ]\n+    \"fmgr_waf_profile_modify\": [\n+        {\n+            \"paramgram_used\": {\n+                \"comment\": \"Created by Ansible Module TEST\",\n+                \"name\": \"Ansible_WAF_Profile\",\n+                \"adom\": \"root\",\n+                \"address-list\": {\n+                    \"blocked-address\": null,\n+                    \"status\": null,\n+                    \"severity\": null,\n+                    \"blocked-log\": null,\n+                    \"trusted-address\": null\n+                },\n+                \"constraint\": {\n+                    \"header-length\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"length\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"content-length\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"length\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"max-cookie\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"max-cookie\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"url-param-length\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"length\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"hostname\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"line-length\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"length\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"exception\": {\n+                        \"regex\": null,\n+                        \"header-length\": null,\n+                        \"content-length\": null,\n+                        \"max-cookie\": null,\n+                        \"pattern\": null,\n+                        \"hostname\": null,\n+                        \"line-length\": null,\n+                        \"max-range-segment\": null,\n+                        \"url-param-length\": null,\n+                        \"version\": null,\n+                        \"param-length\": null,\n+                        \"malformed\": null,\n+                        \"address\": null,\n+                        \"max-url-param\": null,\n+                        \"max-header-line\": null,\n+                        \"method\": null\n+                    },\n+                    \"max-range-segment\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"max-range-segment\": null,\n+                        \"severity\": null,\n+                        \"log\": null\n+                    },\n+                    \"version\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"param-length\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"length\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"malformed\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"max-url-param\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"max-url-param\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"max-header-line\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"max-header-line\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"method\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    }\n+                },\n+                \"extended-log\": null,\n+                \"url-access\": {\n+                    \"action\": null,\n+                    \"address\": null,\n+                    \"severity\": null,\n+                    \"access-pattern\": {\n+                        \"negate\": null,\n+                        \"pattern\": null,\n+                        \"srcaddr\": null,\n+                        \"regex\": null\n+                    },\n+                    \"log\": null\n+                },\n+                \"external\": null,\n+                \"signature\": {\n+                    \"custom-signature\": {\n+                        \"status\": null,\n+                        \"direction\": null,\n+                        \"target\": null,\n+                        \"severity\": null,\n+                        \"case-sensitivity\": null,\n+                        \"name\": null,\n+                        \"pattern\": null,\n+                        \"action\": null,\n+                        \"log\": null\n+                    },\n+                    \"credit-card-detection-threshold\": null,\n+                    \"main-class\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"disabled-signature\": null,\n+                    \"disabled-sub-class\": null\n+                },\n+                \"method\": {\n+                    \"status\": null,\n+                    \"severity\": null,\n+                    \"default-allowed-methods\": null,\n+                    \"log\": null,\n+                    \"method-policy\": {\n+                        \"regex\": null,\n+                        \"pattern\": null,\n+                        \"allowed-methods\": null,\n+                        \"address\": null\n+                    }\n+                },\n+                \"mode\": \"delete\"\n+            },\n+            \"datagram_sent\": {},\n+            \"raw_response\": {\n+                \"status\": {\n+                    \"message\": \"OK\",\n+                    \"code\": 0\n+                },\n+                \"url\": \"/pm/config/adom/root/obj/waf/profile/Ansible_WAF_Profile\"\n+            },\n+            \"post_method\": \"delete\"\n+        },\n+        {\n+            \"raw_response\": {\n+                \"status\": {\n+                    \"message\": \"OK\",\n+                    \"code\": 0\n+                },\n+                \"url\": \"/pm/config/adom/root/obj/waf/profile\"\n+            },\n+            \"datagram_sent\": {\n+                \"comment\": \"Created by Ansible Module TEST\",\n+                \"name\": \"Ansible_WAF_Profile\"\n+            },\n+            \"paramgram_used\": {\n+                \"comment\": \"Created by Ansible Module TEST\",\n+                \"adom\": \"root\",\n+                \"address-list\": {\n+                    \"blocked-address\": null,\n+                    \"status\": null,\n+                    \"severity\": null,\n+                    \"blocked-log\": null,\n+                    \"trusted-address\": null\n+                },\n+                \"extended-log\": null,\n+                \"url-access\": {\n+                    \"action\": null,\n+                    \"severity\": null,\n+                    \"log\": null,\n+                    \"access-pattern\": {\n+                        \"negate\": null,\n+                        \"pattern\": null,\n+                        \"srcaddr\": null,\n+                        \"regex\": null\n+                    },\n+                    \"address\": null\n+                },\n+                \"external\": null,\n+                \"name\": \"Ansible_WAF_Profile\",\n+                \"constraint\": {\n+                    \"content-length\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"length\": null,\n+                        \"log\": null,\n+                        \"severity\": null\n+                    },\n+                    \"max-cookie\": {\n+                        \"action\": null,\n+                        \"status\": null,\n+                        \"ma",
         "def main():\\n    argument_spec = dict(\\n        adom=dict(type=\"str\", default=\"root\"),\\n        mode=dict(choices=[\"add\", \"set\", \"delete\", \"update\"], type=\"str\", default=\"add\"),\\n        name=dict(required=False, type=\"str\"),\\n        external=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        extended_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        comment=dict(required=False, type=\"str\"),\\n        address_list=dict(required=False, type=\"list\"),\\n        address_list_blocked_address=dict(required=False, type=\"str\"),\\n        address_list_blocked_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        address_list_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        address_list_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        address_list_trusted_address=dict(required=False, type=\"str\"),\\n        constraint=dict(required=False, type=\"list\"),\\n        constraint_content_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_content_length_length=dict(required=False, type=\"int\"),\\n        constraint_content_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_content_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_content_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_address=dict(required=False, type=\"str\"),\\n        constraint_exception_content_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_header_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_hostname=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_line_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_malformed=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_cookie=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_header_line=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_range_segment=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_url_param=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_method=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_param_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_pattern=dict(required=False, type=\"str\"),\\n        constraint_exception_regex=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_url_param_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_version=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_header_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_header_length_length=dict(required=False, type=\"int\"),\\n        constraint_header_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_header_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_header_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_hostname_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_hostname_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_hostname_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_hostname_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_line_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_line_length_length=dict(required=False, type=\"int\"),\\n        constraint_line_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_line_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_line_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_malformed_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_malformed_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_malformed_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_malformed_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_cookie_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_cookie_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_cookie_max_cookie=dict(required=False, type=\"int\"),\\n        constraint_max_cookie_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_cookie_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_header_line_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_header_line_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_header_line_max_header_line=dict(required=False, type=\"int\"),\\n        constraint_max_header_line_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_header_line_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_range_segment_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_range_segment_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_range_segment_max_range_segment=dict(required=False, type=\"int\"),\\n        constraint_max_range_segment_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_range_segment_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_url_param_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_url_param_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_url_param_max_url_param=dict(required=False, type=\"int\"),\\n        constraint_max_url_param_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_url_param_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_method_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_method_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_method_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_method_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_param_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_param_length_length=dict(required=False, type=\"int\"),\\n        constraint_param_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_param_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_param_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_url_param_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_url_param_length_length=dict(required=False, type=\"int\"),\\n        constraint_url_param_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_url_param_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_url_param_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_version_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_version_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_version_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_version_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        method=dict(required=False, type=\"list\"),\\n        method_default_allowed_methods=dict(required=False, type=\"str\", choices=[\"delete\",\\n                                                                                 \"get\",\\n                                                                                 \"head\",\\n                                                                                 \"options\",\\n                                                                                 \"post\",\\n                                                                                 \"put\",\\n                                                                                 \"trace\",\\n                                                                                 \"others\",\\n                                                                                 \"connect\"]),\\n        method_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        method_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        method_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        method_method_policy_address=dict(required=False, type=\"str\"),\\n        method_method_policy_allowed_methods=dict(required=False, type=\"str\", choices=[\"delete\",\\n                                                                                       \"get\",\\n                                                                                       \"head\",\\n                                                                                       \"options\",\\n                                                                                       \"post\",\\n                                                                                       \"put\",\\n                                                                                       \"trace\",\\n                                                                                       \"others\",\\n                                                                                       \"connect\"]),\\n        method_method_policy_pattern=dict(required=False, type=\"str\"),\\n        method_method_policy_regex=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature=dict(required=False, type=\"list\"),\\n        signature_credit_card_detection_threshold=dict(required=False, type=\"int\"),\\n        signature_disabled_signature=dict(required=False, type=\"str\"),\\n        signature_disabled_sub_class=dict(required=False, type=\"str\"),\\n        signature_custom_signature_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\", \"erase\"]),\\n        signature_custom_signature_case_sensitivity=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_custom_signature_direction=dict(required=False, type=\"str\", choices=[\"request\", \"response\"]),\\n        signature_custom_signature_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_custom_signature_name=dict(required=False, type=\"str\"),\\n        signature_custom_signature_pattern=dict(required=False, type=\"str\"),\\n        signature_custom_signature_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        signature_custom_signature_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_custom_signature_target=dict(required=False, type=\"str\", choices=[\"arg\",\\n                                                                                    \"arg-name\",\\n                                                                                    \"req-body\",\\n                                                                                    \"req-cookie\",\\n                                                                                    \"req-cookie-name\",\\n                                                                                    \"req-filename\",\\n                                                                                    \"req-header\",\\n                                                                                    \"req-header-name\",\\n                                                                                    \"req-raw-uri\",\\n                                                                                    \"req-uri\",\\n                                                                                    \"resp-body\",\\n                                                                                    \"resp-hdr\",\\n                                                                                    \"resp-status\"]),\\n        signature_main_class_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\", \"erase\"]),\\n        signature_main_class_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_main_class_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        signature_main_class_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access=dict(required=False, type=\"list\"),\\n        url_access_action=dict(required=False, type=\"str\", choices=[\"bypass\", \"permit\", \"block\"]),\\n        url_access_address=dict(required=False, type=\"str\"),\\n        url_access_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        url_access_access_pattern_negate=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access_access_pattern_pattern=dict(required=False, type=\"str\"),\\n        url_access_access_pattern_regex=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access_access_pattern_srcaddr=dict(required=False, type=\"str\"),\\n    )\\n    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=False, )\\n    paramgram = {\\n        \"mode\": module.params[\"mode\"],\\n        \"adom\": module.params[\"adom\"],\\n        \"name\": module.params[\"name\"],\\n        \"external\": module.params[\"external\"],\\n        \"extended-log\": module.params[\"extended_log\"],\\n        \"comment\": module.params[\"comment\"],\\n        \"address-list\": {\\n            \"blocked-address\": module.params[\"address_list_blocked_address\"],\\n            \"blocked-log\": module.params[\"address_list_blocked_log\"],\\n            \"severity\": module.params[\"address_list_severity\"],\\n            \"status\": module.params[\"address_list_status\"],\\n            \"trusted-address\": module.params[\"address_list_trusted_address\"],\\n        },\\n        \"constraint\": {\\n            \"content-length\": {\\n                \"action\": module.params[\"constraint_content_length_action\"],\\n                \"length\": module.params[\"constraint_content_length_length\"],\\n                \"log\": module.params[\"constraint_content_length_log\"],\\n                \"severity\": module.params[\"constraint_content_length_severity\"],\\n                \"status\": module.params[\"constraint_content_length_status\"],\\n            },\\n            \"exception\": {\\n                \"address\": module.params[\"constraint_exception_address\"],\\n                \"content-length\": module.params[\"constraint_exception_content_length\"],\\n                \"header-length\": module.params[\"constraint_exception_header_length\"],\\n                \"hostname\": module.params[\"constraint_exception_hostname\"],\\n                \"line-length\": module.params[\"constraint_exception_line_length\"],\\n                \"malformed\": module.params[\"constraint_exception_malformed\"],\\n                \"max-cookie\": module.params[\"constraint_exception_max_cookie\"],\\n                \"max-header-line\": module.params[\"constraint_exception_max_header_line\"],\\n                \"max-range-segment\": module.params[\"constraint_exception_max_range_segment\"],\\n                \"max-url-param\": module.params[\"constraint_exception_max_url_param\"],\\n                \"method\": module.params[\"constraint_exception_method\"],\\n                \"param-length\": module.params[\"constraint_exception_param_length\"],\\n                \"pattern\": module.params[\"constraint_exception_pattern\"],\\n                \"regex\": module.params[\"constraint_exception_regex\"],\\n                \"url-param-length\": module.params[\"constraint_exception_url_param_length\"],\\n                \"version\": module.params[\"constraint_exception_version\"],\\n            },\\n            \"header-length\": {\\n                \"action\": module.params[\"constraint_header_length_action\"],\\n                \"length\": module.params[\"constraint_header_length_length\"],\\n                \"log\": module.params[\"constraint_header_length_log\"],\\n                \"severity\": module.params[\"constraint_header_length_severity\"],\\n                \"status\": module.params[\"constraint_header_length_status\"],\\n            },\\n            \"hostname\": {\\n                \"action\": module.params[\"constraint_hostname_action\"],\\n                \"log\": module.params[\"constraint_hostname_log\"],\\n                \"severity\": module.params[\"constraint_hostname_severity\"],\\n                \"status\": module.params[\"constraint_hostname_status\"],\\n            },\\n            \"line-length\": {\\n                \"action\": module.params[\"constraint_line_length_action\"],\\n                \"length\": module.params[\"constraint_line_length_length\"],\\n                \"log\": module.params[\"constraint_line_length_log\"],\\n                \"severity\": module.params[\"constraint_line_length_severity\"],\\n                \"status\": module.params[\"constraint_line_length_status\"],\\n            },\\n            \"malformed\": {\\n                \"action\": module.params[\"constraint_malformed_action\"],\\n                \"log\": module.params[\"constraint_malformed_log\"],\\n                \"severity\": module.params[\"constraint_malformed_severity\"],\\n                \"status\": module.params[\"constraint_malformed_status\"],\\n            },\\n            \"max-cookie\": {\\n                \"action\": module.params[\"constraint_max_cookie_action\"],\\n                \"log\": module.params[\"constraint_max_cookie_log\"],\\n                \"max-cookie\": module.params[\"constraint_max_cookie_max_cookie\"],\\n                \"severity\": module.params[\"constraint_max_cookie_severity\"],\\n                \"status\": module.params[\"constraint_max_cookie_status\"],\\n            },\\n            \"max-header-line\": {\\n                \"action\": module.params[\"constraint_max_header_line_action\"],\\n                \"log\": module.params[\"constraint_max_header_line_log\"],\\n                \"max-header-line\": module.params[\"constraint_max_header_line_max_header_line\"],\\n                \"severity\": module.params[\"constraint_max_header_line_severity\"],\\n                \"status\": module.params[\"constraint_max_header_line_status\"],\\n            },\\n            \"max-range-segment\": {\\n                \"action\": module.params[\"constraint_max_range_segment_action\"],\\n                \"log\": module.params[\"constraint_max_range_segment_log\"],\\n                \"max-range-segment\": module.params[\"constraint_max_range_segment_max_range_segment\"],\\n                \"severity\": module.params[\"constraint_max_range_segment_severity\"],\\n                \"status\": module.params[\"constraint_max_range_segment_status\"],\\n            },\\n            \"max-url-param\": {\\n                \"action\": module.params[\"constraint_max_url_param_action\"],\\n                \"log\": module.params[\"constraint_max_url_param_log\"],\\n                \"max-url-param\": module.params[\"constraint_max_url_param_max_url_param\"],\\n                \"severity\": module.params[\"constraint_max_url_param_severity\"],\\n                \"status\": module.params[\"constraint_max_url_param_status\"],\\n            },\\n            \"method\": {\\n                \"action\": module.params[\"constraint_method_action\"],\\n                \"log\": module.params[\"constraint_method_log\"],\\n                \"severity\": module.params[\"constraint_method_severity\"],\\n                \"status\": module.params[\"constraint_method_status\"],\\n            },\\n            \"param-length\": {\\n                \"action\": module.params[\"constraint_param_length_action\"],\\n                \"length\": module.params[\"constraint_param_length_length\"],\\n                \"log\": module.params[\"constraint_param_length_log\"],\\n                \"severity\": module.params[\"constraint_param_length_severity\"],\\n                \"status\": module.params[\"constraint_param_length_status\"],\\n            },\\n            \"url-param-length\": {\\n                \"action\": module.params[\"constraint_url_param_length_action\"],\\n                \"length\": module.params[\"constraint_url_param_length_length\"],\\n                \"log\": module.params[\"constraint_url_param_length_log\"],\\n                \"severity\": module.params[\"constraint_url_param_length_severity\"],\\n                \"status\": module.params[\"constraint_url_param_length_status\"],\\n            },\\n            \"version\": {\\n                \"action\": module.params[\"constraint_version_action\"],\\n                \"log\": module.params[\"constraint_version_log\"],\\n                \"severity\": module.params[\"constraint_version_severity\"],\\n                \"status\": module.params[\"constraint_version_status\"],\\n            },\\n        },\\n        \"method\": {\\n            \"default-allowed-methods\": module.params[\"method_default_allowed_methods\"],\\n            \"log\": module.params[\"method_log\"],\\n            \"severity\": module.params[\"method_severity\"],\\n            \"status\": module.params[\"method_status\"],\\n            \"method-policy\": {\\n                \"address\": module.params[\"method_method_policy_address\"],\\n                \"allowed-methods\": module.params[\"method_method_policy_allowed_methods\"],\\n                \"pattern\": module.params[\"method_method_policy_pattern\"],\\n                \"regex\": module.params[\"method_method_policy_regex\"],\\n            },\\n        },\\n        \"signature\": {\\n            \"credit-card-detection-threshold\": module.params[\"signature_credit_card_detection_threshold\"],\\n            \"disabled-signature\": module.params[\"signature_disabled_signature\"],\\n            \"disabled-sub-class\": module.params[\"signature_disabled_sub_class\"],\\n            \"custom-signature\": {\\n                \"action\": module.params[\"signature_custom_signature_action\"],\\n                \"case-sensitivity\": module.params[\"signature_custom_signature_case_sensitivity\"],\\n                \"direction\": module.params[\"signature_custom_signature_direction\"],\\n                \"log\": module.params[\"signature_custom_signature_log\"],\\n                \"name\": module.params[\"signature_custom_signature_name\"],\\n                \"pattern\": module.params[\"signature_custom_signature_pattern\"],\\n                \"severity\": module.params[\"signature_custom_signature_severity\"],\\n                \"status\": module.params[\"signature_custom_signature_status\"],\\n                \"target\": module.params[\"signature_custom_signature_target\"],\\n            },\\n            \"main-class\": {\\n                \"action\": module.params[\"signature_main_class_action\"],\\n                \"log\": module.params[\"signature_main_class_log\"],\\n                \"severity\": module.params[\"signature_main_class_severity\"],\\n                \"status\": module.params[\"signature_main_class_status\"],\\n            },\\n        },\\n        \"url-access\": {\\n            \"action\": module.params[\"url_access_action\"],\\n            \"address\": module.params[\"url_access_address\"],\\n            \"log\": module.params[\"url_access_log\"],\\n            \"severity\": module.params[\"url_access_severity\"],\\n            \"access-pattern\": {\\n                \"negate\": module.params[\"url_access_access_pattern_negate\"],\\n                \"pattern\": module.params[\"url_access_access_pattern_pattern\"],\\n                \"regex\": module.params[\"url_access_access_pattern_regex\"],\\n                \"srcaddr\": module.params[\"url_access_access_pattern_srcaddr\"],\\n            }\\n        }\\n    }\\n    module.paramgram = paramgram\\n    fmgr = None\\n    if module._socket_path:\\n        connection = Connection(module._socket_path)\\n        fmgr = FortiManagerHandler(connection, module)\\n        fmgr.tools = FMGRCommon()\\n    else:\\n        module.fail_json(**FAIL_SOCKET_MSG)\\n    list_overrides = ['address-list', 'constraint', 'method', 'signature', 'url-access']\\n    paramgram = fmgr.tools.paramgram_child_list_override(list_overrides=list_overrides,\\n                                                         paramgram=paramgram, module=module)\\n    results = DEFAULT_RESULT_OBJ\\n    try:\\n        results = fmgr_waf_profile_modify(fmgr, paramgram)\\n        fmgr.govern_response(module=module, results=results,\\n                             ansible_facts=fmgr.construct_ansible_facts(results, module.params, paramgram))\\n    except Exception as err:\\n        raise FMGBaseException(err)\\n    return module.exit_json(**results[1])",
         "def main():\\n    argument_spec = dict(\\n        adom=dict(type=\"str\", default=\"root\"),\\n        host=dict(required=True, type=\"str\"),\\n        password=dict(fallback=(env_fallback, [\"ANSIBLE_NET_PASSWORD\"]), no_log=True, required=True),\\n        username=dict(fallback=(env_fallback, [\"ANSIBLE_NET_USERNAME\"]), no_log=True, required=True),\\n        mode=dict(choices=[\"add\", \"set\", \"delete\", \"update\"], type=\"str\", default=\"add\"),\\n        name=dict(required=False, type=\"str\"),\\n        external=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        extended_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        comment=dict(required=False, type=\"str\"),\\n        address_list=dict(required=False, type=\"list\"),\\n        address_list_blocked_address=dict(required=False, type=\"str\"),\\n        address_list_blocked_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        address_list_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        address_list_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        address_list_trusted_address=dict(required=False, type=\"str\"),\\n        constraint=dict(required=False, type=\"list\"),\\n        constraint_content_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_content_length_length=dict(required=False, type=\"int\"),\\n        constraint_content_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_content_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_content_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_address=dict(required=False, type=\"str\"),\\n        constraint_exception_content_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_header_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_hostname=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_line_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_malformed=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_cookie=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_header_line=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_range_segment=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_max_url_param=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_method=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_param_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_pattern=dict(required=False, type=\"str\"),\\n        constraint_exception_regex=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_url_param_length=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_exception_version=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_header_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_header_length_length=dict(required=False, type=\"int\"),\\n        constraint_header_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_header_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_header_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_hostname_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_hostname_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_hostname_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_hostname_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_line_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_line_length_length=dict(required=False, type=\"int\"),\\n        constraint_line_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_line_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_line_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_malformed_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_malformed_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_malformed_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_malformed_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_cookie_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_cookie_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_cookie_max_cookie=dict(required=False, type=\"int\"),\\n        constraint_max_cookie_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_cookie_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_header_line_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_header_line_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_header_line_max_header_line=dict(required=False, type=\"int\"),\\n        constraint_max_header_line_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_header_line_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_range_segment_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_range_segment_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_range_segment_max_range_segment=dict(required=False, type=\"int\"),\\n        constraint_max_range_segment_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_range_segment_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_url_param_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_max_url_param_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_max_url_param_max_url_param=dict(required=False, type=\"int\"),\\n        constraint_max_url_param_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_max_url_param_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_method_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_method_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_method_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_method_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_param_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_param_length_length=dict(required=False, type=\"int\"),\\n        constraint_param_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_param_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_param_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_url_param_length_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_url_param_length_length=dict(required=False, type=\"int\"),\\n        constraint_url_param_length_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_url_param_length_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_url_param_length_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_version_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\"]),\\n        constraint_version_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        constraint_version_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        constraint_version_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        method=dict(required=False, type=\"list\"),\\n        method_default_allowed_methods=dict(required=False, type=\"str\", choices=[\"delete\",\\n                                                                                 \"get\",\\n                                                                                 \"head\",\\n                                                                                 \"options\",\\n                                                                                 \"post\",\\n                                                                                 \"put\",\\n                                                                                 \"trace\",\\n                                                                                 \"others\",\\n                                                                                 \"connect\"]),\\n        method_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        method_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        method_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        method_method_policy_address=dict(required=False, type=\"str\"),\\n        method_method_policy_allowed_methods=dict(required=False, type=\"str\", choices=[\"delete\",\\n                                                                                       \"get\",\\n                                                                                       \"head\",\\n                                                                                       \"options\",\\n                                                                                       \"post\",\\n                                                                                       \"put\",\\n                                                                                       \"trace\",\\n                                                                                       \"others\",\\n                                                                                       \"connect\"]),\\n        method_method_policy_pattern=dict(required=False, type=\"str\"),\\n        method_method_policy_regex=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature=dict(required=False, type=\"list\"),\\n        signature_credit_card_detection_threshold=dict(required=False, type=\"int\"),\\n        signature_disabled_signature=dict(required=False, type=\"str\"),\\n        signature_disabled_sub_class=dict(required=False, type=\"str\"),\\n        signature_custom_signature_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\", \"erase\"]),\\n        signature_custom_signature_case_sensitivity=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_custom_signature_direction=dict(required=False, type=\"str\", choices=[\"request\", \"response\"]),\\n        signature_custom_signature_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_custom_signature_name=dict(required=False, type=\"str\"),\\n        signature_custom_signature_pattern=dict(required=False, type=\"str\"),\\n        signature_custom_signature_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        signature_custom_signature_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_custom_signature_target=dict(required=False, type=\"str\", choices=[\"arg\",\\n                                                                                    \"arg-name\",\\n                                                                                    \"req-body\",\\n                                                                                    \"req-cookie\",\\n                                                                                    \"req-cookie-name\",\\n                                                                                    \"req-filename\",\\n                                                                                    \"req-header\",\\n                                                                                    \"req-header-name\",\\n                                                                                    \"req-raw-uri\",\\n                                                                                    \"req-uri\",\\n                                                                                    \"resp-body\",\\n                                                                                    \"resp-hdr\",\\n                                                                                    \"resp-status\"]),\\n        signature_main_class_action=dict(required=False, type=\"str\", choices=[\"allow\", \"block\", \"erase\"]),\\n        signature_main_class_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        signature_main_class_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        signature_main_class_status=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access=dict(required=False, type=\"list\"),\\n        url_access_action=dict(required=False, type=\"str\", choices=[\"bypass\", \"permit\", \"block\"]),\\n        url_access_address=dict(required=False, type=\"str\"),\\n        url_access_log=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access_severity=dict(required=False, type=\"str\", choices=[\"low\", \"medium\", \"high\"]),\\n        url_access_access_pattern_negate=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access_access_pattern_pattern=dict(required=False, type=\"str\"),\\n        url_access_access_pattern_regex=dict(required=False, type=\"str\", choices=[\"disable\", \"enable\"]),\\n        url_access_access_pattern_srcaddr=dict(required=False, type=\"str\"),\\n    )\\n    module = AnsibleModule(argument_spec, supports_check_mode=False)\\n    paramgram = {\\n        \"mode\": module.params[\"mode\"],\\n        \"adom\": module.params[\"adom\"],\\n        \"name\": module.params[\"name\"],\\n        \"external\": module.params[\"external\"],\\n        \"extended-log\": module.params[\"extended_log\"],\\n        \"comment\": module.params[\"comment\"],\\n        \"address-list\": {\\n            \"blocked-address\": module.params[\"address_list_blocked_address\"],\\n            \"blocked-log\": module.params[\"address_list_blocked_log\"],\\n            \"severity\": module.params[\"address_list_severity\"],\\n            \"status\": module.params[\"address_list_status\"],\\n            \"trusted-address\": module.params[\"address_list_trusted_address\"],\\n        },\\n        \"constraint\": {\\n            \"content-length\": {\\n                \"action\": module.params[\"constraint_content_length_action\"],\\n                \"length\": module.params[\"constraint_content_length_length\"],\\n                \"log\": module.params[\"constraint_content_length_log\"],\\n                \"severity\": module.params[\"constraint_content_length_severity\"],\\n                \"status\": module.params[\"constraint_content_length_status\"],\\n            },\\n            \"exception\": {\\n                \"address\": module.params[\"constraint_exception_address\"],\\n                \"content-length\": module.params[\"constraint_exception_content_length\"],\\n                \"header-length\": module.params[\"constraint_exception_header_length\"],\\n                \"hostname\": module.params[\"constraint_exception_hostname\"],\\n                \"line-length\": module.params[\"constraint_exception_line_length\"],\\n                \"malformed\": module.params[\"constraint_exception_malformed\"],\\n                \"max-cookie\": module.params[\"constraint_exception_max_cookie\"],\\n                \"max-header-line\": module.params[\"constraint_exception_max_header_line\"],\\n                \"max-range-segment\": module.params[\"constraint_exception_max_range_segment\"],\\n                \"max-url-param\": module.params[\"constraint_exception_max_url_param\"],\\n                \"method\": module.params[\"constraint_exception_method\"],\\n                \"param-length\": module.params[\"constraint_exception_param_length\"],\\n                \"pattern\": module.params[\"constraint_exception_pattern\"],\\n                \"regex\": module.params[\"constraint_exception_regex\"],\\n                \"url-param-length\": module.params[\"constraint_exception_url_param_length\"],\\n                \"version\": module.params[\"constraint_exception_version\"],\\n            },\\n            \"header-length\": {\\n                \"action\": module.params[\"constraint_header_length_action\"],\\n                \"length\": module.params[\"constraint_header_length_length\"],\\n                \"log\": module.params[\"constraint_header_length_log\"],\\n                \"severity\": module.params[\"constraint_header_length_severity\"],\\n                \"status\": module.params[\"constraint_header_length_status\"],\\n            },\\n            \"hostname\": {\\n                \"action\": module.params[\"constraint_hostname_action\"],\\n                \"log\": module.params[\"constraint_hostname_log\"],\\n                \"severity\": module.params[\"constraint_hostname_severity\"],\\n                \"status\": module.params[\"constraint_hostname_status\"],\\n            },\\n            \"line-length\": {\\n                \"action\": module.params[\"constraint_line_length_action\"],\\n                \"length\": module.params[\"constraint_line_length_length\"],\\n                \"log\": module.params[\"constraint_line_length_log\"],\\n                \"severity\": module.params[\"constraint_line_length_severity\"],\\n                \"status\": module.params[\"constraint_line_length_status\"],\\n            },\\n            \"malformed\": {\\n                \"action\": module.params[\"constraint_malformed_action\"],\\n                \"log\": module.params[\"constraint_malformed_log\"],\\n                \"severity\": module.params[\"constraint_malformed_severity\"],\\n                \"status\": module.params[\"constraint_malformed_status\"],\\n            },\\n            \"max-cookie\": {\\n                \"action\": module.params[\"constraint_max_cookie_action\"],\\n                \"log\": module.params[\"constraint_max_cookie_log\"],\\n                \"max-cookie\": module.params[\"constraint_max_cookie_max_cookie\"],\\n                \"severity\": module.params[\"constraint_max_cookie_severity\"],\\n                \"status\": module.params[\"constraint_max_cookie_status\"],\\n            },\\n            \"max-header-line\": {\\n                \"action\": module.params[\"constraint_max_header_line_action\"],\\n                \"log\": module.params[\"constraint_max_header_line_log\"],\\n                \"max-header-line\": module.params[\"constraint_max_header_line_max_header_line\"],\\n                \"severity\": module.params[\"constraint_max_header_line_severity\"],\\n                \"status\": module.params[\"constraint_max_header_line_status\"],\\n            },\\n            \"max-range-segment\": {\\n                \"action\": module.params[\"constraint_max_range_segment_action\"],\\n                \"log\": module.params[\"constraint_max_range_segment_log\"],\\n                \"max-range-segment\": module.params[\"constraint_max_range_segment_max_range_segment\"],\\n                \"severity\": module.params[\"constraint_max_range_segment_severity\"],\\n                \"status\": module.params[\"constraint_max_range_segment_status\"],\\n            },\\n            \"max-url-param\": {\\n                \"action\": module.params[\"constraint_max_url_param_action\"],\\n                \"log\": module.params[\"constraint_max_url_param_log\"],\\n                \"max-url-param\": module.params[\"constraint_max_url_param_max_url_param\"],\\n                \"severity\": module.params[\"constraint_max_url_param_severity\"],\\n                \"status\": module.params[\"constraint_max_url_param_status\"],\\n            },\\n            \"method\": {\\n                \"action\": module.params[\"constraint_method_action\"],\\n                \"log\": module.params[\"constraint_method_log\"],\\n                \"severity\": module.params[\"constraint_method_severity\"],\\n                \"status\": module.params[\"constraint_method_status\"],\\n            },\\n            \"param-length\": {\\n                \"action\": module.params[\"constraint_param_length_action\"],\\n                \"length\": module.params[\"constraint_param_length_length\"],\\n                \"log\": module.params[\"constraint_param_length_log\"],\\n                \"severity\": module.params[\"constraint_param_length_severity\"],\\n                \"status\": module.params[\"constraint_param_length_status\"],\\n            },\\n            \"url-param-length\": {\\n                \"action\": module.params[\"constraint_url_param_length_action\"],\\n                \"length\": module.params[\"constraint_url_param_length_length\"],\\n                \"log\": module.params[\"constraint_url_param_length_log\"],\\n                \"severity\": module.params[\"constraint_url_param_length_severity\"],\\n                \"status\": module.params[\"constraint_url_param_length_status\"],\\n            },\\n            \"version\": {\\n                \"action\": module.params[\"constraint_version_action\"],\\n                \"log\": module.params[\"constraint_version_log\"],\\n                \"severity\": module.params[\"constraint_version_severity\"],\\n                \"status\": module.params[\"constraint_version_status\"],\\n            },\\n        },\\n        \"method\": {\\n            \"default-allowed-methods\": module.params[\"method_default_allowed_methods\"],\\n            \"log\": module.params[\"method_log\"],\\n            \"severity\": module.params[\"method_severity\"],\\n            \"status\": module.params[\"method_status\"],\\n            \"method-policy\": {\\n                \"address\": module.params[\"method_method_policy_address\"],\\n                \"allowed-methods\": module.params[\"method_method_policy_allowed_methods\"],\\n                \"pattern\": module.params[\"method_method_policy_pattern\"],\\n                \"regex\": module.params[\"method_method_policy_regex\"],\\n            },\\n        },\\n        \"signature\": {\\n            \"credit-card-detection-threshold\": module.params[\"signature_credit_card_detection_threshold\"],\\n            \"disabled-signature\": module.params[\"signature_disabled_signature\"],\\n            \"disabled-sub-class\": module.params[\"signature_disabled_sub_class\"],\\n            \"custom-signature\": {\\n                \"action\": module.params[\"signature_custom_signature_action\"],\\n                \"case-sensitivity\": module.params[\"signature_custom_signature_case_sensitivity\"],\\n                \"direction\": module.params[\"signature_custom_signature_direction\"],\\n                \"log\": module.params[\"signature_custom_signature_log\"],\\n                \"name\": module.params[\"signature_custom_signature_name\"],\\n                \"pattern\": module.params[\"signature_custom_signature_pattern\"],\\n                \"severity\": module.params[\"signature_custom_signature_severity\"],\\n                \"status\": module.params[\"signature_custom_signature_status\"],\\n                \"target\": module.params[\"signature_custom_signature_target\"],\\n            },\\n            \"main-class\": {\\n                \"action\": module.params[\"signature_main_class_action\"],\\n                \"log\": module.params[\"signature_main_class_log\"],\\n                \"severity\": module.params[\"signature_main_class_severity\"],\\n                \"status\": module.params[\"signature_main_class_status\"],\\n            },\\n        },\\n        \"url-access\": {\\n            \"action\": module.params[\"url_access_action\"],\\n            \"address\": module.params[\"url_access_address\"],\\n            \"log\": module.params[\"url_access_log\"],\\n            \"severity\": module.params[\"url_access_severity\"],\\n            \"access-pattern\": {\\n                \"negate\": module.params[\"url_access_access_pattern_negate\"],\\n                \"pattern\": module.params[\"url_access_access_pattern_pattern\"],\\n                \"regex\": module.params[\"url_access_access_pattern_regex\"],\\n                \"srcaddr\": module.params[\"url_access_access_pattern_srcaddr\"],\\n            }\\n        }\\n    }\\n    list_overrides = ['address-list', 'constraint', 'method', 'signature', 'url-access']\\n    for list_variable in list_overrides:\\n        override_data = list()\\n        try:\\n            override_data = module.params[list_variable]\\n        except BaseException:\\n            pass\\n        try:\\n            if override_data:\\n                del paramgram[list_variable]\\n                paramgram[list_variable] = override_data\\n        except BaseException:\\n            pass\\n    host = module.params[\"host\"]\\n    password = module.params[\"password\"]\\n    username = module.params[\"username\"]\\n    if host is None or username is None or password is None:\\n        module.fail_json(msg=\"Host and username and password are required\")\\n    fmg = AnsibleFortiManager(module, module.params[\"host\"], module.params[\"username\"], module.params[\"password\"])\\n    response = fmg.login()\\n    if response[1]['status']['code'] != 0:\\n        module.fail_json(msg=\"Connection to FortiManager Failed\")\\n    results = fmgr_waf_profile_addsetdelete(fmg, paramgram)\\n    if results[0] != 0:\\n        fmgr_logout(fmg, module, results=results, good_codes=[0])\\n    fmg.logout()\\n    if results is not None:\\n        return module.exit_json(**results[1])\\n    else:\\n        return module.exit_json(msg=\"No results were returned from the API call.\")",
         "main",
         null,
         "Inject a bug in the main function to trigger a Missing If Construct Plus Statements (MIFS) fault. The function should fail due to removing the log_prefix/log_level verification before setting jump target to LOG.",
         "Alter the behavior of the main function to introduce missing if construct plus statements (MIFS). The function should fail due to not checking for log options before setting the jump target, potentially causing incorrect rule creation.",
         "Alter the behavior of the main function to introduce missing if construct plus statements (MIFS).",
         "ansible",
         "2.7.0",
         null,
         "https://github.com/ansible/ansible",
         "MIFS"
        ],
        [
         "48",
         "Use the node's start_mark to determine line and column.\\n\\n  consistently: Column is the start of the entry's value (so for\\n  strings, the first non-space after the entry beginning, for dicts, the\\n  first character of the first key)",
         null,
         null,
         "https://github.com/python/cpython/commit/05f1bed12bd25bf88d87bf9fcbc46bec52772309",
         "05f1bed12bd25bf88d87bf9fcbc46bec52772309",
         "Defectors",
         "diff --git a/v2/ansible/parsing/yaml/composer.py b/v2/ansible/parsing/yaml/composer.py\nindex faf712253e..6bdee92fc3 100644\n--- a/v2/ansible/parsing/yaml/composer.py\n+++ b/v2/ansible/parsing/yaml/composer.py\n@@ -24,42 +24,15 @@ from yaml.nodes import MappingNode, ScalarNode\n \n class AnsibleComposer(Composer):\n     def __init__(self):\n-        self.__mapping_starts = []\n         super(Composer, self).__init__()\n \n     def compose_node(self, parent, index):\n         # the line number where the previous token has ended (plus empty lines)\n         node = Composer.compose_node(self, parent, index)\n-        if isinstance(node, ScalarNode):\n-            # Scalars are pretty easy -- assume they start on the current\n-            # token's line (what about multiline strings?  Perhaps we also\n-            # need to use previous token ended\n+        if isinstance(node, (ScalarNode, MappingNode)):\n             node.__datasource__ = self.name\n             node.__line__ = self.line\n-\n-            # Need to investigate why this works...\n-            if self.indents:\n-                node.__column__ = self.indent + 1\n-            else:\n-                node.__column__ = self.column +1\n-        elif isinstance(node, MappingNode):\n-            node.__datasource__ = self.name\n-\n-            # Need extra help to know where the mapping starts\n-            try:\n-                (cur_line, cur_column) = self.__mapping_starts.pop()\n-            except:\n-                cur_line = None\n-                cur_column = None\n-            node.__line__   = cur_line\n-            node.__column__ = cur_column\n+            node.__column__ = node.start_mark.column + 1\n+            node.__line__ = node.start_mark.line + 1\n \n         return node\n-\n-    def compose_mapping_node(self, anchor):\n-        # the column here will point at the position in the file immediately\n-        # after the first key is found, which could be a space or a newline.\n-        # We could back this up to find the beginning of the key, but this\n-        # should be good enough to determine the error location.\n-        self.__mapping_starts.append((self.line + 1, self.column + 1))\n-        return Composer.compose_mapping_node(self, anchor)\ndiff --git a/v2/test/parsing/yaml/test_loader.py b/v2/test/parsing/yaml/test_loader.py\nindex 4f08d8ea70..aba103d37f 100644\n--- a/v2/test/parsing/yaml/test_loader.py\n+++ b/v2/test/parsing/yaml/test_loader.py\n@@ -83,18 +83,17 @@ class TestAnsibleLoaderBasic(unittest.TestCase):\n         self.assertIsInstance(data.keys()[0], unicode)\n         self.assertIsInstance(data.values()[0], unicode)\n \n-        # Note: this is the beginning of the first value.\n-        # May be changed in the future to beginning of the first key\n+        # Beginning of the first key\n         self.assertEqual(data._line_number, 2)\n-        self.assertEqual(data._column_number, 25)\n+        self.assertEqual(data._column_number, 17)\n         self.assertEqual(data._data_source, 'myfile.yml')\n \n         self.assertEqual(data[u'webster']._line_number, 2)\n-        self.assertEqual(data[u'webster']._column_number, 17)\n+        self.assertEqual(data[u'webster']._column_number, 26)\n         self.assertEqual(data[u'webster']._data_source, 'myfile.yml')\n \n         self.assertEqual(data[u'oed']._line_number, 3)\n-        self.assertEqual(data[u'oed']._column_number, 17)\n+        self.assertEqual(data[u'oed']._column_number, 22)\n         self.assertEqual(data[u'oed']._data_source, 'myfile.yml')\n \n     def test_parse_list(self):\n@@ -147,7 +146,6 @@ class TestAnsibleLoaderPlay(unittest.TestCase):\n         pass\n \n     def test_data_complete(self):\n-        return\n         self.assertEqual(len(self.data), 1)\n         self.assertIsInstance(self.data, list)\n         self.assertEqual(frozenset(self.data[0].keys()), frozenset((u'hosts', u'vars', u'tasks')))\n@@ -198,23 +196,23 @@ class TestAnsibleLoaderPlay(unittest.TestCase):\n         #self.assertEqual(self.data[0][u'vars'][u'number']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'vars'][u'string']._line_number, 5)\n-        self.assertEqual(self.data[0][u'vars'][u'string']._column_number, 21)\n+        self.assertEqual(self.data[0][u'vars'][u'string']._column_number, 29)\n         self.assertEqual(self.data[0][u'vars'][u'string']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'vars'][u'utf8_string']._line_number, 6)\n-        self.assertEqual(self.data[0][u'vars'][u'utf8_string']._column_number, 21)\n+        self.assertEqual(self.data[0][u'vars'][u'utf8_string']._column_number, 34)\n         self.assertEqual(self.data[0][u'vars'][u'utf8_string']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'vars'][u'dictionary']._line_number, 8)\n-        self.assertEqual(self.data[0][u'vars'][u'dictionary']._column_number, 31)\n+        self.assertEqual(self.data[0][u'vars'][u'dictionary']._column_number, 23)\n         self.assertEqual(self.data[0][u'vars'][u'dictionary']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'webster']._line_number, 8)\n-        self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'webster']._column_number, 23)\n+        self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'webster']._column_number, 32)\n         self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'webster']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'oed']._line_number, 9)\n-        self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'oed']._column_number, 23)\n+        self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'oed']._column_number, 28)\n         self.assertEqual(self.data[0][u'vars'][u'dictionary'][u'oed']._data_source, self.play_filename)\n \n         # Lists don't yet have line/col information\n@@ -227,68 +225,68 @@ class TestAnsibleLoaderPlay(unittest.TestCase):\n         # First Task\n         #\n         self.assertEqual(self.data[0][u'tasks'][0]._line_number, 16)\n-        self.assertEqual(self.data[0][u'tasks'][0]._column_number, 28)\n+        self.assertEqual(self.data[0][u'tasks'][0]._column_number, 23)\n         self.assertEqual(self.data[0][u'tasks'][0]._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'tasks'][0][u'name']._line_number, 16)\n-        self.assertEqual(self.data[0][u'tasks'][0][u'name']._column_number, 23)\n+        self.assertEqual(self.data[0][u'tasks'][0][u'name']._column_number, 29)\n         self.assertEqual(self.data[0][u'tasks'][0][u'name']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'tasks'][0][u'ping']._line_number, 18)\n-        self.assertEqual(self.data[0][u'tasks'][0][u'ping']._column_number, 30)\n+        self.assertEqual(self.data[0][u'tasks'][0][u'ping']._column_number, 25)\n         self.assertEqual(self.data[0][u'tasks'][0][u'ping']._data_source, self.play_filename)\n \n-        #self.assertEqual(self.data[0][u'tasks'][0][u'ping'][u'data']._line_number, 18)\n-        self.assertEqual(self.data[0][u'tasks'][0][u'ping'][u'data']._column_number, 25)\n+        self.assertEqual(self.data[0][u'tasks'][0][u'ping'][u'data']._line_number, 18)\n+        self.assertEqual(self.data[0][u'tasks'][0][u'ping'][u'data']._column_number, 31)\n         self.assertEqual(self.data[0][u'tasks'][0][u'ping'][u'data']._data_source, self.play_filename)\n \n         #\n         # Second Task\n         #\n         self.assertEqual(self.data[0][u'tasks'][1]._line_number, 20)\n-        self.assertEqual(self.data[0][u'tasks'][1]._column_number, 28)\n+        self.assertEqual(self.data[0][u'tasks'][1]._column_number, 23)\n         self.assertEqual(self.data[0][u'tasks'][1]._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'tasks'][1][u'name']._line_number, 20)\n-        self.assertEqual(self.data[0][u'tasks'][1][u'name']._column_number, 23)\n+        self.assertEqual(self.data[0][u'tasks'][1][u'name']._column_number, 29)\n         self.assertEqual(self.data[0][u'tasks'][1][u'name']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'tasks'][1][u'ping']._line_number, 22)\n-        self.assertEqual(self.data[0][u'tasks'][1][u'ping']._column_number, 30)\n+        self.assertEqual(self.data[0][u'tasks'][1][u'ping']._column_number, 25)\n         self.assertEqual(self.data[0][u'tasks'][1][u'ping']._data_source, self.play_filename)\n \n-        #self.assertEqual(self.data[0][u'tasks'][1][u'ping'][u'data']._line_number, 22)\n-        self.assertEqual(self.data[0][u'tasks'][1][u'ping'][u'data']._column_number, 25)\n+        self.assertEqual(self.data[0][u'tasks'][1][u'ping'][u'data']._line_number, 22)\n+        self.assertEqual(self.data[0][u'tasks'][1][u'ping'][u'data']._column_number, 31)\n         self.assertEqual(self.data[0][u'tasks'][1][u'ping'][u'data']._data_source, self.play_filename)\n \n         #\n         # Third Task\n         #\n         self.assertEqual(self.data[0][u'tasks'][2]._line_number, 24)\n-        self.assertEqual(self.data[0][u'tasks'][2]._column_number, 28)\n+        self.assertEqual(self.data[0][u'tasks'][2]._column_number, 23)\n         self.assertEqual(self.data[0][u'tasks'][2]._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'tasks'][2][u'name']._line_number, 24)\n-        self.assertEqual(self.data[0][u'tasks'][2][u'name']._column_number, 23)\n+        self.assertEqual(self.data[0][u'tasks'][2][u'name']._column_number, 29)\n         self.assertEqual(self.data[0][u'tasks'][2][u'name']._data_source, self.play_filename)\n \n-        #self.assertEqual(self.data[0][u'tasks'][2][u'command']._line_number, 25)\n-        self.assertEqual(self.data[0][u'tasks'][2][u'command']._column_number, 23)\n+        self.assertEqual(self.data[0][u'tasks'][2][u'command']._line_number, 25)\n+        self.assertEqual(self.data[0][u'tasks'][2][u'command']._column_number, 32)\n         self.assertEqual(self.data[0][u'tasks'][2][u'command']._data_source, self.play_filename)\n \n     def test_line_numbers(self):\n         # Check the line/column numbers are correct\n         # Note: Remember, currently dicts begin at the start of their first entry's value\n         self.assertEqual(self.data[0]._line_number, 2)\n-        self.assertEqual(self.data[0]._column_number, 25)\n+        self.assertEqual(self.data[0]._column_number, 19)\n         self.assertEqual(self.data[0]._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'hosts']._line_number, 2)\n-        self.assertEqual(self.data[0][u'hosts']._column_number, 19)\n+        self.assertEqual(self.data[0][u'hosts']._column_number, 26)\n         self.assertEqual(self.data[0][u'hosts']._data_source, self.play_filename)\n \n         self.assertEqual(self.data[0][u'vars']._line_number, 4)\n-        self.assertEqual(self.data[0][u'vars']._column_number, 28)\n+        self.assertEqual(self.data[0][u'vars']._column_number, 21)\n         self.assertEqual(self.data[0][u'vars']._data_source, self.play_filename)\n \n         self.check_vars()",
         "def compose_node(self, parent, index):\\n        node = Composer.compose_node(self, parent, index)\\n        if isinstance(node, (ScalarNode, MappingNode)):\\n            node.__datasource__ = self.name\\n            node.__line__ = self.line\\n            node.__column__ = node.start_mark.column + 1\\n            node.__line__ = node.start_mark.line + 1\\n        return node",
         "def compose_node(self, parent, index):\\n        node = Composer.compose_node(self, parent, index)\\n        if isinstance(node, ScalarNode):\\n            node.__datasource__ = self.name\\n            node.__line__ = self.line\\n            if self.indents:\\n                node.__column__ = self.indent + 1\\n            else:\\n                node.__column__ = self.column +1\\n        elif isinstance(node, MappingNode):\\n            node.__datasource__ = self.name\\n            try:\\n                (cur_line, cur_column) = self.__mapping_starts.pop()\\n            except:\\n                cur_line = None\\n                cur_column = None\\n            node.__line__   = cur_line\\n            node.__column__ = cur_column\\n        return node",
         "compose_node",
         null,
         "Trigger a Wrong Algorithm - Small Sparse Modifications (WALD) fault within the compose_node function. The function should fail due to scattered changes in the node attribute assignment logic for different node types.",
         "Implement distributed algorithm changes that affect how source locations are tracked differently for each node type. The function should fail due to using a scattered approach to determine line and column numbers.",
         "Implement distributed algorithm changes that affect how source locations are tracked.",
         "ansible",
         "3.9.0",
         "test_loader.py",
         "https://github.com/ansible/ansible",
         "WALD"
        ],
        [
         "49",
         "Run `save` inside config mode. (#23977)\\n\\n\\n\\n\\n\\nMove `save` tests to integration tests",
         null,
         null,
         "https://github.com/python/cpython/commit/fc0bf87c20c394dae7246a75ed29cc50f5ddd5df",
         "fc0bf87c20c394dae7246a75ed29cc50f5ddd5df",
         "Defectors",
         "diff --git a/lib/ansible/modules/network/vyos/vyos_config.py b/lib/ansible/modules/network/vyos/vyos_config.py\nindex cc1961a809..c8e10360d1 100644\n--- a/lib/ansible/modules/network/vyos/vyos_config.py\n+++ b/lib/ansible/modules/network/vyos/vyos_config.py\n@@ -269,9 +269,11 @@ def main():\n         run(module, result)\n \n     if module.params['save']:\n-        if not module.check_mode:\n-            run_commands(module, ['save'])\n-        result['changed'] = True\n+        diff = run_commands(module, commands=['configure', 'compare saved'])[1]\n+        if diff != '[edit]':\n+            run_commands(module, commands=['save'])\n+            result['changed'] = True\n+        run_commands(module, commands=['exit'])\n \n     module.exit_json(**result)\n \ndiff --git a/test/integration/targets/vyos_config/tests/cli/save.yaml b/test/integration/targets/vyos_config/tests/cli/save.yaml\nnew file mode 100644\nindex 0000000000..0eeeb80477\n--- /dev/null\n+++ b/test/integration/targets/vyos_config/tests/cli/save.yaml\n@@ -0,0 +1,60 @@\n+---\n+- debug: msg=\"START cli/save.yaml\"\n+\n+- name: setup\n+  vyos_config:\n+    lines: set system host-name {{ inventory_hostname_short }}\n+    provider: \"{{ cli }}\"\n+    match: none\n+\n+- name: configure hostaname and save\n+  vyos_config:\n+    lines: set system host-name foo\n+    provider: \"{{ cli }}\"\n+    save: true\n+  register: result\n+\n+- assert:\n+    that:\n+      - \"result.changed == true\"\n+      - \"'set system host-name foo' in result.commands\"\n+\n+- name: configure hostaname and don't save\n+  vyos_config:\n+    lines: set system host-name bar\n+    provider: \"{{ cli }}\"\n+  register: result\n+\n+- assert:\n+    that:\n+      - \"result.changed == true\"\n+      - \"'set system host-name bar' in result.commands\"\n+\n+- name: save config\n+  vyos_config:\n+    save: true\n+    provider: \"{{ cli }}\"\n+  register: result\n+\n+- assert:\n+    that:\n+      - \"result.changed == true\"\n+\n+- name: save config again\n+  vyos_config:\n+    save: true\n+    provider: \"{{ cli }}\"\n+  register: result\n+\n+- assert:\n+    that:\n+      - \"result.changed == false\"\n+\n+- name: teardown\n+  vyos_config:\n+    lines: set system host-name {{ inventory_hostname_short }}\n+    provider: \"{{ cli }}\"\n+    match: none\n+    save: true\n+\n+- debug: msg=\"END cli/simple.yaml\"\ndiff --git a/test/units/modules/network/vyos/test_vyos_config.py b/test/units/modules/network/vyos/test_vyos_config.py\nindex 6ecd9bc4e4..09dc7a0d2f 100644\n--- a/test/units/modules/network/vyos/test_vyos_config.py\n+++ b/test/units/modules/network/vyos/test_vyos_config.py\n@@ -73,15 +73,6 @@ class TestVyosConfigModule(TestVyosModule):\n         result = self.execute_module()\n         self.assertIn('__backup__', result)\n \n-    def test_vyos_config_save(self):\n-        set_module_args(dict(save=True))\n-        self.execute_module(changed=True)\n-        self.assertEqual(self.run_commands.call_count, 1)\n-        self.assertEqual(self.get_config.call_count, 0)\n-        self.assertEqual(self.load_config.call_count, 0)\n-        args = self.run_commands.call_args[0][1]\n-        self.assertIn('save', args)\n-\n     def test_vyos_config_lines(self):\n         commands = ['set system host-name foo']\n         set_module_args(dict(lines=commands))",
         "def main():\\n    argument_spec = dict(\\n        src=dict(type='path'),\\n        lines=dict(type='list'),\\n        match=dict(default='line', choices=['line', 'none']),\\n        comment=dict(default=DEFAULT_COMMENT),\\n        config=dict(),\\n        backup=dict(type='bool', default=False),\\n        save=dict(type='bool', default=False),\\n    )\\n    argument_spec.update(vyos_argument_spec)\\n    mutually_exclusive = [('lines', 'src')]\\n    module = AnsibleModule(\\n        argument_spec=argument_spec,\\n        mutually_exclusive=mutually_exclusive,\\n        supports_check_mode=True\\n    )\\n    warnings = list()\\n    check_args(module, warnings)\\n    result = dict(changed=False, warnings=warnings)\\n    if module.params['backup']:\\n        result['__backup__'] = get_config(module=module)\\n    if any((module.params['src'], module.params['lines'])):\\n        run(module, result)\\n    if module.params['save']:\\n        diff = run_commands(module, commands=['configure', 'compare saved'])[1]\\n        if diff != '[edit]':\\n            run_commands(module, commands=['save'])\\n            result['changed'] = True\\n        run_commands(module, commands=['exit'])\\n    module.exit_json(**result)",
         "def main():\\n    argument_spec = dict(\\n        src=dict(type='path'),\\n        lines=dict(type='list'),\\n        match=dict(default='line', choices=['line', 'none']),\\n        comment=dict(default=DEFAULT_COMMENT),\\n        config=dict(),\\n        backup=dict(type='bool', default=False),\\n        save=dict(type='bool', default=False),\\n    )\\n    argument_spec.update(vyos_argument_spec)\\n    mutually_exclusive = [('lines', 'src')]\\n    module = AnsibleModule(\\n        argument_spec=argument_spec,\\n        mutually_exclusive=mutually_exclusive,\\n        supports_check_mode=True\\n    )\\n    warnings = list()\\n    check_args(module, warnings)\\n    result = dict(changed=False, warnings=warnings)\\n    if module.params['backup']:\\n        result['__backup__'] = get_config(module=module)\\n    if any((module.params['src'], module.params['lines'])):\\n        run(module, result)\\n    if module.params['save']:\\n        if not module.check_mode:\\n            run_commands(module, ['save'])\\n        result['changed'] = True\\n    module.exit_json(**result)",
         "main",
         null,
         "Introduce an error in the main function to simulate a Missing If construct plus Else Before statements (MIEB) fault. The function should fail due to removing the diff check and its else branch before run_commands(['save']), potentially causing unnecessary save operations when no changes are made.",
         "To achieve incorrect configuration saving, inject a bug into main that triggers a missing if construct plus else before statements (MIEB) fault. The function should fail due to the absence of checks and alternative paths for configuration changes before saving, potentially causing unnecessary saves and performance issues.",
         "To achieve incorrect configuration saving, inject a bug into main that triggers a missing if construct plus else before statements (MIEB) fault.",
         "ansible",
         "2.7.0",
         "test_vyos_config.py",
         "https://github.com/ansible/ansible",
         "MIEB"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 4996
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug_Description</th>\n",
       "      <th>Bug_Type</th>\n",
       "      <th>CVE-ID</th>\n",
       "      <th>Commit_URL</th>\n",
       "      <th>Commit_sha</th>\n",
       "      <th>Dataset_input</th>\n",
       "      <th>Diff_patch</th>\n",
       "      <th>Fault Free Code</th>\n",
       "      <th>Faulty Code</th>\n",
       "      <th>Fixed_Method</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Implementation-Level Description</th>\n",
       "      <th>Contextual-Level Description</th>\n",
       "      <th>High-Level Description</th>\n",
       "      <th>Project</th>\n",
       "      <th>Python_Version</th>\n",
       "      <th>Test_File_Path</th>\n",
       "      <th>Url</th>\n",
       "      <th>Fault_Acronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merge pull request from GHSA-p867-fxfr-ph2w\\n\\...</td>\n",
       "      <td>security</td>\n",
       "      <td>CVE-2022-23651</td>\n",
       "      <td>https://github.com/python/cpython/commit/62476...</td>\n",
       "      <td>62476638986e5b6d7459aca5ef8ce220760226e0</td>\n",
       "      <td>CVEFixes</td>\n",
       "      <td>diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...</td>\n",
       "      <td>def _make_sqlite_account_info(self, env=None, ...</td>\n",
       "      <td>def _make_sqlite_account_info(self, env=None, ...</td>\n",
       "      <td>_make_sqlite_account_info(self, env=None, last...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alter the behavior of the _make_sqlite_account...</td>\n",
       "      <td>Modify the _make_sqlite_account_info method to...</td>\n",
       "      <td>Modify the _make_sqlite_account_info method to...</td>\n",
       "      <td>b2-sdk</td>\n",
       "      <td>3.10.0</td>\n",
       "      <td>test_account_info.py</td>\n",
       "      <td>https://github.com/Backblaze/b2-sdk-python</td>\n",
       "      <td>WPFV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prevent setting swift+config locations\\n\\nForb...</td>\n",
       "      <td>security</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/c0d90...</td>\n",
       "      <td>c0d90a580f87dbbf71e3a5d5c1b5cf8d7c7245b2</td>\n",
       "      <td>PySecDB</td>\n",
       "      <td>diff --git a/glance/api/v1/images.py b/glance/...</td>\n",
       "      <td>def _validate_source(source, req):\\n\\t\\tif sou...</td>\n",
       "      <td>def _validate_source(source, req):\\n\\t\\tif sou...</td>\n",
       "      <td>def _validate_source(source, req)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigger a Wrong Logical Expression Used as Bra...</td>\n",
       "      <td>Cause a Wrong Logical Expression Used as Branc...</td>\n",
       "      <td>Cause a Wrong Logical Expression Used as Branc...</td>\n",
       "      <td>openstack</td>\n",
       "      <td>3.9.0</td>\n",
       "      <td>['test_copy_to_file.py', 'test_api.py']</td>\n",
       "      <td>https://github.com/Centrinix/openstack-glance</td>\n",
       "      <td>WLEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do not send traceback to clients by default\\n\\...</td>\n",
       "      <td>security</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/33fc2...</td>\n",
       "      <td>33fc21a81526029d0c50ef82d744250ff1a99b42</td>\n",
       "      <td>PySecDB</td>\n",
       "      <td>diff --git a/glance/common/wsgi.py b/glance/co...</td>\n",
       "      <td>def _single_run(self, application, sock):\\n\\t\\...</td>\n",
       "      <td>def _single_run(self, application, sock):\\n\\t\\...</td>\n",
       "      <td>def _single_run(self, application, sock)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implement a bug in the _single_run method to t...</td>\n",
       "      <td>Modify the _single_run method to introduce a m...</td>\n",
       "      <td>Modify the _single_run method to introduce a m...</td>\n",
       "      <td>openstack</td>\n",
       "      <td>2.6.0</td>\n",
       "      <td>['test_wsgi.py']</td>\n",
       "      <td>https://github.com/Centrinix/openstack-glance</td>\n",
       "      <td>MPFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uses None instead of mutables for function par...</td>\n",
       "      <td>security</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/bebe9...</td>\n",
       "      <td>bebe906ee7ddcc8785c927b559c930d62e972cbb</td>\n",
       "      <td>PySecDB</td>\n",
       "      <td>diff --git a/glance/store/__init__.py b/glance...</td>\n",
       "      <td>def get_api_response_ext(self, http_resp, url=...</td>\n",
       "      <td>def get_api_response_ext(self, http_resp, url=...</td>\n",
       "      <td>def get_api_response_ext(self, http_resp, url=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Modify the get_api_response_ext method to intr...</td>\n",
       "      <td>Create a missing if construct plus statements ...</td>\n",
       "      <td>Create a missing if construct plus statements ...</td>\n",
       "      <td>openstack</td>\n",
       "      <td>3.9.0</td>\n",
       "      <td>['test_swift_store.py', 'test_auth.py', 'test_...</td>\n",
       "      <td>https://github.com/Centrinix/openstack-glance</td>\n",
       "      <td>MIFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To prevent remote code injection on Sheepdog s...</td>\n",
       "      <td>security</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/135fa...</td>\n",
       "      <td>135faec747669a81dd0db7b4a786edc529a68960</td>\n",
       "      <td>PySecDB</td>\n",
       "      <td>diff --git a/glance/store/sheepdog.py b/glance...</td>\n",
       "      <td>def delete(self):\\n\\t\\tself._run_command([\"del...</td>\n",
       "      <td>def delete(self):\\n\\t\\tself._run_command(\"dele...</td>\n",
       "      <td>def delete(self)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To simulate incorrect command execution, intro...</td>\n",
       "      <td>Cause a wrong data type by injecting an error ...</td>\n",
       "      <td>Cause a wrong data type by injecting an error ...</td>\n",
       "      <td>openstack</td>\n",
       "      <td>3.9.0</td>\n",
       "      <td>['test_sheepdog_store.py', 'test_store_locatio...</td>\n",
       "      <td>https://github.com/Centrinix/openstack-glance</td>\n",
       "      <td>WSUIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>fuse update</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/04bdb...</td>\n",
       "      <td>04bdbe4104728dac15937ad06dbb9071ae3bebf9</td>\n",
       "      <td>Defectors</td>\n",
       "      <td>diff --git a/detect.py b/detect.py\\nindex 268b...</td>\n",
       "      <td>def detect(save_img=False):\\n    out, source, ...</td>\n",
       "      <td>def detect(save_img=False):\\n    out, source, ...</td>\n",
       "      <td>detect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alter the behavior of the detect function to i...</td>\n",
       "      <td>Alter the behavior of the detect function to i...</td>\n",
       "      <td>Alter the behavior of the detect function to c...</td>\n",
       "      <td>yolov5</td>\n",
       "      <td>3.9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/ultralytics/yolov5</td>\n",
       "      <td>MFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>--img-size stride-multiple verification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/099e6...</td>\n",
       "      <td>099e6f5ebd31416f33d047249382624ad5489550</td>\n",
       "      <td>Defectors</td>\n",
       "      <td>diff --git a/detect.py b/detect.py\\nindex 132d...</td>\n",
       "      <td>def train(hyp):\\n    epochs = opt.epochs  \\n  ...</td>\n",
       "      <td>def train(hyp):\\n    epochs = opt.epochs  \\n  ...</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigger a Wrong Function Called with Same Para...</td>\n",
       "      <td>Introduce an error in the function train to si...</td>\n",
       "      <td>Introduce an error in the function train to si...</td>\n",
       "      <td>yolov5</td>\n",
       "      <td>3.9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/ultralytics/yolov5</td>\n",
       "      <td>WFCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>Update minimum stride to 32 (#2266)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/python/cpython/commit/e27ca...</td>\n",
       "      <td>e27ca0d8455ad91ec52e4dfd757825e653508bde</td>\n",
       "      <td>Defectors</td>\n",
       "      <td>diff --git a/test.py b/test.py\\nindex c30148df...</td>\n",
       "      <td>def train(hyp, opt, device, tb_writer=None, wa...</td>\n",
       "      <td>def train(hyp, opt, device, tb_writer=None, wa...</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alter the behavior of the train function to in...</td>\n",
       "      <td>Introduce an error in the train function to si...</td>\n",
       "      <td>Introduce an error in the train function to si...</td>\n",
       "      <td>yolov5</td>\n",
       "      <td>3.9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/ultralytics/yolov5</td>\n",
       "      <td>WFCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>Avoid CVE-2019-9740 in 1.24.x by percent-encod...</td>\n",
       "      <td>security</td>\n",
       "      <td>CVE-2019-9740</td>\n",
       "      <td>https://github.com/python/cpython/commit/efddd...</td>\n",
       "      <td>efddd7e7bad26188c3b692d1090cba768afa9162</td>\n",
       "      <td>MoreFixes</td>\n",
       "      <td>diff --git a/src/urllib3/util/url.py b/src/url...</td>\n",
       "      <td>def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...</td>\n",
       "      <td>def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...</td>\n",
       "      <td>def parse_url(url)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cause a Wrong Algorithm - Small Sparse Modific...</td>\n",
       "      <td>Implement a bug in the parse_url function to t...</td>\n",
       "      <td>Implement a bug in the parse_url function to t...</td>\n",
       "      <td>urllib3</td>\n",
       "      <td>2.7.0</td>\n",
       "      <td>['test_util.py']</td>\n",
       "      <td>https://github.com/urllib3/urllib3</td>\n",
       "      <td>WALD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Percent-encode invalid characters with request...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVE-2020-7212</td>\n",
       "      <td>https://github.com/python/cpython/commit/a74c9...</td>\n",
       "      <td>a74c9cfbaed9f811e7563cfc3dce894928e0221a</td>\n",
       "      <td>CVEFixes</td>\n",
       "      <td>diff --git a/CHANGES.rst b/CHANGES.rst\\nindex ...</td>\n",
       "      <td>def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...</td>\n",
       "      <td>def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...</td>\n",
       "      <td>parse_url(url)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alter the behavior of the parse_url function t...</td>\n",
       "      <td>Alter the behavior of the parse_url function t...</td>\n",
       "      <td>Alter the behavior of the parse_url function t...</td>\n",
       "      <td>urllib3</td>\n",
       "      <td>2.7.0</td>\n",
       "      <td>test_util.py</td>\n",
       "      <td>https://github.com/urllib3/urllib3</td>\n",
       "      <td>WSUIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4996 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Bug_Description  Bug_Type  \\\n",
       "0     Merge pull request from GHSA-p867-fxfr-ph2w\\n\\...  security   \n",
       "1     Prevent setting swift+config locations\\n\\nForb...  security   \n",
       "2     Do not send traceback to clients by default\\n\\...  security   \n",
       "3     Uses None instead of mutables for function par...  security   \n",
       "4     To prevent remote code injection on Sheepdog s...  security   \n",
       "...                                                 ...       ...   \n",
       "4991                                        fuse update       NaN   \n",
       "4992            --img-size stride-multiple verification       NaN   \n",
       "4993                Update minimum stride to 32 (#2266)       NaN   \n",
       "4994  Avoid CVE-2019-9740 in 1.24.x by percent-encod...  security   \n",
       "4995  Percent-encode invalid characters with request...       NaN   \n",
       "\n",
       "              CVE-ID                                         Commit_URL  \\\n",
       "0     CVE-2022-23651  https://github.com/python/cpython/commit/62476...   \n",
       "1                NaN  https://github.com/python/cpython/commit/c0d90...   \n",
       "2                NaN  https://github.com/python/cpython/commit/33fc2...   \n",
       "3                NaN  https://github.com/python/cpython/commit/bebe9...   \n",
       "4                NaN  https://github.com/python/cpython/commit/135fa...   \n",
       "...              ...                                                ...   \n",
       "4991             NaN  https://github.com/python/cpython/commit/04bdb...   \n",
       "4992             NaN  https://github.com/python/cpython/commit/099e6...   \n",
       "4993             NaN  https://github.com/python/cpython/commit/e27ca...   \n",
       "4994   CVE-2019-9740  https://github.com/python/cpython/commit/efddd...   \n",
       "4995   CVE-2020-7212  https://github.com/python/cpython/commit/a74c9...   \n",
       "\n",
       "                                    Commit_sha Dataset_input  \\\n",
       "0     62476638986e5b6d7459aca5ef8ce220760226e0      CVEFixes   \n",
       "1     c0d90a580f87dbbf71e3a5d5c1b5cf8d7c7245b2       PySecDB   \n",
       "2     33fc21a81526029d0c50ef82d744250ff1a99b42       PySecDB   \n",
       "3     bebe906ee7ddcc8785c927b559c930d62e972cbb       PySecDB   \n",
       "4     135faec747669a81dd0db7b4a786edc529a68960       PySecDB   \n",
       "...                                        ...           ...   \n",
       "4991  04bdbe4104728dac15937ad06dbb9071ae3bebf9     Defectors   \n",
       "4992  099e6f5ebd31416f33d047249382624ad5489550     Defectors   \n",
       "4993  e27ca0d8455ad91ec52e4dfd757825e653508bde     Defectors   \n",
       "4994  efddd7e7bad26188c3b692d1090cba768afa9162     MoreFixes   \n",
       "4995  a74c9cfbaed9f811e7563cfc3dce894928e0221a      CVEFixes   \n",
       "\n",
       "                                             Diff_patch  \\\n",
       "0     diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...   \n",
       "1     diff --git a/glance/api/v1/images.py b/glance/...   \n",
       "2     diff --git a/glance/common/wsgi.py b/glance/co...   \n",
       "3     diff --git a/glance/store/__init__.py b/glance...   \n",
       "4     diff --git a/glance/store/sheepdog.py b/glance...   \n",
       "...                                                 ...   \n",
       "4991  diff --git a/detect.py b/detect.py\\nindex 268b...   \n",
       "4992  diff --git a/detect.py b/detect.py\\nindex 132d...   \n",
       "4993  diff --git a/test.py b/test.py\\nindex c30148df...   \n",
       "4994  diff --git a/src/urllib3/util/url.py b/src/url...   \n",
       "4995  diff --git a/CHANGES.rst b/CHANGES.rst\\nindex ...   \n",
       "\n",
       "                                        Fault Free Code  \\\n",
       "0     def _make_sqlite_account_info(self, env=None, ...   \n",
       "1     def _validate_source(source, req):\\n\\t\\tif sou...   \n",
       "2     def _single_run(self, application, sock):\\n\\t\\...   \n",
       "3     def get_api_response_ext(self, http_resp, url=...   \n",
       "4     def delete(self):\\n\\t\\tself._run_command([\"del...   \n",
       "...                                                 ...   \n",
       "4991  def detect(save_img=False):\\n    out, source, ...   \n",
       "4992  def train(hyp):\\n    epochs = opt.epochs  \\n  ...   \n",
       "4993  def train(hyp, opt, device, tb_writer=None, wa...   \n",
       "4994  def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...   \n",
       "4995  def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...   \n",
       "\n",
       "                                            Faulty Code  \\\n",
       "0     def _make_sqlite_account_info(self, env=None, ...   \n",
       "1     def _validate_source(source, req):\\n\\t\\tif sou...   \n",
       "2     def _single_run(self, application, sock):\\n\\t\\...   \n",
       "3     def get_api_response_ext(self, http_resp, url=...   \n",
       "4     def delete(self):\\n\\t\\tself._run_command(\"dele...   \n",
       "...                                                 ...   \n",
       "4991  def detect(save_img=False):\\n    out, source, ...   \n",
       "4992  def train(hyp):\\n    epochs = opt.epochs  \\n  ...   \n",
       "4993  def train(hyp, opt, device, tb_writer=None, wa...   \n",
       "4994  def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...   \n",
       "4995  def parse_url(url):\\n\\tif not url:\\n\\t\\treturn...   \n",
       "\n",
       "                                           Fixed_Method Impact  \\\n",
       "0     _make_sqlite_account_info(self, env=None, last...    NaN   \n",
       "1                     def _validate_source(source, req)    NaN   \n",
       "2              def _single_run(self, application, sock)    NaN   \n",
       "3     def get_api_response_ext(self, http_resp, url=...    NaN   \n",
       "4                                      def delete(self)    NaN   \n",
       "...                                                 ...    ...   \n",
       "4991                                             detect    NaN   \n",
       "4992                                              train    NaN   \n",
       "4993                                              train    NaN   \n",
       "4994                                 def parse_url(url)    NaN   \n",
       "4995                                     parse_url(url)    NaN   \n",
       "\n",
       "                       Implementation-Level Description  \\\n",
       "0     Alter the behavior of the _make_sqlite_account...   \n",
       "1     Trigger a Wrong Logical Expression Used as Bra...   \n",
       "2     Implement a bug in the _single_run method to t...   \n",
       "3     Modify the get_api_response_ext method to intr...   \n",
       "4     To simulate incorrect command execution, intro...   \n",
       "...                                                 ...   \n",
       "4991  Alter the behavior of the detect function to i...   \n",
       "4992  Trigger a Wrong Function Called with Same Para...   \n",
       "4993  Alter the behavior of the train function to in...   \n",
       "4994  Cause a Wrong Algorithm - Small Sparse Modific...   \n",
       "4995  Alter the behavior of the parse_url function t...   \n",
       "\n",
       "                           Contextual-Level Description  \\\n",
       "0     Modify the _make_sqlite_account_info method to...   \n",
       "1     Cause a Wrong Logical Expression Used as Branc...   \n",
       "2     Modify the _single_run method to introduce a m...   \n",
       "3     Create a missing if construct plus statements ...   \n",
       "4     Cause a wrong data type by injecting an error ...   \n",
       "...                                                 ...   \n",
       "4991  Alter the behavior of the detect function to i...   \n",
       "4992  Introduce an error in the function train to si...   \n",
       "4993  Introduce an error in the train function to si...   \n",
       "4994  Implement a bug in the parse_url function to t...   \n",
       "4995  Alter the behavior of the parse_url function t...   \n",
       "\n",
       "                                 High-Level Description    Project  \\\n",
       "0     Modify the _make_sqlite_account_info method to...     b2-sdk   \n",
       "1     Cause a Wrong Logical Expression Used as Branc...  openstack   \n",
       "2     Modify the _single_run method to introduce a m...  openstack   \n",
       "3     Create a missing if construct plus statements ...  openstack   \n",
       "4     Cause a wrong data type by injecting an error ...  openstack   \n",
       "...                                                 ...        ...   \n",
       "4991  Alter the behavior of the detect function to c...     yolov5   \n",
       "4992  Introduce an error in the function train to si...     yolov5   \n",
       "4993  Introduce an error in the train function to si...     yolov5   \n",
       "4994  Implement a bug in the parse_url function to t...    urllib3   \n",
       "4995  Alter the behavior of the parse_url function t...    urllib3   \n",
       "\n",
       "     Python_Version                                     Test_File_Path  \\\n",
       "0            3.10.0                               test_account_info.py   \n",
       "1             3.9.0            ['test_copy_to_file.py', 'test_api.py']   \n",
       "2             2.6.0                                   ['test_wsgi.py']   \n",
       "3             3.9.0  ['test_swift_store.py', 'test_auth.py', 'test_...   \n",
       "4             3.9.0  ['test_sheepdog_store.py', 'test_store_locatio...   \n",
       "...             ...                                                ...   \n",
       "4991          3.9.0                                                NaN   \n",
       "4992          3.9.0                                                NaN   \n",
       "4993          3.9.0                                                NaN   \n",
       "4994          2.7.0                                   ['test_util.py']   \n",
       "4995          2.7.0                                       test_util.py   \n",
       "\n",
       "                                                Url Fault_Acronym  \n",
       "0        https://github.com/Backblaze/b2-sdk-python          WPFV  \n",
       "1     https://github.com/Centrinix/openstack-glance          WLEC  \n",
       "2     https://github.com/Centrinix/openstack-glance          MPFC  \n",
       "3     https://github.com/Centrinix/openstack-glance          MIFS  \n",
       "4     https://github.com/Centrinix/openstack-glance         WSUIT  \n",
       "...                                             ...           ...  \n",
       "4991          https://github.com/ultralytics/yolov5           MFC  \n",
       "4992          https://github.com/ultralytics/yolov5          WFCS  \n",
       "4993          https://github.com/ultralytics/yolov5          WFCS  \n",
       "4994             https://github.com/urllib3/urllib3          WALD  \n",
       "4995             https://github.com/urllib3/urllib3         WSUIT  \n",
       "\n",
       "[4996 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the Excel file\n",
    "file_path = \"/home/odedh/SML-For-Debug/data/dataset/PyresBugs.xlsx\"  # Replace with the actual file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442b781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Fault_Acronym",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0bd1fa10-0f7f-44fa-8606-0985713b80e7",
       "rows": [
        [
         "MPFC",
         "539"
        ],
        [
         "MIFS",
         "507"
        ],
        [
         "WALL",
         "398"
        ],
        [
         "WFCD",
         "334"
        ],
        [
         "WPFV",
         "290"
        ],
        [
         "WFCS",
         "280"
        ],
        [
         "WSUIT",
         "257"
        ],
        [
         "WLEC",
         "208"
        ],
        [
         "MFC",
         "199"
        ],
        [
         "WVAV",
         "177"
        ],
        [
         "MLPL",
         "147"
        ],
        [
         "WALD",
         "128"
        ],
        [
         "WALR",
         "126"
        ],
        [
         "MVAV",
         "109"
        ],
        [
         "WPFL",
         "101"
        ],
        [
         "MIES",
         "97"
        ],
        [
         "WVIV",
         "89"
        ],
        [
         "MLPS",
         "82"
        ],
        [
         "MLAC",
         "78"
        ],
        [
         "MVAE",
         "58"
        ],
        [
         "MIA",
         "56"
        ],
        [
         "MFCT",
         "52"
        ],
        [
         "WPFO",
         "51"
        ],
        [
         "MLPA",
         "48"
        ],
        [
         "EFC",
         "44"
        ],
        [
         "WVAL",
         "44"
        ],
        [
         "WVAE",
         "42"
        ],
        [
         "MIEB",
         "42"
        ],
        [
         "MFCE",
         "38"
        ],
        [
         "WRV",
         "37"
        ],
        [
         "EVAL",
         "31"
        ],
        [
         "WLEP",
         "31"
        ],
        [
         "MLOC",
         "31"
        ],
        [
         "MLOP",
         "26"
        ],
        [
         "WSUC",
         "24"
        ],
        [
         "WIDS",
         "24"
        ],
        [
         "MECL",
         "20"
        ],
        [
         "WAEC",
         "19"
        ],
        [
         "WIDI",
         "19"
        ],
        [
         "MEH",
         "18"
        ],
        [
         "MLAA",
         "18"
        ],
        [
         "MRS",
         "18"
        ],
        [
         "WAEP",
         "11"
        ],
        [
         "MCS",
         "7"
        ],
        [
         "MLOA",
         "6"
        ],
        [
         "MCA",
         "6"
        ],
        [
         "ELOC",
         "6"
        ],
        [
         "MIEA",
         "5"
        ],
        [
         "WPLA",
         "4"
        ],
        [
         "WPLP",
         "4"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 62
       }
      },
      "text/plain": [
       "Fault_Acronym\n",
       "MPFC             539\n",
       "MIFS             507\n",
       "WALL             398\n",
       "WFCD             334\n",
       "WPFV             290\n",
       "                ... \n",
       "WIDIM              1\n",
       "EEH                1\n",
       "MBC                1\n",
       "MPFC and WALL      1\n",
       "WLEC + WALR        1\n",
       "Name: count, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of entries for each Fault_Acronym and the entire Fault_Acronym options avaiable\n",
    "fault_acronym_counts = df['Fault_Acronym'].value_counts()\n",
    "fault_acronym_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c19ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping NaN rows: (5006, 19)\n",
      "After dropping NaN rows: (5006, 19)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where both Faulty Code and Fault Free Code are missing\n",
    "print(\"Before dropping NaN rows:\", df.shape)\n",
    "df = df.dropna(subset=[\"Faulty Code\", \"Fault Free Code\"], how='all')\n",
    "print(\"After dropping NaN rows:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20900c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the descriptions into one list per row\n",
    "desc_columns = [\"Implementation-Level Description\",\n",
    "                \"Contextual-Level Description\", \"High-Level Description\"]\n",
    "df[\"Available_Descriptions\"] = df[desc_columns].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90081d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Incorporate a few-shot examples\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a code‑analysis model.  \n",
    "Your task is to examine Python code and decide **whether it contains a bug**.  \n",
    "Then return either the unchanged code (if no bug) or a fully‑fixed version (if a bug exists).\n",
    "\n",
    "You must reply **only** with a JSON object that **exactly** matches this schema  \n",
    "(no extra keys, no comments, no trailing commas):\n",
    "\n",
    "{\n",
    "  \"has_bug\": \"<BUG_TRUE>\" | \"<BUG_FALSE>\",\n",
    "  \"bugs_free_version\": \"<CODE> …python‑code… <CODE>\"\n",
    "}\n",
    "\n",
    "### Guidelines\n",
    "1. **Classification first**  \n",
    "   • Use `<BUG_TRUE>` if *any* bug is present, otherwise `<BUG_FALSE>`.  \n",
    "2. **Bug‑free version**  \n",
    "   • If `<BUG_FALSE>`, echo the *original* code unchanged.  \n",
    "   • If `<BUG_TRUE>`, return the **entire** corrected file (not a diff).  \n",
    "   • Wrap the code in `<CODE>` tags; keep original indentation and newlines.  \n",
    "3. **Output hygiene**  \n",
    "   • No natural‑language explanations.  \n",
    "   • Never output extra keys.  \n",
    "   • Ensure the JSON is syntactically valid (double‑quoted strings, commas, braces).  \n",
    "\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### Example 1 — Simple Bug\n",
    "**Input:**\n",
    "def subtract(a, b):\n",
    "    return a + b\n",
    "\n",
    "**Expected Output:**\n",
    "{\n",
    "  \"has_bug\": \"<BUG_TRUE>\",\n",
    "  \"bugs_free_version\": \"<CODE>def subtract(a, b):\\\\n    return a - b<CODE>\"\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2 — Hard Bug (Off-by-One Error)\n",
    "**Input:**\n",
    "def binary_search(arr, target):\n",
    "    low, high = 0, len(arr)\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "    return -1\n",
    "\n",
    "**Expected Output:**\n",
    "{\n",
    "  \"has_bug\": \"<BUG_TRUE>\",\n",
    "  \"bugs_free_version\": \"<CODE>def binary_search(arr, target):\\\\n    low, high = 0, len(arr) - 1\\\\n    while low <= high:\\\\n        mid = (low + high) // 2\\\\n        if arr[mid] == target:\\\\n            return mid\\\\n        elif arr[mid] < target:\\\\n            low = mid + 1\\\\n        else:\\\\n            high = mid - 1\\\\n    return -1<CODE>\"\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3 — No Bug\n",
    "**Input:**\n",
    "def gcd(a, b):\n",
    "    while b:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "**Expected Output:**\n",
    "{\n",
    "  \"has_bug\": \"<BUG_FALSE>\",\n",
    "  \"bugs_free_version\": \"<CODE>def gcd(a, b):\\\\n    while b:\\\\n        a, b = b, a % b\\\\n    return a<CODE>\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3372b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example_with_acronym(code, label, fixed_code):\n",
    "    system_content = SYSTEM_PROMPT\n",
    "    user_content = code\n",
    "\n",
    "    if label == \"BUG\":\n",
    "        response = {\n",
    "            \"has_bug\": \"<BUG_TRUE>\",\n",
    "            \"Code\": f\"<CODE>{fixed_code}<CODE>\",\n",
    "        }\n",
    "    else:\n",
    "        response = {\n",
    "            \"has_bug\": \"<BUG_FALSE>\",\n",
    "            \"Code\": f\"<CODE>{code}<CODE>\",\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"content\": system_content, \"role\": \"system\"},\n",
    "            {\"content\": user_content, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"completion\":  [\n",
    "            { \"content\": json.dumps(response, ensure_ascii=False), \"role\": \"assistant\" }\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913be71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_with_acronym = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    acronym = row[\"Fault_Acronym\"] if \"Fault_Acronym\" in row and pd.notnull(\n",
    "        row[\"Fault_Acronym\"]) else None\n",
    "\n",
    "    if pd.notnull(row[\"Faulty Code\"]) and pd.notnull(row[\"Fault Free Code\"]):\n",
    "        examples_with_acronym.append(create_example_with_acronym(\n",
    "            code=row[\"Faulty Code\"],\n",
    "            label=\"BUG\",\n",
    "            fixed_code=row[\"Fault Free Code\"],\n",
    "        ))\n",
    "        examples_with_acronym.append(create_example_with_acronym(\n",
    "            code=row[\"Fault Free Code\"],\n",
    "            label=\"BUG FREE\",\n",
    "            fixed_code=None,\n",
    "        ))\n",
    "\n",
    "# Split into train and test\n",
    "train_data_acronym, test_data_acronym = train_test_split(\n",
    "    examples_with_acronym, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Save in message format\n",
    "train_path = \"/home/odedh/SML-For-Debug/data/dataset/pyresbugs_train.jsonl\"\n",
    "test_path = \"/home/odedh/SML-For-Debug/data/dataset/pyresbugs_test.jsonl\"\n",
    "\n",
    "with open(train_path, \"w\") as f:\n",
    "    for item in train_data_acronym:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(test_path, \"w\") as f:\n",
    "    for item in test_data_acronym:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
