{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fe46a2",
   "metadata": {},
   "source": [
    "### VLLM serve command:\n",
    "\n",
    "### Codestral-22B-v0.1\n",
    "``` sh\n",
    "docker run --rm --gpus all --privileged   --ipc=host  --shm-size=2g --network host -v ~/.cache/huggingface:/root/.cache/huggingface\n",
    "  -v /home/odedh/SML-For-Debug/models/:/models   vllm/vllm-openai:latest   --model /models/Codestral-22B-v0.1   --use-tqdm-on-load   \n",
    "--enable-chunked-prefill   --tensor-parallel-size 2\n",
    "\n",
    "```\n",
    "\n",
    "### Qwen3-0.6B\n",
    "``` sh\n",
    "docker run --rm --gpus all  --privileged   --ipc=host  --shm-size=2g --network host -v ~/.cache/huggingface:/root/.cache/huggingface -v /home/odedh/SML-For-Debug/models/:/models   -e CUDA_VISIBLE_DEVICES=2 vllm/vllm-openai:latest   --model /models/Qwen3-0.6B   --use-tqdm-on-load   --enable-chunked-prefill    --port 8001\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddf8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834487a",
   "metadata": {},
   "source": [
    "Running a simpel example for the Qwen3-0.6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7a0d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/Qwen3-0.6B\n",
      "<think>\n",
      "Okay, let's see. The user provided a Python function called divide_numbers that takes two parameters, a and b, and returns a divided by b. The question is to classify this code and determine if there's a bug in it.\n",
      "\n",
      "First, I need to think about what the function does. The function is straightforward: it divides the first number by the second. But wait, what if there's a division by zero? Oh, right! If b is zero, dividing by zero would cause a division by zero error. But in the code given, there's no error checking. So the function as written doesn't handle that case.\n",
      "\n",
      "But the user is asking if there's a bug in the code. The function is supposed to perform the division, but without error handling. So the code is incomplete. The function doesn't check for division by zero, which is a common bug. However, maybe the user expects me to just classify the code as a simple function and note that division by zero is a potential bug.\n",
      "\n",
      "Wait, but the question says \"classify this code and ans if there is a bug in it\". So the user wants me to first classify the code and then answer if there's a bug. The code is a function that returns a / b. The classification would be that it's a function definition. But the classification isn't necessary here. The answer is whether there's a bug. Since division by zero is a bug, the answer is yes, there is a bug.\n",
      "</think>\n",
      "\n",
      "The code defines a function `divide_numbers(a, b)` that returns `a / b`. However, it does **not** include any error handling for division by zero. This means the function could crash if `b` is zero. \n",
      "\n",
      "**Classification**: The code is a function definition.  \n",
      "**Bug**: Yes, there is a bug in the code because it does not handle division by zero.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8001/v1\",\n",
    "    api_key=\"-\",\n",
    ")\n",
    "# print the model name\n",
    "print(client.models.list().data[0].id)\n",
    "\n",
    "model = client.models.list().data[0].id\n",
    "\n",
    "code_for_debugging = \"\"\"\n",
    "def divide_numbers(a, b):\n",
    "    return a / b\n",
    "\"\"\"\n",
    "content = f\"Classify this code and ans if there is a bug in it: {code_for_debugging}\"\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": content}\n",
    "    ],\n",
    "    # extra_body={\"guided_choice\": [\"bug\", \"no-bug\"]},\n",
    "    \n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0957e9",
   "metadata": {},
   "source": [
    "Codestral-22B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196c97eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/Qwen3-0.6B\n",
      "bug\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8001/v1\",\n",
    "    api_key=\"-\",\n",
    ")\n",
    "model = client.models.list().data[0].id\n",
    "print(model)\n",
    "\n",
    "code_for_debugging = \"\"\"\n",
    "def divide_numbers(a, b):\n",
    "    return a / b\n",
    "\"\"\"\n",
    "content = f\"Classify this code: {code_for_debugging}\"\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": content}\n",
    "    ],\n",
    "    extra_body={\"guided_choice\": [\"bug\", \"no-bug\"]},\n",
    "    \n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b66b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"has_bug\": \"has_bug\", \"bug_type\": \"Missing If Construct Plus Statements (MIFS)\", \"fixability\": \"not_fixable\", \"tested_functions\": [\"get_api_response_ext\"] , \"rationale\": \"The function is missing an if statement to check if headers is None, which could lead to a TypeError when headers is None. This is a MIFS fault because the code does not include the if condition, and the fix is not possible to implement.\"}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from typing import Optional, List\n",
    "\n",
    "class BugStatus(str, Enum):\n",
    "    no_bug = \"no_bug\"\n",
    "    has_bug = \"has_bug\"\n",
    "    # uncertain = \"uncertain\"\n",
    "\n",
    "class Fixability(str, Enum):\n",
    "    fixable = \"fixable\"\n",
    "    not_fixable = \"not_fixable\"\n",
    "    unknown = \"unknown\"\n",
    "\n",
    "class ClassificationResult(BaseModel):\n",
    "    has_bug: BugStatus\n",
    "    bug_type: Optional[str] = Field(default=None, description=\"Type of bug if present\")\n",
    "    suggested_fix: Optional[str] = Field(default=None, description=\"Optional fix attempt if model detects a bug\")\n",
    "    confidence_score: float = Field(default=0, ge=0.0, le=1.0)\n",
    "    fixability: Optional[Fixability] = None\n",
    "    tested_functions: Optional[List[str]] = None\n",
    "    rationale: Optional[str] = Field(default=None, description=\"Short reasoning for classification\")\n",
    "\n",
    "json_schema = ClassificationResult.model_json_schema()\n",
    "\n",
    "\n",
    "code_snippet = \"\"\"\n",
    "def get_api_response_ext(self, http_resp, url='/images', headers={},\\n\\t\\t\\t\\t\\t\\t\\t body=None, method=None, api=None,\\n\\t\\t\\t\\t\\t\\t\\t content_type=None):\\n\\t\\tif api is None:\\n\\t\\t\\tapi = self.api\\n\\t\\treq = webob.Request.blank(url)\\n\\t\\tfor k, v in headers.iteritems():\\n\\t\\t\\treq.headers[k] = v\\n\\t\\tif method:\\n\\t\\t\\treq.method = method\\n\\t\\tif body:\\n\\t\\t\\treq.body = body\\n\\t\\tif content_type == 'json':\\n\\t\\t\\treq.content_type = 'application/json'\\n\\t\\telif content_type == 'octet':\\n\\t\\t\\treq.content_type = 'application/octet-stream'\\n\\t\\tres = req.get_response(api)\\n\\t\\tself.assertEqual(res.status_int, http_resp)\\n\\t\\treturn res\n",
    "\"\"\"\n",
    "\n",
    "description = \"\"\"\n",
    "Modify the get_api_response_ext method to introduce a Missing If Construct Plus Statements (MIFS) fault. The function should fail due to removing the check if headers is None:, causing potential TypeError exceptions when headers is None and iteriting over it.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    temperature=0.15, # Lower temperature for more deterministic output\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are given a Python code snippet. Your job is to classify whether it contains a bug. \"\n",
    "                \"If it does, describe the bug and attempt a fix. If not, state that it is correct. \"\n",
    "                \"Return your response as a structured JSON matching the provided schema. \"\n",
    "                \"Do not explain or justify in natural language outside the JSON. \"\n",
    "                \"Do not assume the answer is known. Use your reasoning to classify the code.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The code snippet: {code_snippet}\\nShort description: {description}\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"code-diagnostic\",\n",
    "            \"schema\": json_schema\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
